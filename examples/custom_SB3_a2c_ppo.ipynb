{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\WilliamFetzner\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment forex-hedge-v0 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
            "c:\\Users\\WilliamFetzner\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment forex-unhedge-v0 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
            "c:\\Users\\WilliamFetzner\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment stocks-hedge-v0 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
            "c:\\Users\\WilliamFetzner\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment stocks-unhedge-v0 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
            "c:\\Users\\WilliamFetzner\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment crypto-hedge-v0 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
            "c:\\Users\\WilliamFetzner\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment crypto-unhedge-v0 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
            "c:\\Users\\WilliamFetzner\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment mixed-hedge-v0 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
            "c:\\Users\\WilliamFetzner\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment mixed-unhedge-v0 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import gymnasium as gym\n",
        "import gym_mtsim\n",
        "sys.path.append(\"C:/Users/WilliamFetzner/Documents/Trading/\")\n",
        "from gym_mtsim_forked.gym_mtsim.data import FOREX_DATA_PATH_TRAIN, FOREX_DATA_PATH_TEST, FOREX_DATA_PATH\n",
        "from gym_mtsim import OrderType, Timeframe, MtEnv, MtSimulator\n",
        "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials, STATUS_FAIL\n",
        "from stable_baselines3 import A2C, PPO\n",
        "from stable_baselines3.common.callbacks import BaseCallback, EvalCallback\n",
        "import time\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import pickle\n",
        "# import time\n",
        "# from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
        "\n",
        "\n",
        "# def objective(x):\n",
        "#     return {\n",
        "#         'loss': x ** 2,\n",
        "#         'status': STATUS_OK,\n",
        "#         # -- store other results like this\n",
        "#         'eval_time': time.time(),\n",
        "#         'other_stuff': {'type': None, 'value': x},\n",
        "#         # -- attachments are handled differently\n",
        "#         'attachments':\n",
        "#             {'time_module': pickle.dumps(time.time)}\n",
        "#         }\n",
        "# trials = Trials()\n",
        "# best = fmin(objective,\n",
        "#             space=hp.uniform('x', -10, 10),\n",
        "#             algo=tpe.suggest,\n",
        "#             max_evals=100,\n",
        "#             trials=trials)\n",
        "\n",
        "# print(best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# trials.results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "# unpack the pickle file and load the data that is in symbols_forex.pkl\n",
        "with open('C:/Users/WilliamFetzner/Documents/Trading/gym_mtsim_forked/gym_mtsim/data/symbols_forex.pkl', 'rb') as f:\n",
        "    symbols = pickle.load(f)\n",
        "# convert symbols to a pd.dataframe\n",
        "# symbols[1]['EURUSD']\n",
        "split = int(len(symbols[1]['EURUSD']) * 0.80)\n",
        "validation_split = int(len(symbols[1]['EURUSD']) * 0.90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get the 2 weeks of the symbols[1]['EURUSD'] dataframe by first finding the max date\n",
        "# then subtracting 14 days from that date\n",
        "symbols[1]['EURUSD'].index = pd.to_datetime(symbols[1]['EURUSD'].index)\n",
        "max_date = symbols[1]['EURUSD'].index.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# find the previous friday before max_date\n",
        "# what is the day of the week of the max_date\n",
        "max_day_of_week = max_date.dayofweek\n",
        "# subtract the day of the week from the max_date to get the previous friday\n",
        "max_friday = max_date - pd.DateOffset(days=max_day_of_week+2)\n",
        "two_weeks = max_friday - pd.DateOffset(days=14)\n",
        "one_week = max_friday - pd.DateOffset(days=7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "training_index_slice = symbols[1]['EURUSD'].loc[:two_weeks, :].index\n",
        "validation_index_slice = symbols[1]['EURUSD'].loc[two_weeks:one_week, :].index\n",
        "testing_index_slice = symbols[1]['EURUSD'].loc[one_week:, :].index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatetimeIndex(['2024-04-01 00:00:00+00:00', '2024-04-01 01:00:00+00:00',\n",
              "               '2024-04-01 02:00:00+00:00', '2024-04-01 03:00:00+00:00',\n",
              "               '2024-04-01 04:00:00+00:00', '2024-04-01 05:00:00+00:00',\n",
              "               '2024-04-01 06:00:00+00:00', '2024-04-01 07:00:00+00:00',\n",
              "               '2024-04-01 08:00:00+00:00', '2024-04-01 09:00:00+00:00',\n",
              "               ...\n",
              "               '2024-04-05 14:00:00+00:00', '2024-04-05 15:00:00+00:00',\n",
              "               '2024-04-05 16:00:00+00:00', '2024-04-05 17:00:00+00:00',\n",
              "               '2024-04-05 18:00:00+00:00', '2024-04-05 19:00:00+00:00',\n",
              "               '2024-04-05 20:00:00+00:00', '2024-04-05 21:00:00+00:00',\n",
              "               '2024-04-05 22:00:00+00:00', '2024-04-05 23:00:00+00:00'],\n",
              "              dtype='datetime64[ns, UTC]', name='Time', length=120, freq=None)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "validation_index_slice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create Env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "sim_train = gym_mtsim.MtSimulator(\n",
        "    unit='USD',\n",
        "    balance=200000.,\n",
        "    leverage=100.,\n",
        "    stop_out_level=0.2,\n",
        "    hedge=True,\n",
        "    symbols_filename=FOREX_DATA_PATH\n",
        ")\n",
        "\n",
        "env_train = MtEnv(\n",
        "    original_simulator=sim_train,\n",
        "    trading_symbols=['EURUSD'],\n",
        "    window_size = 10,\n",
        "    time_points=list(training_index_slice),\n",
        "    hold_threshold=0.5,\n",
        "    close_threshold=0.5,\n",
        "    fee=lambda symbol: {\n",
        "        # 'GBPCAD': max(0., np.random.normal(0.0007, 0.00005)),\n",
        "        'EURUSD': max(0., np.random.normal(0.0001, 0.00003))\n",
        "        # 'USDJPY': max(0., np.random.normal(0.02, 0.003)),\n",
        "    }[symbol],\n",
        "    symbol_max_orders=2,\n",
        "    multiprocessing_processes=2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "sim_validation = gym_mtsim.MtSimulator(\n",
        "    unit='USD',\n",
        "    balance=200000.,\n",
        "    leverage=100.,\n",
        "    stop_out_level=0.2,\n",
        "    hedge=True,\n",
        "    symbols_filename=FOREX_DATA_PATH\n",
        ")\n",
        "\n",
        "env_validation = MtEnv(\n",
        "    original_simulator=sim_validation,\n",
        "    trading_symbols=['EURUSD'],\n",
        "    window_size = 10,\n",
        "    time_points=list(validation_index_slice),\n",
        "    hold_threshold=0.5,\n",
        "    close_threshold=0.5,\n",
        "    fee=lambda symbol: {\n",
        "        # 'GBPCAD': max(0., np.random.normal(0.0007, 0.00005)),\n",
        "        'EURUSD': max(0., np.random.normal(0.0001, 0.00003))\n",
        "        # 'USDJPY': max(0., np.random.normal(0.02, 0.003)),\n",
        "    }[symbol],\n",
        "    symbol_max_orders=2,\n",
        "    multiprocessing_processes=2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "sim_testing = gym_mtsim.MtSimulator(\n",
        "    unit='USD',\n",
        "    balance=200000.,\n",
        "    leverage=100.,\n",
        "    stop_out_level=0.2,\n",
        "    hedge=True,\n",
        "    symbols_filename=FOREX_DATA_PATH\n",
        ")\n",
        "\n",
        "env_testing = MtEnv(\n",
        "    original_simulator=sim_testing,\n",
        "    trading_symbols=['EURUSD'],\n",
        "    window_size = 10,\n",
        "    time_points=list(testing_index_slice),\n",
        "    hold_threshold=0.5,\n",
        "    close_threshold=0.5,\n",
        "    fee=lambda symbol: {\n",
        "        # 'GBPCAD': max(0., np.random.normal(0.0007, 0.00005)),\n",
        "        'EURUSD': max(0., np.random.normal(0.0001, 0.00003))\n",
        "        # 'USDJPY': max(0., np.random.normal(0.02, 0.003)),\n",
        "    }[symbol],\n",
        "    symbol_max_orders=2,\n",
        "    multiprocessing_processes=2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_stats(reward_over_episodes, printing_name):\n",
        "    \"\"\"  Print Reward  \"\"\"\n",
        "\n",
        "    avg_rewards = np.mean(reward_over_episodes)\n",
        "    min_rewards = np.min(reward_over_episodes)\n",
        "    max_rewards = np.max(reward_over_episodes)\n",
        "\n",
        "    print (f'Min. {printing_name}          : {min_rewards:>10.3f}')\n",
        "    print (f'Avg. {printing_name}          : {avg_rewards:>10.3f}')\n",
        "    print (f'Max. {printing_name}          : {max_rewards:>10.3f}')\n",
        "\n",
        "    return min_rewards, avg_rewards, max_rewards\n",
        "\n",
        "\n",
        "# ProgressBarCallback for model.learn()\n",
        "class ProgressBarCallback(BaseCallback):\n",
        "\n",
        "    def __init__(self, check_freq: int, verbose: int = 1):\n",
        "        super().__init__(verbose)\n",
        "        self.check_freq = check_freq\n",
        "\n",
        "    def _on_training_start(self) -> None:\n",
        "        \"\"\"\n",
        "        This method is called before the first rollout starts.\n",
        "        \"\"\"\n",
        "        self.progress_bar = tqdm(total=self.model._total_timesteps, desc=\"model.learn()\")\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        if self.n_calls % self.check_freq == 0:\n",
        "            self.progress_bar.update(self.check_freq)\n",
        "        return True\n",
        "    \n",
        "    def _on_training_end(self) -> None:\n",
        "        \"\"\"\n",
        "        This event is triggered before exiting the `learn()` method.\n",
        "        \"\"\"\n",
        "        self.progress_bar.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "space = {\n",
        "    'learning_rate': hp.loguniform('learning_rate', -5, -2), # Learning rate\n",
        "    # 'gamma': hp.uniform('gamma', 0.97, 0.99), # Discount factor\n",
        "    'ent_coef': hp.loguniform('ent_coef', -5, 0), # Entropy coefficient\n",
        "    # 'learning_timesteps': hp.choice('learning_timesteps', [25, 50, 100, 250, 500]),\n",
        "    # 'window_size': hp.choice('window_size', [10, 20, 50]) # Window size\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TRAINING + TEST\n",
        "def train_val_model(model, model_policy, env_tr, env_val, seed, steps_str, lr, gamma_param, entropy, total_learning_timesteps=10_000):\n",
        "    \"\"\"\n",
        "    Trains and validates a model using the Proximal Policy Optimization (PPO) algorithm.\n",
        "\n",
        "    Args:\n",
        "        model (object): The model to be trained.\n",
        "        model_policy (object): The policy used by the model.\n",
        "        env_tr (object): The training environment.\n",
        "        env_val (object): The validation environment.\n",
        "        seed (int): The random seed for reproducibility.\n",
        "        steps_str (str): A string representing the number of steps.\n",
        "        window_size_param (int): The window size parameter.\n",
        "        lr (float): The learning rate.\n",
        "        gamma_param (float): The gamma parameter.\n",
        "        entropy (float): The entropy coefficient.\n",
        "        total_learning_timesteps (int, optional): The total number of learning timesteps. Defaults to 10,000.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the reward over validations, orders over validations, and the model dictionary.\n",
        "    \"\"\"\n",
        "    # reproduce training and test\n",
        "    print('-' * 80)\n",
        "    torch.manual_seed(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    #model_dict = {}\n",
        "    # env_tr.window_size = window_size_param\n",
        "    print(f'entropy: {entropy}, learning rate: {lr}')\n",
        "    # eval_callback = EvalCallback(env_tr, log_path='./logs/', eval_freq=1000)\n",
        "    model = PPO(model_policy, env_tr, verbose=0, ent_coef=entropy, learning_rate=lr)#, gamma=gamma_param, \n",
        "    obs_tr, info_tr = env_tr.reset(seed=seed)\n",
        "    # custom callback for 'progress_bar'\n",
        "    model.learn(total_timesteps=total_learning_timesteps)#, callback=ProgressBarCallback(100))\n",
        "\n",
        "    reward_over_validations = []\n",
        "    orders_over_validations = []\n",
        "\n",
        "    for episode in range(0, 10):\n",
        "        obs_val, info_val = env_val.reset(seed=seed)\n",
        "\n",
        "        total_reward = 0\n",
        "        done_val = False\n",
        "\n",
        "        while not done_val:\n",
        "            action, _states = model.predict(obs_val)\n",
        "            obs_val, reward_val, terminated_val, truncated_val, info_val = env_val.step(action)\n",
        "            done_val = terminated_val or truncated_val\n",
        "\n",
        "            total_reward += reward_val\n",
        "            if done_val:\n",
        "                break\n",
        "        try:\n",
        "            order_len = len(env_val.render()['orders'])\n",
        "        except:\n",
        "            order_len = 0\n",
        "\n",
        "        # model_dict[f'model_{episode}'] = model\n",
        "        # model.save(f'models_4_19_24/window_{window_size_param}_entropy_{round(entropy, 4)}/model_{steps_str}_{episode}.pkl')\n",
        "\n",
        "        reward_over_validations.append(total_reward)    \n",
        "        orders_over_validations.append(order_len)  \n",
        "\n",
        "\n",
        "        # if episode % 1 == 0:\n",
        "        avg_reward = np.mean(reward_over_validations)\n",
        "        avg_orders = np.mean(orders_over_validations)\n",
        "        print(f'Episode: {episode}, Avg. Reward: {avg_reward:.3f}, # of orders: {avg_orders:.3f}')\n",
        "\n",
        "    return reward_over_validations, orders_over_validations#, model_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train + Test Env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "seed                     : 2024\n"
          ]
        }
      ],
      "source": [
        "seed = 2024  # random seed\n",
        "total_num_episodes = 10\n",
        "\n",
        "# print (\"env_name                 :\", env_name)\n",
        "print (\"seed                     :\", seed)\n",
        "\n",
        "# INIT matplotlib\n",
        "plot_settings = {}\n",
        "plot_data = {'x': [i for i in range(1, total_num_episodes + 1)]}\n",
        "\n",
        "# learning_timesteps_list_in_K = [25]#, 50, 100]\n",
        "# learning_timesteps_list_in_K = [50, 250, 500]\n",
        "# learning_timesteps_list_in_K = [500, 1000, 3000, 5000]\n",
        "\n",
        "# RL Algorithms: https://stable-baselines3.readthedocs.io/en/master/guide/algos.html\n",
        "\n",
        "timesteps_models_dict = {}\n",
        "def objective(params):\n",
        "    learning_timesteps = 50 #params['learning_timesteps']\n",
        "    ent_coef = params['ent_coef']\n",
        "    gamma = 0.99 #params['gamma']\n",
        "    learning_rate = params['learning_rate']#0.0003#\n",
        "\n",
        "    if learning_rate > 0.05:\n",
        "        print(f'Learning rate too high: {learning_rate}')\n",
        "        return {'loss': None, 'status': STATUS_FAIL, 'eval_time': time.time(), 'parameters': params}\n",
        "    if ent_coef > 0.1:\n",
        "        print(f'Entropy too high: {ent_coef}')\n",
        "        return {'loss': None, 'status': STATUS_FAIL, 'eval_time': time.time(), 'parameters': params}\n",
        "\n",
        "    total_learning_timesteps = learning_timesteps * 1000\n",
        "    step_key = f'{learning_timesteps}K'\n",
        "    policy_dict = PPO.policy_aliases\n",
        "    policy = policy_dict.get('MultiInputPolicy')\n",
        "    class_name = type(PPO).__qualname__\n",
        "    plot_key = f'{class_name}_rewards_'+step_key\n",
        "    try:\n",
        "        print(f'length of training env time points: {len(env_train.time_points)}, \\\n",
        "              length of validation env time points: {len(env_validation.time_points)}')\n",
        "        rewards, orders = train_val_model(PPO, policy, env_train, env_validation, seed, step_key,  \n",
        "                                                    learning_rate, gamma, ent_coef, total_learning_timesteps)\n",
        "    except:\n",
        "        print(f'''there was an error with those parameters: timesteps: {learning_timesteps}, \\n\n",
        "              ent_coef: {ent_coef}, gamma: {gamma}, learning_rate: {learning_rate}''')\n",
        "        return {'loss': None, 'status': STATUS_FAIL, 'eval_time': time.time(), 'parameters': params}\n",
        "    # timesteps_models_dict[step_key] = models_dict\n",
        "    min_rewards, avg_rewards, max_rewards, = print_stats(rewards, 'Reward')\n",
        "    print_stats(orders, 'Orders')\n",
        "    label = f'Avg. {avg_rewards:>7.2f} : {class_name} - {step_key}'\n",
        "    plot_data[plot_key] = rewards\n",
        "    plot_settings[plot_key] = {'label': label}\n",
        "    params['avg_orders'] = np.mean(orders)       \n",
        "\n",
        "    return {'loss': -avg_rewards, 'status': STATUS_OK, 'eval_time': time.time(), 'parameters': params} "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # # check if it is working:\n",
        "# parameters = {\n",
        "#     # 'window_size': 10,\n",
        "#     # 'learning_timesteps': 25,\n",
        "#     'ent_coef': 0.008841807731982131,\n",
        "#     # 'gamma': 0.9484679718228304,\n",
        "#     'learning_rate': 0.021173768344759137\n",
        "# }\n",
        "# objective(parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# PPO('MultiInputPolicy', env_train, verbose=0, ent_coef=parameters['ent_coef']).learn(total_timesteps=25_000) #, learning_rate=parameters['learning_rate'], gamma=parameters['gamma'], ent_coef=parameters['ent_coef']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entropy too high: 0.4816466208856177                  \n",
            "Learning rate too high: 0.08793059868769006           \n",
            "length of training env time points: 88173,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------\n",
            "entropy: 0.06388200908593093, learning rate: 0.009441601315862682\n",
            "  4%|‚ñç         | 2/50 [00:00<00:00, 78.33trial/s, best loss=?]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode: 0, Avg. Reward: 22242.201, # of orders: 38.000       \n",
            "Episode: 1, Avg. Reward: 30042.514, # of orders: 40.000          \n",
            "Episode: 2, Avg. Reward: -12288.608, # of orders: 31.000         \n",
            "Episode: 3, Avg. Reward: 37186.343, # of orders: 35.500          \n",
            "Episode: 4, Avg. Reward: -4247.699, # of orders: 32.600          \n",
            "Episode: 5, Avg. Reward: -27023.573, # of orders: 30.333         \n",
            "Episode: 6, Avg. Reward: -37332.776, # of orders: 28.429         \n",
            "Episode: 7, Avg. Reward: -40700.983, # of orders: 29.250         \n",
            "Episode: 8, Avg. Reward: -28179.638, # of orders: 31.556         \n",
            "Episode: 9, Avg. Reward: -36825.287, # of orders: 30.600         \n",
            "Min. Reward          : -169983.864                               \n",
            "Avg. Reward          : -36825.287                                \n",
            "Max. Reward          : 185611.194                                \n",
            "Min. Orders          :     13.000                                \n",
            "Avg. Orders          :     30.600                                \n",
            "Max. Orders          :     50.000                                \n",
            "Entropy too high: 0.46410884264844837                                             \n",
            "Learning rate too high: 0.09548919277990674                                       \n",
            "Learning rate too high: 0.05098112386374207                                       \n",
            "Entropy too high: 0.19467723261540715                                             \n",
            "Learning rate too high: 0.11601346446896663                                       \n",
            "length of training env time points: 88173,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------\n",
            "entropy: 0.052879345069309074, learning rate: 0.045378594435389524              \n",
            "there was an error with those parameters: timesteps: 50,                        \n",
            "\n",
            "              ent_coef: 0.052879345069309074, gamma: 0.99, learning_rate: 0.045378594435389524\n",
            "Learning rate too high: 0.06312709365683031                                     \n",
            "Learning rate too high: 0.13478105767627485                                     \n",
            "Learning rate too high: 0.13394851475695113                                      \n",
            "Learning rate too high: 0.06668127421383148                                      \n",
            "Learning rate too high: 0.07927440042129782                                      \n",
            "length of training env time points: 88173,               length of validation env time points: 120\n",
            "-------------------------------------------------------------------------------- \n",
            "entropy: 0.021883568031535742, learning rate: 0.027402423499051785               \n",
            "Episode: 0, Avg. Reward: 25764.005, # of orders: 36.000                          \n",
            "Episode: 1, Avg. Reward: 26172.155, # of orders: 39.000                          \n",
            "Episode: 2, Avg. Reward: 12418.504, # of orders: 39.667                          \n",
            "Episode: 3, Avg. Reward: 51393.137, # of orders: 42.000                          \n",
            "Episode: 4, Avg. Reward: 8119.296, # of orders: 37.600                           \n",
            "Episode: 5, Avg. Reward: -9785.675, # of orders: 35.833                          \n",
            "Episode: 6, Avg. Reward: -21721.508, # of orders: 33.286                         \n",
            "Episode: 7, Avg. Reward: -27075.349, # of orders: 33.125                         \n",
            "Episode: 8, Avg. Reward: -16205.061, # of orders: 35.000                         \n",
            "Episode: 9, Avg. Reward: -25136.633, # of orders: 33.700                         \n",
            "Min. Reward          : -164976.069                                               \n",
            "Avg. Reward          : -25136.633                                                \n",
            "Max. Reward          : 168317.036                                                \n",
            "Min. Orders          :     18.000                                                \n",
            "Avg. Orders          :     33.700                                                \n",
            "Max. Orders          :     50.000                                                \n",
            "length of training env time points: 88173,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------\n",
            "entropy: 0.07251117338344797, learning rate: 0.009168328683727377               \n",
            "Episode: 0, Avg. Reward: 21815.359, # of orders: 38.000                         \n",
            "Episode: 1, Avg. Reward: 28910.153, # of orders: 40.000                         \n",
            "Episode: 2, Avg. Reward: -13080.147, # of orders: 31.000                        \n",
            "Episode: 3, Avg. Reward: 35643.286, # of orders: 35.500                         \n",
            "Episode: 4, Avg. Reward: -4733.144, # of orders: 32.600                         \n",
            "Episode: 5, Avg. Reward: -27796.632, # of orders: 30.333                        \n",
            "Episode: 6, Avg. Reward: -37275.615, # of orders: 28.143                        \n",
            "Episode: 7, Avg. Reward: -40774.049, # of orders: 29.000                        \n",
            "Episode: 8, Avg. Reward: -28295.306, # of orders: 31.333                        \n",
            "Episode: 9, Avg. Reward: -36797.224, # of orders: 30.400                        \n",
            "Min. Reward          : -166238.865                                              \n",
            "Avg. Reward          : -36797.224                                               \n",
            "Max. Reward          : 181813.587                                               \n",
            "Min. Orders          :     13.000                                               \n",
            "Avg. Orders          :     30.400                                               \n",
            "Max. Orders          :     50.000                                               \n",
            "length of training env time points: 88173,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------\n",
            "entropy: 0.02305487933298093, learning rate: 0.019027808100495334               \n",
            "Episode: 0, Avg. Reward: 14245.834, # of orders: 27.000                         \n",
            "Episode: 1, Avg. Reward: -37983.215, # of orders: 24.000                        \n",
            "Episode: 2, Avg. Reward: -19439.520, # of orders: 27.000                        \n",
            "Episode: 3, Avg. Reward: 28813.359, # of orders: 26.750                         \n",
            "Episode: 4, Avg. Reward: 32022.285, # of orders: 27.000                         \n",
            "Episode: 5, Avg. Reward: 19026.555, # of orders: 27.000                         \n",
            "Episode: 6, Avg. Reward: 6130.790, # of orders: 27.000                          \n",
            "Episode: 7, Avg. Reward: -888.195, # of orders: 26.750                          \n",
            "Episode: 8, Avg. Reward: 11385.693, # of orders: 27.333                         \n",
            "Episode: 9, Avg. Reward: -3032.859, # of orders: 27.300                         \n",
            "Min. Reward          : -132799.826                                              \n",
            "Avg. Reward          :  -3032.859                                               \n",
            "Max. Reward          : 173571.998                                               \n",
            "Min. Orders          :     21.000                                               \n",
            "Avg. Orders          :     27.300                                               \n",
            "Max. Orders          :     33.000                                               \n",
            "Learning rate too high: 0.11781703755828704                                        \n",
            "Learning rate too high: 0.08498022443807954                                        \n",
            "Entropy too high: 0.7065359179976084                                               \n",
            "length of training env time points: 88173,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------   \n",
            "entropy: 0.018640906672420327, learning rate: 0.02685082968841721                  \n",
            "Episode: 0, Avg. Reward: 22028.380, # of orders: 38.000                            \n",
            "Episode: 1, Avg. Reward: 28619.219, # of orders: 40.000                            \n",
            "Episode: 2, Avg. Reward: -13722.181, # of orders: 31.000                           \n",
            "Episode: 3, Avg. Reward: 35435.063, # of orders: 35.750                            \n",
            "Episode: 4, Avg. Reward: -5419.567, # of orders: 32.800                            \n",
            "Episode: 5, Avg. Reward: -28023.198, # of orders: 30.500                           \n",
            "Episode: 6, Avg. Reward: -37441.471, # of orders: 28.286                           \n",
            "Episode: 7, Avg. Reward: -41040.228, # of orders: 29.125                           \n",
            "Episode: 8, Avg. Reward: -28559.754, # of orders: 31.333                           \n",
            "Episode: 9, Avg. Reward: -37117.727, # of orders: 30.400                           \n",
            "Min. Reward          : -168838.088                                                 \n",
            "Avg. Reward          : -37117.727                                                  \n",
            "Max. Reward          : 182906.797                                                  \n",
            "Min. Orders          :     13.000                                                  \n",
            "Avg. Orders          :     30.400                                                  \n",
            "Max. Orders          :     50.000                                                  \n",
            "Entropy too high: 0.11553351308508845                                              \n",
            "length of training env time points: 88173,               length of validation env time points: 120\n",
            "-------------------------------------------------------------------------------- \n",
            "entropy: 0.016482509412106546, learning rate: 0.03546896230087201                \n",
            "Episode: 0, Avg. Reward: 5176.131, # of orders: 31.000                           \n",
            "Episode: 1, Avg. Reward: 28560.138, # of orders: 34.500                          \n",
            "Episode: 2, Avg. Reward: 3815.430, # of orders: 36.000                           \n",
            "Episode: 3, Avg. Reward: 54331.782, # of orders: 39.750                          \n",
            "Episode: 4, Avg. Reward: 9523.189, # of orders: 35.600                           \n",
            "Episode: 5, Avg. Reward: -12700.334, # of orders: 32.833                         \n",
            "Episode: 6, Avg. Reward: -24677.877, # of orders: 30.429                         \n",
            "Episode: 7, Avg. Reward: -24692.483, # of orders: 30.125                         \n",
            "Episode: 8, Avg. Reward: -16607.245, # of orders: 31.556                         \n",
            "Episode: 9, Avg. Reward: -27173.956, # of orders: 31.000                         \n",
            "Min. Reward          : -169711.183                                               \n",
            "Avg. Reward          : -27173.956                                                \n",
            "Max. Reward          : 205880.839                                                \n",
            "Min. Orders          :     16.000                                                \n",
            "Avg. Orders          :     31.000                                                \n",
            "Max. Orders          :     51.000                                                \n",
            "length of training env time points: 88173,               length of validation env time points: 120\n",
            "-------------------------------------------------------------------------------- \n",
            "entropy: 0.008461103582978002, learning rate: 0.017420938220927808               \n",
            "Episode: 0, Avg. Reward: 22622.137, # of orders: 37.000                          \n",
            "Episode: 1, Avg. Reward: 37329.053, # of orders: 39.000                          \n",
            "Episode: 2, Avg. Reward: 26774.432, # of orders: 40.667                          \n",
            "Episode: 3, Avg. Reward: 70013.727, # of orders: 41.750                          \n",
            "Episode: 4, Avg. Reward: 24541.677, # of orders: 37.600                          \n",
            "Episode: 5, Avg. Reward: 3293.022, # of orders: 36.833                           \n",
            "Episode: 6, Avg. Reward: -13530.070, # of orders: 34.429                         \n",
            "Episode: 7, Avg. Reward: -27488.960, # of orders: 33.750                         \n",
            "Episode: 8, Avg. Reward: -15685.954, # of orders: 35.667                         \n",
            "Episode: 9, Avg. Reward: -27896.264, # of orders: 34.800                         \n",
            "Min. Reward          : -157346.522                                               \n",
            "Avg. Reward          : -27896.264                                                \n",
            "Max. Reward          : 199731.611                                                \n",
            "Min. Orders          :     20.000                                                \n",
            "Avg. Orders          :     34.800                                                \n",
            "Max. Orders          :     51.000                                                \n",
            "length of training env time points: 88173,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------   \n",
            "entropy: 0.031456301749184144, learning rate: 0.012642537643459281                 \n",
            "Episode: 0, Avg. Reward: 21931.919, # of orders: 38.000                            \n",
            "Episode: 1, Avg. Reward: 26768.419, # of orders: 40.000                            \n",
            "Episode: 2, Avg. Reward: -14849.053, # of orders: 31.000                           \n",
            "Episode: 3, Avg. Reward: 34634.629, # of orders: 35.500                            \n",
            "Episode: 4, Avg. Reward: -6422.461, # of orders: 32.600                            \n",
            "Episode: 5, Avg. Reward: -29010.341, # of orders: 30.333                           \n",
            "Episode: 6, Avg. Reward: -38540.781, # of orders: 28.143                           \n",
            "Episode: 7, Avg. Reward: -41901.340, # of orders: 29.000                           \n",
            "Episode: 8, Avg. Reward: -28609.023, # of orders: 31.333                           \n",
            "Episode: 9, Avg. Reward: -37130.307, # of orders: 30.400                           \n",
            "Min. Reward          : -170650.819                                                 \n",
            "Avg. Reward          : -37130.307                                                  \n",
            "Max. Reward          : 183085.673                                                  \n",
            "Min. Orders          :     13.000                                                  \n",
            "Avg. Orders          :     30.400                                                  \n",
            "Max. Orders          :     50.000                                                  \n",
            "length of training env time points: 88173,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------   \n",
            "entropy: 0.015101226530875192, learning rate: 0.033443970307727236                 \n",
            "Episode: 0, Avg. Reward: -33296.000, # of orders: 52.000                           \n",
            "Episode: 1, Avg. Reward: 10540.187, # of orders: 57.500                            \n",
            "Episode: 2, Avg. Reward: -26788.660, # of orders: 43.333                           \n",
            "Episode: 3, Avg. Reward: 19816.070, # of orders: 49.250                            \n",
            "Episode: 4, Avg. Reward: -2837.631, # of orders: 43.200                            \n",
            "Episode: 5, Avg. Reward: -25346.638, # of orders: 39.833                           \n",
            "Episode: 6, Avg. Reward: -37744.112, # of orders: 38.286                           \n",
            "Episode: 7, Avg. Reward: -53630.278, # of orders: 36.125                           \n",
            "Episode: 8, Avg. Reward: -48014.007, # of orders: 38.000                           \n",
            "Episode: 9, Avg. Reward: -57489.444, # of orders: 36.700                           \n",
            "Min. Reward          : -164833.440                                                 \n",
            "Avg. Reward          : -57489.444                                                  \n",
            "Max. Reward          : 159630.262                                                  \n",
            "Min. Orders          :     15.000                                                  \n",
            "Avg. Orders          :     36.700                                                  \n",
            "Max. Orders          :     67.000                                                  \n",
            "Entropy too high: 0.1339324563309591                                               \n",
            "length of training env time points: 88173,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------   \n",
            "entropy: 0.022959513114255058, learning rate: 0.04209523077840347                  \n",
            "Episode: 0, Avg. Reward: 15811.295, # of orders: 38.000                            \n",
            "Episode: 1, Avg. Reward: 24633.684, # of orders: 40.500                            \n",
            "Episode: 2, Avg. Reward: -16145.296, # of orders: 31.333                           \n",
            "Episode: 3, Avg. Reward: 23926.472, # of orders: 35.000                            \n",
            "Episode: 4, Avg. Reward: -14658.760, # of orders: 32.200                           \n",
            "Episode: 5, Avg. Reward: -34736.040, # of orders: 30.000                           \n",
            "Episode: 6, Avg. Reward: -43840.467, # of orders: 28.000                           \n",
            "Episode: 7, Avg. Reward: -46626.975, # of orders: 29.000                           \n",
            "Episode: 8, Avg. Reward: -31281.532, # of orders: 31.333                           \n",
            "Episode: 9, Avg. Reward: -39756.709, # of orders: 30.400                           \n",
            "Min. Reward          : -168999.688                                                 \n",
            "Avg. Reward          : -39756.709                                                  \n",
            "Max. Reward          : 144141.778                                                  \n",
            "Min. Orders          :     13.000                                                  \n",
            "Avg. Orders          :     30.400                                                  \n",
            "Max. Orders          :     50.000                                                  \n",
            "length of training env time points: 88173,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------   \n",
            "entropy: 0.03769995781515452, learning rate: 0.013869415130244851                  \n",
            "Episode: 0, Avg. Reward: 22753.491, # of orders: 38.000                            \n",
            "Episode: 1, Avg. Reward: 29054.091, # of orders: 40.000                              \n",
            "Episode: 2, Avg. Reward: -13037.013, # of orders: 31.000                             \n",
            "Episode: 3, Avg. Reward: 36317.249, # of orders: 35.500                              \n",
            "Episode: 4, Avg. Reward: -4881.855, # of orders: 32.600                              \n",
            "Episode: 5, Avg. Reward: -27806.545, # of orders: 30.333                             \n",
            "Episode: 6, Avg. Reward: -37185.180, # of orders: 28.143                             \n",
            "Episode: 7, Avg. Reward: -40316.036, # of orders: 29.000                             \n",
            "Episode: 8, Avg. Reward: -27718.466, # of orders: 31.333                             \n",
            "Episode: 9, Avg. Reward: -36385.673, # of orders: 30.400                             \n",
            "Min. Reward          : -169678.274                                                   \n",
            "Avg. Reward          : -36385.673                                                    \n",
            "Max. Reward          : 184380.037                                                    \n",
            "Min. Orders          :     13.000                                                    \n",
            "Avg. Orders          :     30.400                                                    \n",
            "Max. Orders          :     50.000                                                    \n",
            "length of training env time points: 88173,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------     \n",
            "entropy: 0.007119622091535491, learning rate: 0.01987496007872917                    \n",
            "Episode: 0, Avg. Reward: 16483.408, # of orders: 39.000                              \n",
            "Episode: 1, Avg. Reward: 27487.519, # of orders: 40.500                              \n",
            "Episode: 2, Avg. Reward: -14552.181, # of orders: 31.333                             \n",
            "Episode: 3, Avg. Reward: 35166.287, # of orders: 36.000                              \n",
            "Episode: 4, Avg. Reward: -6192.591, # of orders: 33.200                              \n",
            "Episode: 5, Avg. Reward: -29087.128, # of orders: 31.000                             \n",
            "Episode: 6, Avg. Reward: -38504.227, # of orders: 28.714                             \n",
            "Episode: 7, Avg. Reward: -42315.081, # of orders: 29.375                             \n",
            "Episode: 8, Avg. Reward: -29592.433, # of orders: 31.556                             \n",
            "Episode: 9, Avg. Reward: -37979.758, # of orders: 30.500                             \n",
            "Min. Reward          : -171628.103                                                   \n",
            "Avg. Reward          : -37979.758                                                    \n",
            "Max. Reward          : 184321.689                                                    \n",
            "Min. Orders          :     13.000                                                    \n",
            "Avg. Orders          :     30.500                                                    \n",
            "Max. Orders          :     50.000                                                    \n",
            "Entropy too high: 0.17172275844142984                                                \n",
            "length of training env time points: 88173,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------     \n",
            "entropy: 0.08808057575044916, learning rate: 0.028167520219215057                    \n",
            "there was an error with those parameters: timesteps: 50,                             \n",
            "\n",
            "              ent_coef: 0.08808057575044916, gamma: 0.99, learning_rate: 0.028167520219215057\n",
            "length of training env time points: 88173,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------     \n",
            "entropy: 0.01232171101755206, learning rate: 0.023080648672035416                    \n",
            "Episode: 0, Avg. Reward: 11333.653, # of orders: 31.000                              \n",
            "Episode: 1, Avg. Reward: -13154.371, # of orders: 30.000                             \n",
            "Episode: 2, Avg. Reward: -29124.159, # of orders: 31.667                             \n",
            "Episode: 3, Avg. Reward: 32668.086, # of orders: 33.000                              \n",
            "Episode: 4, Avg. Reward: 116.389, # of orders: 30.400                                \n",
            "Episode: 5, Avg. Reward: -16955.721, # of orders: 30.333                             \n",
            "Episode: 6, Avg. Reward: -29027.434, # of orders: 29.143                             \n",
            "Episode: 7, Avg. Reward: -36217.791, # of orders: 29.125                             \n",
            "Episode: 8, Avg. Reward: -20994.136, # of orders: 30.889                             \n",
            "Episode: 9, Avg. Reward: -28667.554, # of orders: 30.300                             \n",
            "Min. Reward          : -130090.398                                                   \n",
            "Avg. Reward          : -28667.554                                                    \n",
            "Max. Reward          : 218044.822                                                    \n",
            "Min. Orders          :     20.000                                                    \n",
            "Avg. Orders          :     30.300                                                    \n",
            "Max. Orders          :     45.000                                                    \n",
            "length of training env time points: 88173,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------     \n",
            "entropy: 0.025593847984547013, learning rate: 0.00686986555067144                    \n",
            "Episode: 0, Avg. Reward: 1063.965, # of orders: 39.000                               \n",
            "Episode: 1, Avg. Reward: -5655.774, # of orders: 37.500                              \n",
            "Episode: 2, Avg. Reward: -36893.395, # of orders: 35.333                             \n",
            "Episode: 3, Avg. Reward: 18204.795, # of orders: 37.500                              \n",
            "Episode: 4, Avg. Reward: -16841.667, # of orders: 34.400                             \n",
            "Episode: 5, Avg. Reward: -20828.220, # of orders: 35.167                             \n",
            "Episode: 6, Avg. Reward: -23845.301, # of orders: 36.429                             \n",
            "Episode: 7, Avg. Reward: -34207.646, # of orders: 35.250                             \n",
            "Episode: 8, Avg. Reward: -18518.108, # of orders: 37.222                             \n",
            "Episode: 9, Avg. Reward: -26471.784, # of orders: 36.700                             \n",
            "Min. Reward          : -157027.514                                                   \n",
            "Avg. Reward          : -26471.784                                                    \n",
            "Max. Reward          : 183499.363                                                    \n",
            "Min. Orders          :     22.000                                                    \n",
            "Avg. Orders          :     36.700                                                    \n",
            "Max. Orders          :     53.000                                                    \n",
            "length of training env time points: 88173,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------     \n",
            "entropy: 0.01992296204264731, learning rate: 0.03891833317061838                     \n",
            "Episode: 0, Avg. Reward: 16060.602, # of orders: 37.000                              \n",
            "Episode: 1, Avg. Reward: 29670.082, # of orders: 39.000                              \n",
            "Episode: 2, Avg. Reward: -11682.015, # of orders: 30.667                             \n",
            "Episode: 3, Avg. Reward: 38041.215, # of orders: 35.250                              \n",
            "Episode: 4, Avg. Reward: -3071.482, # of orders: 32.200                              \n",
            "Episode: 5, Avg. Reward: -25209.062, # of orders: 30.000                             \n",
            "Episode: 6, Avg. Reward: -36218.336, # of orders: 28.000                             \n",
            "Episode: 7, Avg. Reward: -39710.834, # of orders: 28.750                             \n",
            "Episode: 8, Avg. Reward: -26945.185, # of orders: 31.111                             \n",
            "Episode: 9, Avg. Reward: -36013.061, # of orders: 30.200                             \n",
            "Min. Reward          : -167522.268                                                   \n",
            "Avg. Reward          : -36013.061                                                    \n",
            "Max. Reward          : 187210.903                                                    \n",
            "Min. Orders          :     14.000                                                    \n",
            "Avg. Orders          :     30.200                                                    \n",
            "Max. Orders          :     50.000                                                    \n",
            "Entropy too high: 0.26881941928940517                                                \n",
            "length of training env time points: 88173,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------     \n",
            "entropy: 0.036781798752661736, learning rate: 0.030953102582608895                   \n",
            "Episode: 0, Avg. Reward: 22322.711, # of orders: 38.000                              \n",
            "Episode: 1, Avg. Reward: 29848.033, # of orders: 40.000                              \n",
            "Episode: 2, Avg. Reward: -12602.011, # of orders: 31.000                             \n",
            "Episode: 3, Avg. Reward: 36781.372, # of orders: 35.500                              \n",
            "Episode: 4, Avg. Reward: -4437.619, # of orders: 32.600                              \n",
            "Episode: 5, Avg. Reward: -27252.894, # of orders: 30.333                             \n",
            "Episode: 6, Avg. Reward: -38186.427, # of orders: 28.857                             \n",
            "Episode: 7, Avg. Reward: -41447.928, # of orders: 29.625                             \n",
            "Episode: 8, Avg. Reward: -28843.588, # of orders: 31.889                             \n",
            "Episode: 9, Avg. Reward: -37422.842, # of orders: 30.900                             \n",
            "Min. Reward          : -169313.583                                                   \n",
            "Avg. Reward          : -37422.842                                                    \n",
            "Max. Reward          : 184931.521                                                    \n",
            "Min. Orders          :     13.000                                                    \n",
            "Avg. Orders          :     30.900                                                    \n",
            "Max. Orders          :     50.000                                                    \n",
            "Learning rate too high: 0.05478171281138742                                          \n",
            "length of training env time points: 88173,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------   \n",
            "entropy: 0.009544641844832688, learning rate: 0.011450160687267237                 \n",
            "Episode: 0, Avg. Reward: -5946.730, # of orders: 37.000                            \n",
            "Episode: 1, Avg. Reward: -9833.476, # of orders: 35.500                            \n",
            "Episode: 2, Avg. Reward: -3231.125, # of orders: 40.333                            \n",
            "Episode: 3, Avg. Reward: -930.184, # of orders: 38.750                             \n",
            "Episode: 4, Avg. Reward: -5065.026, # of orders: 38.800                            \n",
            "Episode: 5, Avg. Reward: -3567.775, # of orders: 39.500                            \n",
            "Episode: 6, Avg. Reward: -5365.018, # of orders: 39.714                            \n",
            "Episode: 7, Avg. Reward: -7106.507, # of orders: 39.250                            \n",
            "Episode: 8, Avg. Reward: -4192.246, # of orders: 40.222                            \n",
            "Episode: 9, Avg. Reward: -2758.382, # of orders: 40.600                            \n",
            "Min. Reward          : -21604.393                                                  \n",
            "Avg. Reward          :  -2758.382                                                  \n",
            "Max. Reward          :  19121.843                                                  \n",
            "Min. Orders          :     34.000                                                  \n",
            "Avg. Orders          :     40.600                                                  \n",
            "Max. Orders          :     50.000                                                  \n",
            "length of training env time points: 88173,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.009353649198558587, learning rate: 0.011960059003364108                  \n",
            "Episode: 0, Avg. Reward: -2864.001, # of orders: 44.000                             \n",
            "Episode: 1, Avg. Reward: -23571.665, # of orders: 46.000                            \n",
            "Episode: 2, Avg. Reward: -21202.357, # of orders: 49.667                            \n",
            "Episode: 3, Avg. Reward: 17113.539, # of orders: 50.500                             \n",
            "Episode: 4, Avg. Reward: 9250.840, # of orders: 50.200                              \n",
            "Episode: 5, Avg. Reward: -10780.956, # of orders: 47.000                            \n",
            "Episode: 6, Avg. Reward: -25684.136, # of orders: 45.143                            \n",
            "Episode: 7, Avg. Reward: -34139.307, # of orders: 44.750                            \n",
            "Episode: 8, Avg. Reward: -28124.767, # of orders: 45.667                            \n",
            "Episode: 9, Avg. Reward: -36397.949, # of orders: 44.400                            \n",
            "Min. Reward          : -115103.216                                                  \n",
            "Avg. Reward          : -36397.949                                                   \n",
            "Max. Reward          : 132061.227                                                   \n",
            "Min. Orders          :     31.000                                                   \n",
            "Avg. Orders          :     44.400                                                   \n",
            "Max. Orders          :     57.000                                                   \n",
            "length of training env time points: 88173,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.014397150870799732, learning rate: 0.01043086417313006                   \n",
            "Episode: 0, Avg. Reward: 10945.271, # of orders: 34.000                             \n",
            "Episode: 1, Avg. Reward: -20813.987, # of orders: 34.000                            \n",
            "Episode: 2, Avg. Reward: -15879.661, # of orders: 38.333                            \n",
            "Episode: 3, Avg. Reward: 30265.844, # of orders: 39.500                             \n",
            "Episode: 4, Avg. Reward: 476.561, # of orders: 36.200                               \n",
            "Episode: 5, Avg. Reward: -15272.706, # of orders: 36.833                            \n",
            "Episode: 6, Avg. Reward: -26713.182, # of orders: 35.857                            \n",
            "Episode: 7, Avg. Reward: -35461.843, # of orders: 35.000                            \n",
            "Episode: 8, Avg. Reward: -21717.913, # of orders: 36.444                            \n",
            "Episode: 9, Avg. Reward: -32867.511, # of orders: 35.900                            \n",
            "Min. Reward          : -133213.899                                                  \n",
            "Avg. Reward          : -32867.511                                                   \n",
            "Max. Reward          : 168702.359                                                   \n",
            "Min. Orders          :     23.000                                                   \n",
            "Avg. Orders          :     35.900                                                   \n",
            "Max. Orders          :     48.000                                                   \n",
            "length of training env time points: 88173,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.06988652990080942, learning rate: 0.01585409409160165                    \n",
            "there was an error with those parameters: timesteps: 50,                            \n",
            "\n",
            "              ent_coef: 0.06988652990080942, gamma: 0.99, learning_rate: 0.01585409409160165\n",
            "length of training env time points: 88173,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.008946461117332492, learning rate: 0.008272790052640817                  \n",
            "Episode: 0, Avg. Reward: 35800.194, # of orders: 37.000                             \n",
            "Episode: 1, Avg. Reward: 38116.052, # of orders: 36.500                             \n",
            "Episode: 2, Avg. Reward: 24308.262, # of orders: 41.000                             \n",
            "Episode: 3, Avg. Reward: 68749.741, # of orders: 41.250                             \n",
            "Episode: 4, Avg. Reward: 56745.461, # of orders: 40.600                             \n",
            "Episode: 5, Avg. Reward: 49560.955, # of orders: 40.833                             \n",
            "Episode: 6, Avg. Reward: 57232.476, # of orders: 41.143                             \n",
            "Episode: 7, Avg. Reward: 38151.422, # of orders: 40.500                             \n",
            "Episode: 8, Avg. Reward: 48006.563, # of orders: 41.556                             \n",
            "Episode: 9, Avg. Reward: 30583.519, # of orders: 41.400                             \n",
            "Min. Reward          : -126223.872                                                  \n",
            "Avg. Reward          :  30583.519                                                   \n",
            "Max. Reward          : 202074.179                                                   \n",
            "Min. Orders          :     36.000                                                   \n",
            "Avg. Orders          :     41.400                                                   \n",
            "Max. Orders          :     50.000                                                   \n",
            "length of training env time points: 88173,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------     \n",
            "entropy: 0.007037820674746703, learning rate: 0.007931921633654674                   \n",
            "Episode: 0, Avg. Reward: -4692.342, # of orders: 15.000                              \n",
            "Episode: 1, Avg. Reward: 3800.133, # of orders: 14.500                               \n",
            "Episode: 2, Avg. Reward: -2677.879, # of orders: 16.333                              \n",
            "Episode: 3, Avg. Reward: 13505.841, # of orders: 16.750                              \n",
            "Episode: 4, Avg. Reward: 13755.723, # of orders: 16.800                              \n",
            "Episode: 5, Avg. Reward: 11410.156, # of orders: 15.833                              \n",
            "Episode: 6, Avg. Reward: 11597.836, # of orders: 16.429                              \n",
            "Episode: 7, Avg. Reward: 7960.316, # of orders: 16.750                               \n",
            "Episode: 8, Avg. Reward: 9137.437, # of orders: 17.556                               \n",
            "Episode: 9, Avg. Reward: 7542.177, # of orders: 17.400                               \n",
            "Min. Reward          : -17502.318                                                    \n",
            "Avg. Reward          :   7542.177                                                    \n",
            "Max. Reward          :  62057.000                                                    \n",
            "Min. Orders          :     11.000                                                    \n",
            "Avg. Orders          :     17.400                                                    \n",
            "Max. Orders          :     24.000                                                    \n",
            "length of training env time points: 88173,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------     \n",
            "entropy: 0.006773691856536071, learning rate: 0.007902157485847267                   \n",
            "Episode: 0, Avg. Reward: -47485.487, # of orders: 26.000                             \n",
            "Episode: 1, Avg. Reward: -80612.915, # of orders: 23.500                             \n",
            "Episode: 2, Avg. Reward: -83964.490, # of orders: 27.000                             \n",
            "Episode: 3, Avg. Reward: -97742.813, # of orders: 25.500                             \n",
            "Episode: 4, Avg. Reward: -90006.607, # of orders: 25.600                             \n",
            "Episode: 5, Avg. Reward: -83897.044, # of orders: 26.167                             \n",
            "Episode: 6, Avg. Reward: -83886.895, # of orders: 26.286                             \n",
            "Episode: 7, Avg. Reward: -76017.330, # of orders: 26.375                             \n",
            "Episode: 8, Avg. Reward: -71407.598, # of orders: 26.889                             \n",
            "Episode: 9, Avg. Reward: -71657.219, # of orders: 27.400                             \n",
            "Min. Reward          : -139077.782                                                   \n",
            "Avg. Reward          : -71657.219                                                    \n",
            "Max. Reward          : -20930.375                                                    \n",
            "Min. Orders          :     21.000                                                    \n",
            "Avg. Orders          :     27.400                                                    \n",
            "Max. Orders          :     34.000                                                    \n",
            "Entropy too high: 0.4838291085031609                                                 \n",
            "length of training env time points: 88173,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------     \n",
            "entropy: 0.008115236783712095, learning rate: 0.010107543361633902                   \n",
            "Episode: 0, Avg. Reward: -24760.231, # of orders: 73.000                             \n",
            "Episode: 1, Avg. Reward: -4766.731, # of orders: 73.000                              \n",
            "Episode: 2, Avg. Reward: 13919.911, # of orders: 75.667                              \n",
            "Episode: 3, Avg. Reward: 20793.737, # of orders: 74.500                              \n",
            "Episode: 4, Avg. Reward: 18557.023, # of orders: 75.200                              \n",
            "Episode: 5, Avg. Reward: 22212.153, # of orders: 73.833                              \n",
            "Episode: 6, Avg. Reward: 24027.391, # of orders: 73.429                              \n",
            "Episode: 7, Avg. Reward: 23112.436, # of orders: 73.750                              \n",
            "Episode: 8, Avg. Reward: 22470.464, # of orders: 74.222                              \n",
            "Episode: 9, Avg. Reward: 20122.022, # of orders: 73.900                              \n",
            "Min. Reward          : -24760.231                                                    \n",
            "Avg. Reward          :  20122.022                                                    \n",
            "Max. Reward          :  51293.196                                                    \n",
            "Min. Orders          :     67.000                                                    \n",
            "Avg. Orders          :     73.900                                                    \n",
            "Max. Orders          :     81.000                                                    \n",
            "Entropy too high: 0.3085357354780383                                                 \n",
            "length of training env time points: 88173,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------     \n",
            "entropy: 0.031073855159468627, learning rate: 0.013256566765810374                   \n",
            "Episode: 0, Avg. Reward: -35929.156, # of orders: 46.000                             \n",
            "Episode: 1, Avg. Reward: -71982.850, # of orders: 44.500                             \n",
            "Episode: 2, Avg. Reward: -56375.820, # of orders: 49.000                             \n",
            "Episode: 3, Avg. Reward: -13967.781, # of orders: 49.250                             \n",
            "Episode: 4, Avg. Reward: -30642.992, # of orders: 46.800                             \n",
            "Episode: 5, Avg. Reward: -43177.201, # of orders: 45.333                             \n",
            "Episode: 6, Avg. Reward: -52979.278, # of orders: 44.286                             \n",
            "Episode: 7, Avg. Reward: -54231.095, # of orders: 45.250                             \n",
            "Episode: 8, Avg. Reward: -41954.583, # of orders: 46.556                             \n",
            "Episode: 9, Avg. Reward: -51239.331, # of orders: 44.700                             \n",
            "Min. Reward          : -134802.065                                                   \n",
            "Avg. Reward          : -51239.331                                                    \n",
            "Max. Reward          : 113256.336                                                    \n",
            "Min. Orders          :     28.000                                                    \n",
            "Avg. Orders          :     44.700                                                    \n",
            "Max. Orders          :     58.000                                                    \n",
            "length of training env time points: 88173,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------     \n",
            "entropy: 0.0128443515874318, learning rate: 0.006841526474704151                     \n",
            "Episode: 0, Avg. Reward: -98170.453, # of orders: 55.000                             \n",
            "Episode: 1, Avg. Reward: -60365.935, # of orders: 59.000                             \n",
            "Episode: 2, Avg. Reward: -33752.369, # of orders: 60.667                             \n",
            "Episode: 3, Avg. Reward: 22639.534, # of orders: 61.500                              \n",
            "Episode: 4, Avg. Reward: -19097.535, # of orders: 56.000                             \n",
            "Episode: 5, Avg. Reward: -24646.069, # of orders: 56.333                             \n",
            "Episode: 6, Avg. Reward: -28319.272, # of orders: 56.857                             \n",
            "Episode: 7, Avg. Reward: -41672.634, # of orders: 56.375                             \n",
            "Episode: 8, Avg. Reward: -25336.434, # of orders: 57.778                             \n",
            "Episode: 9, Avg. Reward: -31814.771, # of orders: 57.100                             \n",
            "Min. Reward          : -186045.812                                                   \n",
            "Avg. Reward          : -31814.771                                                    \n",
            "Max. Reward          : 191815.242                                                    \n",
            "Min. Orders          :     34.000                                                    \n",
            "Avg. Orders          :     57.100                                                    \n",
            "Max. Orders          :     69.000                                                    \n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [2:33:29<00:00, 184.19s/trial, best loss: -30583.519426987146]\n",
            "Best parameters: {'ent_coef': 0.008946461117332492, 'learning_rate': 0.008272790052640817}\n",
            "Learning rate too high: 0.06142381168267034           \n",
            "length of training env time points: 88053,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------\n",
            "entropy: 0.02731211536534503, learning rate: 0.04028912298981056\n",
            "Episode: 0, Avg. Reward: 27616.046, # of orders: 40.000       \n",
            "Episode: 1, Avg. Reward: -32597.394, # of orders: 39.000         \n",
            "Episode: 2, Avg. Reward: -15924.327, # of orders: 40.667         \n",
            "Episode: 3, Avg. Reward: -37814.185, # of orders: 35.750         \n",
            "Episode: 4, Avg. Reward: -49523.302, # of orders: 35.600         \n",
            "Episode: 5, Avg. Reward: -55057.476, # of orders: 35.833         \n",
            "Episode: 6, Avg. Reward: -36037.708, # of orders: 37.000         \n",
            "Episode: 7, Avg. Reward: -45055.896, # of orders: 35.625         \n",
            "Episode: 8, Avg. Reward: -37191.915, # of orders: 36.111         \n",
            "Episode: 9, Avg. Reward: -31397.969, # of orders: 36.500         \n",
            "Min. Reward          : -108183.211                               \n",
            "Avg. Reward          : -31397.969                                \n",
            "Max. Reward          :  78080.900                                \n",
            "Min. Orders          :     21.000                                \n",
            "Avg. Orders          :     36.500                                \n",
            "Max. Orders          :     44.000                                \n",
            "length of training env time points: 88053,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------   \n",
            "entropy: 0.016984687866576233, learning rate: 0.029007519418527063                 \n",
            "Episode: 0, Avg. Reward: 15270.778, # of orders: 35.000                            \n",
            "Episode: 1, Avg. Reward: -37912.251, # of orders: 32.000                           \n",
            "Episode: 2, Avg. Reward: -14764.511, # of orders: 36.000                           \n",
            "Episode: 3, Avg. Reward: -36891.617, # of orders: 32.250                           \n",
            "Episode: 4, Avg. Reward: -50220.673, # of orders: 32.600                           \n",
            "Episode: 5, Avg. Reward: -55589.575, # of orders: 33.000                           \n",
            "Episode: 6, Avg. Reward: -39692.735, # of orders: 34.000                           \n",
            "Episode: 7, Avg. Reward: -46481.537, # of orders: 32.375                           \n",
            "Episode: 8, Avg. Reward: -39346.818, # of orders: 33.000                           \n",
            "Episode: 9, Avg. Reward: -33847.706, # of orders: 33.500                           \n",
            "Min. Reward          : -103536.896                                                 \n",
            "Avg. Reward          : -33847.706                                                  \n",
            "Max. Reward          :  55688.305                                                  \n",
            "Min. Orders          :     21.000                                                  \n",
            "Avg. Orders          :     33.500                                                  \n",
            "Max. Orders          :     44.000                                                  \n",
            "length of training env time points: 88053,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------   \n",
            "entropy: 0.03304654468039319, learning rate: 0.014146072684216858                  \n",
            "Episode: 0, Avg. Reward: 18481.756, # of orders: 37.000                            \n",
            "Episode: 1, Avg. Reward: -36361.780, # of orders: 35.500                           \n",
            "Episode: 2, Avg. Reward: -21785.136, # of orders: 38.000                           \n",
            "Episode: 3, Avg. Reward: -42041.252, # of orders: 34.000                           \n",
            "Episode: 4, Avg. Reward: -51894.778, # of orders: 33.800                           \n",
            "Episode: 5, Avg. Reward: -58483.554, # of orders: 34.167                           \n",
            "Episode: 6, Avg. Reward: -37213.054, # of orders: 35.429                           \n",
            "Episode: 7, Avg. Reward: -46301.051, # of orders: 34.250                           \n",
            "Episode: 8, Avg. Reward: -38440.117, # of orders: 34.889                           \n",
            "Episode: 9, Avg. Reward: -32622.247, # of orders: 35.100                           \n",
            "Min. Reward          : -109917.036                                                 \n",
            "Avg. Reward          : -32622.247                                                  \n",
            "Max. Reward          :  90409.949                                                  \n",
            "Min. Orders          :     22.000                                                  \n",
            "Avg. Orders          :     35.100                                                  \n",
            "Max. Orders          :     43.000                                                  \n",
            "length of training env time points: 88053,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------   \n",
            "entropy: 0.007932959925409879, learning rate: 0.022353821229549826                 \n",
            "Episode: 0, Avg. Reward: 2144.457, # of orders: 29.000                             \n",
            "Episode: 1, Avg. Reward: 4733.042, # of orders: 27.500                             \n",
            "Episode: 2, Avg. Reward: -1776.670, # of orders: 31.333                            \n",
            "Episode: 3, Avg. Reward: 165.109, # of orders: 30.250                              \n",
            "Episode: 4, Avg. Reward: 2943.740, # of orders: 30.600                             \n",
            "Episode: 5, Avg. Reward: -1079.880, # of orders: 30.667                            \n",
            "Episode: 6, Avg. Reward: 837.210, # of orders: 31.286                              \n",
            "Episode: 7, Avg. Reward: -3748.536, # of orders: 31.000                            \n",
            "Episode: 8, Avg. Reward: -2387.665, # of orders: 31.333                            \n",
            "Episode: 9, Avg. Reward: 1202.687, # of orders: 32.000                             \n",
            "Min. Reward          : -35848.756                                                  \n",
            "Avg. Reward          :   1202.687                                                  \n",
            "Max. Reward          :  33515.848                                                  \n",
            "Min. Orders          :     26.000                                                  \n",
            "Avg. Orders          :     32.000                                                  \n",
            "Max. Orders          :     39.000                                                  \n",
            "length of training env time points: 88053,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.07587712830141301, learning rate: 0.010232157898508317                   \n",
            "Episode: 0, Avg. Reward: 24834.661, # of orders: 39.000                             \n",
            "Episode: 1, Avg. Reward: -33214.248, # of orders: 36.500                            \n",
            "Episode: 2, Avg. Reward: -16627.887, # of orders: 39.000                            \n",
            "Episode: 3, Avg. Reward: -38236.665, # of orders: 34.500                            \n",
            "Episode: 4, Avg. Reward: -49340.869, # of orders: 34.600                            \n",
            "Episode: 5, Avg. Reward: -55292.165, # of orders: 35.000                            \n",
            "Episode: 6, Avg. Reward: -35927.998, # of orders: 36.000                            \n",
            "Episode: 7, Avg. Reward: -45277.915, # of orders: 34.750                            \n",
            "Episode: 8, Avg. Reward: -37435.064, # of orders: 35.333                            \n",
            "Episode: 9, Avg. Reward: -31832.715, # of orders: 35.700                            \n",
            "Min. Reward          : -110727.339                                                  \n",
            "Avg. Reward          : -31832.715                                                   \n",
            "Max. Reward          :  80257.005                                                   \n",
            "Min. Orders          :     21.000                                                   \n",
            "Avg. Orders          :     35.700                                                   \n",
            "Max. Orders          :     44.000                                                   \n",
            "Entropy too high: 0.10448407975107651                                               \n",
            "Learning rate too high: 0.12239906392891105                                         \n",
            "length of training env time points: 88053,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.07468261698602414, learning rate: 0.010969850405350414                   \n",
            "Episode: 0, Avg. Reward: -64342.818, # of orders: 42.000                            \n",
            "Episode: 1, Avg. Reward: -45156.230, # of orders: 38.500                            \n",
            "Episode: 2, Avg. Reward: -24782.435, # of orders: 44.000                            \n",
            "Episode: 3, Avg. Reward: -11078.751, # of orders: 44.000                            \n",
            "Episode: 4, Avg. Reward: -13892.095, # of orders: 42.800                            \n",
            "Episode: 5, Avg. Reward: -27147.217, # of orders: 42.667                            \n",
            "Episode: 6, Avg. Reward: -21398.509, # of orders: 43.143                            \n",
            "Episode: 7, Avg. Reward: -30457.325, # of orders: 42.750                            \n",
            "Episode: 8, Avg. Reward: -20869.915, # of orders: 43.444                            \n",
            "Episode: 9, Avg. Reward: -13457.188, # of orders: 44.000                            \n",
            "Min. Reward          : -93869.040                                                   \n",
            "Avg. Reward          : -13457.188                                                   \n",
            "Max. Reward          :  55829.371                                                   \n",
            "Min. Orders          :     35.000                                                   \n",
            "Avg. Orders          :     44.000                                                   \n",
            "Max. Orders          :     55.000                                                   \n",
            "Learning rate too high: 0.05899643732616617                                         \n",
            "Entropy too high: 0.6752121630692484                                                \n",
            "length of training env time points: 88053,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------     \n",
            "entropy: 0.011647879517814432, learning rate: 0.031079889879345582                   \n",
            "Episode: 0, Avg. Reward: -38588.366, # of orders: 40.000                             \n",
            "Episode: 1, Avg. Reward: -53622.177, # of orders: 41.000                             \n",
            "Episode: 2, Avg. Reward: -44032.888, # of orders: 47.000                             \n",
            "Episode: 3, Avg. Reward: -39846.715, # of orders: 46.250                             \n",
            "Episode: 4, Avg. Reward: -50740.724, # of orders: 44.600                             \n",
            "Episode: 5, Avg. Reward: -58223.849, # of orders: 43.833                             \n",
            "Episode: 6, Avg. Reward: -50535.166, # of orders: 43.857                             \n",
            "Episode: 7, Avg. Reward: -57895.704, # of orders: 42.375                             \n",
            "Episode: 8, Avg. Reward: -49839.803, # of orders: 43.111                             \n",
            "Episode: 9, Avg. Reward: -38894.822, # of orders: 43.700                             \n",
            "Min. Reward          : -109419.470                                                   \n",
            "Avg. Reward          : -38894.822                                                    \n",
            "Max. Reward          :  59610.001                                                    \n",
            "Min. Orders          :     32.000                                                    \n",
            "Avg. Orders          :     43.700                                                    \n",
            "Max. Orders          :     59.000                                                    \n",
            "Entropy too high: 0.4149018314147279                                                 \n",
            "Learning rate too high: 0.05492056817505721                                          \n",
            "Entropy too high: 0.45431764747887504                                                \n",
            "Learning rate too high: 0.11524463002481725                                          \n",
            "length of training env time points: 88053,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------     \n",
            "entropy: 0.023981345216910917, learning rate: 0.030920627700752278                   \n",
            "Episode: 0, Avg. Reward: -3131.554, # of orders: 34.000                              \n",
            "Episode: 1, Avg. Reward: -48751.142, # of orders: 30.000                             \n",
            "Episode: 2, Avg. Reward: -45044.832, # of orders: 32.000                             \n",
            "Episode: 3, Avg. Reward: -57837.842, # of orders: 30.750                             \n",
            "Episode: 4, Avg. Reward: -56348.532, # of orders: 32.000                             \n",
            "Episode: 5, Avg. Reward: -61874.241, # of orders: 33.000                             \n",
            "Episode: 6, Avg. Reward: -48368.453, # of orders: 33.286                             \n",
            "Episode: 7, Avg. Reward: -57425.103, # of orders: 32.500                             \n",
            "Episode: 8, Avg. Reward: -46863.494, # of orders: 33.111                             \n",
            "Episode: 9, Avg. Reward: -40587.647, # of orders: 33.400                             \n",
            "Min. Reward          : -120821.658                                                   \n",
            "Avg. Reward          : -40587.647                                                    \n",
            "Max. Reward          :  37629.383                                                    \n",
            "Min. Orders          :     26.000                                                    \n",
            "Avg. Orders          :     33.400                                                    \n",
            "Max. Orders          :     38.000                                                    \n",
            "Learning rate too high: 0.0891103184179578                                           \n",
            "Learning rate too high: 0.0814841999289755                                           \n",
            "length of training env time points: 88053,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------   \n",
            "entropy: 0.015453368907991507, learning rate: 0.034766114649727106                 \n",
            "Episode: 0, Avg. Reward: 14405.115, # of orders: 60.000                            \n",
            "Episode: 1, Avg. Reward: 6816.154, # of orders: 60.000                             \n",
            "Episode: 2, Avg. Reward: -11450.793, # of orders: 63.000                           \n",
            "Episode: 3, Avg. Reward: -12816.189, # of orders: 61.750                           \n",
            "Episode: 4, Avg. Reward: -11578.063, # of orders: 62.400                           \n",
            "Episode: 5, Avg. Reward: -20535.144, # of orders: 62.000                           \n",
            "Episode: 6, Avg. Reward: -16368.356, # of orders: 61.571                           \n",
            "Episode: 7, Avg. Reward: -27592.310, # of orders: 61.125                           \n",
            "Episode: 8, Avg. Reward: -23097.144, # of orders: 61.444                           \n",
            "Episode: 9, Avg. Reward: -17250.500, # of orders: 61.300                           \n",
            "Min. Reward          : -106159.987                                                 \n",
            "Avg. Reward          : -17250.500                                                  \n",
            "Max. Reward          :  35369.287                                                  \n",
            "Min. Orders          :     58.000                                                  \n",
            "Avg. Orders          :     61.300                                                  \n",
            "Max. Orders          :     69.000                                                  \n",
            "length of training env time points: 88053,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------   \n",
            "entropy: 0.062804619124296, learning rate: 0.00714873012300586                     \n",
            "Episode: 0, Avg. Reward: 25420.987, # of orders: 39.000                            \n",
            "Episode: 1, Avg. Reward: -33675.230, # of orders: 38.000                           \n",
            "Episode: 2, Avg. Reward: -16590.376, # of orders: 40.667                           \n",
            "Episode: 3, Avg. Reward: -39041.384, # of orders: 35.750                           \n",
            "Episode: 4, Avg. Reward: -50116.632, # of orders: 35.600                           \n",
            "Episode: 5, Avg. Reward: -56981.920, # of orders: 35.667                           \n",
            "Episode: 6, Avg. Reward: -36855.737, # of orders: 36.571                           \n",
            "Episode: 7, Avg. Reward: -45873.532, # of orders: 35.250                           \n",
            "Episode: 8, Avg. Reward: -38195.174, # of orders: 35.778                           \n",
            "Episode: 9, Avg. Reward: -33104.155, # of orders: 35.900                           \n",
            "Min. Reward          : -108998.095                                                 \n",
            "Avg. Reward          : -33104.155                                                  \n",
            "Max. Reward          :  83901.361                                                  \n",
            "Min. Orders          :     21.000                                                  \n",
            "Avg. Orders          :     35.900                                                  \n",
            "Max. Orders          :     46.000                                                  \n",
            "length of training env time points: 88053,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------     \n",
            "entropy: 0.05325745521465026, learning rate: 0.013084062145801852                    \n",
            "Episode: 0, Avg. Reward: 25104.160, # of orders: 39.000                              \n",
            "Episode: 1, Avg. Reward: -37438.253, # of orders: 35.500                               \n",
            "Episode: 2, Avg. Reward: -19065.898, # of orders: 39.333                               \n",
            "Episode: 3, Avg. Reward: -25039.917, # of orders: 40.250                               \n",
            "Episode: 4, Avg. Reward: -38903.162, # of orders: 39.400                               \n",
            "Episode: 5, Avg. Reward: -48931.502, # of orders: 39.000                               \n",
            "Episode: 6, Avg. Reward: -36813.605, # of orders: 38.714                               \n",
            "Episode: 7, Avg. Reward: -46208.414, # of orders: 37.375                               \n",
            "Episode: 8, Avg. Reward: -39199.271, # of orders: 37.444                               \n",
            "Episode: 9, Avg. Reward: -31422.447, # of orders: 37.900                               \n",
            "Min. Reward          : -111972.077                                                     \n",
            "Avg. Reward          : -31422.447                                                      \n",
            "Max. Reward          :  38568.965                                                      \n",
            "Min. Orders          :     28.000                                                      \n",
            "Avg. Orders          :     37.900                                                      \n",
            "Max. Orders          :     47.000                                                      \n",
            "Entropy too high: 0.1246913489514122                                                   \n",
            "length of training env time points: 88053,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------       \n",
            "entropy: 0.04218233150243728, learning rate: 0.009305781567214694                      \n",
            "Episode: 0, Avg. Reward: 13823.214, # of orders: 36.000                                \n",
            "Episode: 1, Avg. Reward: -42943.582, # of orders: 34.000                               \n",
            "Episode: 2, Avg. Reward: -20744.581, # of orders: 40.333                               \n",
            "Episode: 3, Avg. Reward: -33991.368, # of orders: 40.500                               \n",
            "Episode: 4, Avg. Reward: -45670.765, # of orders: 39.200                               \n",
            "Episode: 5, Avg. Reward: -52733.110, # of orders: 38.833                               \n",
            "Episode: 6, Avg. Reward: -30315.865, # of orders: 39.429                               \n",
            "Episode: 7, Avg. Reward: -38259.932, # of orders: 38.750                               \n",
            "Episode: 8, Avg. Reward: -31225.354, # of orders: 39.000                               \n",
            "Episode: 9, Avg. Reward: -25393.263, # of orders: 38.800                               \n",
            "Min. Reward          : -99710.379                                                      \n",
            "Avg. Reward          : -25393.263                                                      \n",
            "Max. Reward          : 104187.606                                                      \n",
            "Min. Orders          :     32.000                                                      \n",
            "Avg. Orders          :     38.800                                                      \n",
            "Max. Orders          :     53.000                                                      \n",
            "length of training env time points: 88053,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------       \n",
            "entropy: 0.006747513027642891, learning rate: 0.01565759749337945                      \n",
            "Episode: 0, Avg. Reward: 28212.178, # of orders: 32.000                                \n",
            "Episode: 1, Avg. Reward: -25467.574, # of orders: 29.500                               \n",
            "Episode: 2, Avg. Reward: -12591.578, # of orders: 33.000                               \n",
            "Episode: 3, Avg. Reward: -33059.560, # of orders: 29.750                               \n",
            "Episode: 4, Avg. Reward: -44876.499, # of orders: 29.600                               \n",
            "Episode: 5, Avg. Reward: -52547.839, # of orders: 30.500                               \n",
            "Episode: 6, Avg. Reward: -39017.583, # of orders: 30.000                               \n",
            "Episode: 7, Avg. Reward: -46633.984, # of orders: 28.625                               \n",
            "Episode: 8, Avg. Reward: -41594.768, # of orders: 28.556                               \n",
            "Episode: 9, Avg. Reward: -27819.289, # of orders: 30.400                               \n",
            "Min. Reward          : -99948.789                                                      \n",
            "Avg. Reward          : -27819.289                                                      \n",
            "Max. Reward          :  96160.025                                                      \n",
            "Min. Orders          :     19.000                                                      \n",
            "Avg. Orders          :     30.400                                                      \n",
            "Max. Orders          :     47.000                                                      \n",
            "Entropy too high: 0.18814709427318366                                                  \n",
            "Entropy too high: 0.3365182639548108                                                   \n",
            "length of training env time points: 88053,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------       \n",
            "entropy: 0.03912176500894859, learning rate: 0.011949731259619555                      \n",
            "Episode: 0, Avg. Reward: -2573.747, # of orders: 39.000                                \n",
            "Episode: 1, Avg. Reward: -24866.861, # of orders: 39.500                               \n",
            "Episode: 2, Avg. Reward: -10582.381, # of orders: 43.667                               \n",
            "Episode: 3, Avg. Reward: -298.248, # of orders: 43.750                                 \n",
            "Episode: 4, Avg. Reward: -4501.581, # of orders: 43.400                                \n",
            "Episode: 5, Avg. Reward: -21888.038, # of orders: 43.000                               \n",
            "Episode: 6, Avg. Reward: -4399.517, # of orders: 43.286                                \n",
            "Episode: 7, Avg. Reward: -12713.673, # of orders: 44.000                               \n",
            "Episode: 8, Avg. Reward: -5574.686, # of orders: 44.111                                \n",
            "Episode: 9, Avg. Reward: 5304.713, # of orders: 44.600                                 \n",
            "Min. Reward          : -108820.323                                                     \n",
            "Avg. Reward          :   5304.713                                                      \n",
            "Max. Reward          : 103219.303                                                      \n",
            "Min. Orders          :     39.000                                                      \n",
            "Avg. Orders          :     44.600                                                      \n",
            "Max. Orders          :     52.000                                                      \n",
            "length of training env time points: 88053,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------  \n",
            "entropy: 0.006969046571068815, learning rate: 0.044261215487165564                \n",
            "Episode: 0, Avg. Reward: -27077.389, # of orders: 46.000                          \n",
            "Episode: 1, Avg. Reward: -43325.881, # of orders: 46.500                          \n",
            "Episode: 2, Avg. Reward: -39982.281, # of orders: 51.667                          \n",
            "Episode: 3, Avg. Reward: -20933.027, # of orders: 51.250                          \n",
            "Episode: 4, Avg. Reward: -23149.746, # of orders: 50.600                          \n",
            "Episode: 5, Avg. Reward: -31565.604, # of orders: 49.667                          \n",
            "Episode: 6, Avg. Reward: -30056.783, # of orders: 50.000                          \n",
            "Episode: 7, Avg. Reward: -39566.808, # of orders: 49.875                          \n",
            "Episode: 8, Avg. Reward: -34646.347, # of orders: 50.222                          \n",
            "Episode: 9, Avg. Reward: -27704.749, # of orders: 50.100                          \n",
            "Min. Reward          : -106136.978                                                \n",
            "Avg. Reward          : -27704.749                                                 \n",
            "Max. Reward          :  36214.734                                                 \n",
            "Min. Orders          :     45.000                                                 \n",
            "Avg. Orders          :     50.100                                                 \n",
            "Max. Orders          :     62.000                                                 \n",
            "length of training env time points: 88053,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.013865833626414796, learning rate: 0.019267202165229265                  \n",
            "Episode: 0, Avg. Reward: 3899.067, # of orders: 33.000                              \n",
            "Episode: 1, Avg. Reward: -47400.535, # of orders: 31.000                            \n",
            "Episode: 2, Avg. Reward: -71966.810, # of orders: 28.333                            \n",
            "Episode: 3, Avg. Reward: -68594.064, # of orders: 29.750                            \n",
            "Episode: 4, Avg. Reward: -48954.671, # of orders: 33.200                            \n",
            "Episode: 5, Avg. Reward: -54417.012, # of orders: 33.833                            \n",
            "Episode: 6, Avg. Reward: -38759.833, # of orders: 34.286                            \n",
            "Episode: 7, Avg. Reward: -46137.945, # of orders: 33.250                            \n",
            "Episode: 8, Avg. Reward: -35066.674, # of orders: 34.000                            \n",
            "Episode: 9, Avg. Reward: -28903.795, # of orders: 34.400                            \n",
            "Min. Reward          : -121099.361                                                  \n",
            "Avg. Reward          : -28903.795                                                   \n",
            "Max. Reward          :  55183.243                                                   \n",
            "Min. Orders          :     23.000                                                   \n",
            "Avg. Orders          :     34.400                                                   \n",
            "Max. Orders          :     47.000                                                   \n",
            "length of training env time points: 88053,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.010573817131509053, learning rate: 0.007796447877890481                  \n",
            "Episode: 0, Avg. Reward: 0.000, # of orders: 0.000                                  \n",
            "Episode: 1, Avg. Reward: 0.000, # of orders: 0.000                                  \n",
            "Episode: 2, Avg. Reward: -137.332, # of orders: 0.333                               \n",
            "Episode: 3, Avg. Reward: -113.411, # of orders: 0.500                               \n",
            "Episode: 4, Avg. Reward: -90.729, # of orders: 0.400                                \n",
            "Episode: 5, Avg. Reward: -75.608, # of orders: 0.333                                \n",
            "Episode: 6, Avg. Reward: -1287.971, # of orders: 0.571                              \n",
            "Episode: 7, Avg. Reward: -1126.975, # of orders: 0.500                              \n",
            "Episode: 8, Avg. Reward: -1001.755, # of orders: 0.444                              \n",
            "Episode: 9, Avg. Reward: -701.881, # of orders: 0.600                               \n",
            "Min. Reward          :  -8562.154                                                   \n",
            "Avg. Reward          :   -701.881                                                   \n",
            "Max. Reward          :   1996.987                                                   \n",
            "Min. Orders          :      0.000                                                   \n",
            "Avg. Orders          :      0.600                                                   \n",
            "Max. Orders          :      2.000                                                   \n",
            "length of training env time points: 88053,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.04054710411237531, learning rate: 0.04629042302967578                    \n",
            "there was an error with those parameters: timesteps: 50,                            \n",
            "\n",
            "              ent_coef: 0.04054710411237531, gamma: 0.99, learning_rate: 0.04629042302967578\n",
            "Entropy too high: 0.13087670544737273                                               \n",
            "length of training env time points: 88053,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.018794601624451752, learning rate: 0.016835273638875447                  \n",
            "Episode: 0, Avg. Reward: 37092.612, # of orders: 54.000                             \n",
            "Episode: 1, Avg. Reward: 52433.976, # of orders: 43.500                             \n",
            "Episode: 2, Avg. Reward: 12722.135, # of orders: 40.000                             \n",
            "Episode: 3, Avg. Reward: 8670.238, # of orders: 41.500                              \n",
            "Episode: 4, Avg. Reward: 42777.207, # of orders: 46.000                             \n",
            "Episode: 5, Avg. Reward: 29947.816, # of orders: 45.333                             \n",
            "Episode: 6, Avg. Reward: 44593.354, # of orders: 48.429                             \n",
            "Episode: 7, Avg. Reward: 37941.825, # of orders: 45.500                             \n",
            "Episode: 8, Avg. Reward: 38951.443, # of orders: 48.333                             \n",
            "Episode: 9, Avg. Reward: 29072.220, # of orders: 47.400                             \n",
            "Min. Reward          : -66701.548                                                   \n",
            "Avg. Reward          :  29072.220                                                   \n",
            "Max. Reward          : 179205.082                                                   \n",
            "Min. Orders          :     25.000                                                   \n",
            "Avg. Orders          :     47.400                                                   \n",
            "Max. Orders          :     71.000                                                   \n",
            "length of training env time points: 88053,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------     \n",
            "entropy: 0.030735050996141516, learning rate: 0.008252954154140232                   \n",
            "Episode: 0, Avg. Reward: -4232.180, # of orders: 61.000                              \n",
            "Episode: 1, Avg. Reward: -4679.146, # of orders: 59.500                              \n",
            "Episode: 2, Avg. Reward: -12190.692, # of orders: 63.333                             \n",
            "Episode: 3, Avg. Reward: -7959.721, # of orders: 62.250                              \n",
            "Episode: 4, Avg. Reward: -8404.313, # of orders: 63.400                              \n",
            "Episode: 5, Avg. Reward: -9143.885, # of orders: 62.667                              \n",
            "Episode: 6, Avg. Reward: -8483.505, # of orders: 62.000                              \n",
            "Episode: 7, Avg. Reward: -11105.390, # of orders: 61.750                             \n",
            "Episode: 8, Avg. Reward: -9652.325, # of orders: 61.889                              \n",
            "Episode: 9, Avg. Reward: -7965.397, # of orders: 61.800                              \n",
            "Min. Reward          : -29458.583                                                    \n",
            "Avg. Reward          :  -7965.397                                                    \n",
            "Max. Reward          :   7216.950                                                    \n",
            "Min. Orders          :     58.000                                                    \n",
            "Avg. Orders          :     61.800                                                    \n",
            "Max. Orders          :     71.000                                                    \n",
            "length of training env time points: 88053,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------     \n",
            "entropy: 0.04392015473339439, learning rate: 0.017037893010288244                    \n",
            "Episode: 0, Avg. Reward: 3946.795, # of orders: 40.000                               \n",
            "Episode: 1, Avg. Reward: -28331.807, # of orders: 41.500                             \n",
            "Episode: 2, Avg. Reward: -18519.507, # of orders: 47.000                             \n",
            "Episode: 3, Avg. Reward: -4767.064, # of orders: 47.250                              \n",
            "Episode: 4, Avg. Reward: -244.005, # of orders: 47.200                               \n",
            "Episode: 5, Avg. Reward: -16749.598, # of orders: 46.500                             \n",
            "Episode: 6, Avg. Reward: -2387.832, # of orders: 46.571                              \n",
            "Episode: 7, Avg. Reward: -17023.750, # of orders: 44.875                             \n",
            "Episode: 8, Avg. Reward: -11628.827, # of orders: 45.333                             \n",
            "Episode: 9, Avg. Reward: -4100.112, # of orders: 45.600                              \n",
            "Min. Reward          : -119475.175                                                   \n",
            "Avg. Reward          :  -4100.112                                                    \n",
            "Max. Reward          :  83782.763                                                    \n",
            "Min. Orders          :     33.000                                                    \n",
            "Avg. Orders          :     45.600                                                    \n",
            "Max. Orders          :     58.000                                                    \n",
            "length of training env time points: 88053,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------       \n",
            "entropy: 0.01941218702496326, learning rate: 0.011584592452858417                      \n",
            "Episode: 0, Avg. Reward: -1727.883, # of orders: 38.000                                \n",
            "Episode: 1, Avg. Reward: -13136.175, # of orders: 39.500                               \n",
            "Episode: 2, Avg. Reward: -15762.560, # of orders: 44.667                               \n",
            "Episode: 3, Avg. Reward: -10684.189, # of orders: 44.750                               \n",
            "Episode: 4, Avg. Reward: -8021.243, # of orders: 44.200                                \n",
            "Episode: 5, Avg. Reward: -18294.759, # of orders: 43.667                               \n",
            "Episode: 6, Avg. Reward: -12834.325, # of orders: 44.000                               \n",
            "Episode: 7, Avg. Reward: -25930.919, # of orders: 42.875                               \n",
            "Episode: 8, Avg. Reward: -21966.616, # of orders: 43.556                               \n",
            "Episode: 9, Avg. Reward: -16544.634, # of orders: 43.800                               \n",
            "Min. Reward          : -117607.082                                                     \n",
            "Avg. Reward          : -16544.634                                                      \n",
            "Max. Reward          :  32253.206                                                      \n",
            "Min. Orders          :     35.000                                                      \n",
            "Avg. Orders          :     43.800                                                      \n",
            "Max. Orders          :     55.000                                                      \n",
            "length of training env time points: 88053,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------       \n",
            "entropy: 0.09459367264700097, learning rate: 0.014286192539020925                      \n",
            "there was an error with those parameters: timesteps: 50,                               \n",
            "\n",
            "              ent_coef: 0.09459367264700097, gamma: 0.99, learning_rate: 0.014286192539020925\n",
            "length of training env time points: 88053,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------     \n",
            "entropy: 0.03141640687171352, learning rate: 0.025141918510508905                    \n",
            "Episode: 0, Avg. Reward: 23821.328, # of orders: 40.000                              \n",
            "Episode: 1, Avg. Reward: -37975.642, # of orders: 35.500                             \n",
            "Episode: 2, Avg. Reward: -22681.603, # of orders: 38.000                             \n",
            "Episode: 3, Avg. Reward: -43221.679, # of orders: 34.000                             \n",
            "Episode: 4, Avg. Reward: -54401.784, # of orders: 34.200                             \n",
            "Episode: 5, Avg. Reward: -60633.470, # of orders: 34.500                             \n",
            "Episode: 6, Avg. Reward: -36822.817, # of orders: 36.000                             \n",
            "Episode: 7, Avg. Reward: -45445.586, # of orders: 34.625                             \n",
            "Episode: 8, Avg. Reward: -38873.063, # of orders: 35.000                             \n",
            "Episode: 9, Avg. Reward: -33067.210, # of orders: 35.300                             \n",
            "Min. Reward          : -105804.969                                                   \n",
            "Avg. Reward          : -33067.210                                                    \n",
            "Max. Reward          : 106041.102                                                    \n",
            "Min. Orders          :     22.000                                                    \n",
            "Avg. Orders          :     35.300                                                    \n",
            "Max. Orders          :     45.000                                                    \n",
            "length of training env time points: 88053,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------     \n",
            "entropy: 0.06365491766158685, learning rate: 0.0274658028917094                      \n",
            "there was an error with those parameters: timesteps: 50,                             \n",
            "\n",
            "              ent_coef: 0.06365491766158685, gamma: 0.99, learning_rate: 0.0274658028917094\n",
            "length of training env time points: 88053,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------     \n",
            "entropy: 0.016586907230971323, learning rate: 0.03744963629561628                    \n",
            "Episode: 0, Avg. Reward: -80182.213, # of orders: 43.000                             \n",
            "Episode: 1, Avg. Reward: -59312.262, # of orders: 44.000                             \n",
            "Episode: 2, Avg. Reward: -48614.683, # of orders: 48.000                             \n",
            "Episode: 3, Avg. Reward: -46040.216, # of orders: 48.250                             \n",
            "Episode: 4, Avg. Reward: -40063.142, # of orders: 48.400                             \n",
            "Episode: 5, Avg. Reward: -49615.395, # of orders: 47.667                             \n",
            "Episode: 6, Avg. Reward: -38056.185, # of orders: 47.571                             \n",
            "Episode: 7, Avg. Reward: -47034.699, # of orders: 47.250                             \n",
            "Episode: 8, Avg. Reward: -36685.415, # of orders: 47.667                             \n",
            "Episode: 9, Avg. Reward: -28017.244, # of orders: 47.800                             \n",
            "Min. Reward          : -109884.294                                                   \n",
            "Avg. Reward          : -28017.244                                                    \n",
            "Max. Reward          :  49996.295                                                    \n",
            "Min. Orders          :     43.000                                                    \n",
            "Avg. Orders          :     47.800                                                    \n",
            "Max. Orders          :     56.000                                                    \n",
            "length of training env time points: 88053,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------     \n",
            "entropy: 0.012449289865508271, learning rate: 0.018974492900095275                   \n",
            "Episode: 0, Avg. Reward: 14292.349, # of orders: 31.000                              \n",
            "Episode: 1, Avg. Reward: -5124.952, # of orders: 30.500                              \n",
            "Episode: 2, Avg. Reward: 5655.764, # of orders: 36.667                               \n",
            "Episode: 3, Avg. Reward: -23584.484, # of orders: 32.250                             \n",
            "Episode: 4, Avg. Reward: -37896.748, # of orders: 31.400                             \n",
            "Episode: 5, Avg. Reward: -44309.439, # of orders: 31.833                             \n",
            "Episode: 6, Avg. Reward: -29435.568, # of orders: 33.000                             \n",
            "Episode: 7, Avg. Reward: -38385.984, # of orders: 32.375                             \n",
            "Episode: 8, Avg. Reward: -28571.149, # of orders: 32.889                             \n",
            "Episode: 9, Avg. Reward: -17710.367, # of orders: 34.200                             \n",
            "Min. Reward          : -111305.229                                                   \n",
            "Avg. Reward          : -17710.367                                                    \n",
            "Max. Reward          :  80036.669                                                    \n",
            "Min. Orders          :     19.000                                                    \n",
            "Avg. Orders          :     34.200                                                    \n",
            "Max. Orders          :     49.000                                                    \n",
            "Entropy too high: 0.1712727155585599                                                 \n",
            "length of training env time points: 88053,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------     \n",
            "entropy: 0.03518210987627296, learning rate: 0.01089605504736748                     \n",
            "Episode: 0, Avg. Reward: -6938.689, # of orders: 6.000                               \n",
            "Episode: 1, Avg. Reward: 5065.444, # of orders: 7.500                                \n",
            "Episode: 2, Avg. Reward: -6340.137, # of orders: 8.000                               \n",
            "Episode: 3, Avg. Reward: 896.587, # of orders: 7.750                                 \n",
            "Episode: 4, Avg. Reward: -4503.638, # of orders: 7.800                               \n",
            "Episode: 5, Avg. Reward: -3183.408, # of orders: 6.833                               \n",
            "Episode: 6, Avg. Reward: -5047.382, # of orders: 7.143                               \n",
            "Episode: 7, Avg. Reward: -5041.309, # of orders: 7.125                               \n",
            "Episode: 8, Avg. Reward: -959.631, # of orders: 7.778                                \n",
            "Episode: 9, Avg. Reward: 6.544, # of orders: 7.700                                   \n",
            "Min. Reward          : -29151.299                                                    \n",
            "Avg. Reward          :      6.544                                                    \n",
            "Max. Reward          :  31693.797                                                    \n",
            "Min. Orders          :      2.000                                                    \n",
            "Avg. Orders          :      7.700                                                    \n",
            "Max. Orders          :     13.000                                                    \n",
            "length of training env time points: 88053,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------     \n",
            "entropy: 0.053082525174159616, learning rate: 0.014446699357185053                   \n",
            "Episode: 0, Avg. Reward: 21161.243, # of orders: 37.000                              \n",
            "Episode: 1, Avg. Reward: -35389.697, # of orders: 37.000                             \n",
            "Episode: 2, Avg. Reward: -17513.035, # of orders: 39.667                             \n",
            "Episode: 3, Avg. Reward: -39059.980, # of orders: 35.000                             \n",
            "Episode: 4, Avg. Reward: -50250.645, # of orders: 35.000                             \n",
            "Episode: 5, Avg. Reward: -57413.962, # of orders: 35.333                             \n",
            "Episode: 6, Avg. Reward: -37492.634, # of orders: 36.286                             \n",
            "Episode: 7, Avg. Reward: -46500.939, # of orders: 35.000                             \n",
            "Episode: 8, Avg. Reward: -38646.512, # of orders: 35.556                             \n",
            "Episode: 9, Avg. Reward: -32377.931, # of orders: 36.300                             \n",
            "Min. Reward          : -109559.076                                                   \n",
            "Avg. Reward          : -32377.931                                                    \n",
            "Max. Reward          :  82035.338                                                    \n",
            "Min. Orders          :     21.000                                                    \n",
            "Avg. Orders          :     36.300                                                    \n",
            "Max. Orders          :     45.000                                                    \n",
            "length of training env time points: 88053,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------     \n",
            "entropy: 0.023695563358676505, learning rate: 0.021563530704100393                   \n",
            "Episode: 0, Avg. Reward: -107837.073, # of orders: 39.000                            \n",
            "Episode: 1, Avg. Reward: -67550.534, # of orders: 41.000                             \n",
            "Episode: 2, Avg. Reward: -54741.676, # of orders: 45.000                             \n",
            "Episode: 3, Avg. Reward: -49204.443, # of orders: 44.750                             \n",
            "Episode: 4, Avg. Reward: -43996.362, # of orders: 44.800                             \n",
            "Episode: 5, Avg. Reward: -52107.024, # of orders: 44.000                             \n",
            "Episode: 6, Avg. Reward: -44094.839, # of orders: 44.000                             \n",
            "Episode: 7, Avg. Reward: -52064.530, # of orders: 44.000                             \n",
            "Episode: 8, Avg. Reward: -42989.829, # of orders: 44.667                             \n",
            "Episode: 9, Avg. Reward: -34776.264, # of orders: 45.200                             \n",
            "Min. Reward          : -107852.365                                                   \n",
            "Avg. Reward          : -34776.264                                                    \n",
            "Max. Reward          :  39145.820                                                    \n",
            "Min. Orders          :     39.000                                                    \n",
            "Avg. Orders          :     45.200                                                    \n",
            "Max. Orders          :     53.000                                                    \n",
            "length of training env time points: 88053,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------     \n",
            "entropy: 0.09088273587117288, learning rate: 0.025763613447427506                    \n",
            "there was an error with those parameters: timesteps: 50,                             \n",
            "\n",
            "              ent_coef: 0.09088273587117288, gamma: 0.99, learning_rate: 0.025763613447427506\n",
            "Learning rate too high: 0.06824915913638445                                          \n",
            "length of training env time points: 88053,               length of validation env time points: 120\n",
            "--------------------------------------------------------------------------------     \n",
            "entropy: 0.01842794810940948, learning rate: 0.01726779058351955                     \n",
            "Episode: 0, Avg. Reward: -14150.921, # of orders: 41.000                             \n",
            "Episode: 1, Avg. Reward: -24536.276, # of orders: 40.000                             \n",
            "Episode: 2, Avg. Reward: -27822.243, # of orders: 44.667                             \n",
            "Episode: 3, Avg. Reward: -13893.895, # of orders: 44.250                             \n",
            "Episode: 4, Avg. Reward: -24929.713, # of orders: 43.000                             \n",
            "Episode: 5, Avg. Reward: -32252.891, # of orders: 43.000                             \n",
            "Episode: 6, Avg. Reward: -27766.809, # of orders: 43.714                             \n",
            "Episode: 7, Avg. Reward: -30951.754, # of orders: 43.750                             \n",
            "Episode: 8, Avg. Reward: -25092.528, # of orders: 44.556                             \n",
            "Episode: 9, Avg. Reward: -18843.914, # of orders: 45.000                             \n",
            "Min. Reward          : -69072.984                                                    \n",
            "Avg. Reward          : -18843.914                                                    \n",
            "Max. Reward          :  37393.606                                                    \n",
            "Min. Orders          :     38.000                                                    \n",
            "Avg. Orders          :     45.000                                                    \n",
            "Max. Orders          :     54.000                                                    \n",
            "Entropy too high: 0.2664991103660938                                                 \n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [2:54:38<00:00, 209.58s/trial, best loss: -29072.219646727386]\n",
            "Best parameters: {'ent_coef': 0.018794601624451752, 'learning_rate': 0.016835273638875447}\n",
            "Entropy too high: 0.7115970931406743                  \n",
            "length of training env time points: 87934,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------\n",
            "entropy: 0.062026384537266284, learning rate: 0.008972516781784226\n",
            "Episode: 0, Avg. Reward: -40434.910, # of orders: 35.000      \n",
            "Episode: 1, Avg. Reward: -43777.767, # of orders: 36.500         \n",
            "Episode: 2, Avg. Reward: -39368.771, # of orders: 39.000         \n",
            "Episode: 3, Avg. Reward: -52721.299, # of orders: 36.750         \n",
            "Episode: 4, Avg. Reward: -51002.537, # of orders: 38.000         \n",
            "Episode: 5, Avg. Reward: -40468.794, # of orders: 38.000         \n",
            "Episode: 6, Avg. Reward: -31499.410, # of orders: 37.857         \n",
            "Episode: 7, Avg. Reward: -35904.601, # of orders: 37.375         \n",
            "Episode: 8, Avg. Reward: -38957.244, # of orders: 37.444         \n",
            "Episode: 9, Avg. Reward: -37176.149, # of orders: 37.400         \n",
            "Min. Reward          : -92778.885                                \n",
            "Avg. Reward          : -37176.149                                \n",
            "Max. Reward          :  22316.898                                \n",
            "Min. Orders          :     30.000                                \n",
            "Avg. Orders          :     37.400                                \n",
            "Max. Orders          :     44.000                                \n",
            "length of training env time points: 87934,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------  \n",
            "entropy: 0.023849625155874056, learning rate: 0.01734609442461828                 \n",
            "Episode: 0, Avg. Reward: -43227.658, # of orders: 35.000                          \n",
            "Episode: 1, Avg. Reward: -40114.529, # of orders: 38.500                          \n",
            "Episode: 2, Avg. Reward: -34652.816, # of orders: 40.333                          \n",
            "Episode: 3, Avg. Reward: -45967.205, # of orders: 40.750                          \n",
            "Episode: 4, Avg. Reward: -36865.283, # of orders: 42.000                          \n",
            "Episode: 5, Avg. Reward: -32449.591, # of orders: 41.500                          \n",
            "Episode: 6, Avg. Reward: -23835.366, # of orders: 41.429                          \n",
            "Episode: 7, Avg. Reward: -29168.463, # of orders: 40.625                          \n",
            "Episode: 8, Avg. Reward: -33556.512, # of orders: 40.333                          \n",
            "Episode: 9, Avg. Reward: -32220.199, # of orders: 40.400                          \n",
            "Min. Reward          : -79910.369                                                 \n",
            "Avg. Reward          : -32220.199                                                 \n",
            "Max. Reward          :  27849.987                                                 \n",
            "Min. Orders          :     35.000                                                 \n",
            "Avg. Orders          :     40.400                                                 \n",
            "Max. Orders          :     47.000                                                 \n",
            "Learning rate too high: 0.06666006425079209                                       \n",
            "Learning rate too high: 0.10979552247381809                                       \n",
            "Entropy too high: 0.3848908530912525                                              \n",
            "Learning rate too high: 0.09872773266258963                                       \n",
            "length of training env time points: 87934,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------  \n",
            "entropy: 0.08355545279323519, learning rate: 0.01768732131578664                  \n",
            "there was an error with those parameters: timesteps: 50,                          \n",
            "\n",
            "              ent_coef: 0.08355545279323519, gamma: 0.99, learning_rate: 0.01768732131578664\n",
            "Learning rate too high: 0.06099136798718596                                       \n",
            "length of training env time points: 87934,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------  \n",
            "entropy: 0.0723258665285787, learning rate: 0.02924789534354247                   \n",
            "there was an error with those parameters: timesteps: 50,                          \n",
            "\n",
            "              ent_coef: 0.0723258665285787, gamma: 0.99, learning_rate: 0.02924789534354247\n",
            "Learning rate too high: 0.12748100679559163                                        \n",
            "length of training env time points: 87934,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------   \n",
            "entropy: 0.06490820909999516, learning rate: 0.013254402638182266                  \n",
            "Episode: 0, Avg. Reward: -43820.780, # of orders: 36.000                           \n",
            "Episode: 1, Avg. Reward: -45713.778, # of orders: 37.000                           \n",
            "Episode: 2, Avg. Reward: -40957.653, # of orders: 39.667                           \n",
            "Episode: 3, Avg. Reward: -53754.526, # of orders: 37.250                           \n",
            "Episode: 4, Avg. Reward: -50281.519, # of orders: 38.600                           \n",
            "Episode: 5, Avg. Reward: -40267.195, # of orders: 38.500                           \n",
            "Episode: 6, Avg. Reward: -31452.914, # of orders: 38.286                           \n",
            "Episode: 7, Avg. Reward: -36187.911, # of orders: 37.750                           \n",
            "Episode: 8, Avg. Reward: -39727.427, # of orders: 37.778                           \n",
            "Episode: 9, Avg. Reward: -37532.645, # of orders: 37.700                           \n",
            "Min. Reward          : -92145.143                                                  \n",
            "Avg. Reward          : -37532.645                                                  \n",
            "Max. Reward          :  21432.777                                                  \n",
            "Min. Orders          :     30.000                                                  \n",
            "Avg. Orders          :     37.700                                                  \n",
            "Max. Orders          :     45.000                                                  \n",
            "length of training env time points: 87934,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------   \n",
            "entropy: 0.025937506889261996, learning rate: 0.04090657110753264                  \n",
            "Episode: 0, Avg. Reward: -56690.566, # of orders: 36.000                           \n",
            "Episode: 1, Avg. Reward: -55499.732, # of orders: 37.000                           \n",
            "Episode: 2, Avg. Reward: -31280.742, # of orders: 41.333                           \n",
            "Episode: 3, Avg. Reward: -39616.587, # of orders: 40.750                           \n",
            "Episode: 4, Avg. Reward: -41949.730, # of orders: 40.400                           \n",
            "Episode: 5, Avg. Reward: -33977.356, # of orders: 40.167                           \n",
            "Episode: 6, Avg. Reward: -25496.256, # of orders: 40.000                           \n",
            "Episode: 7, Avg. Reward: -28665.119, # of orders: 39.250                           \n",
            "Episode: 8, Avg. Reward: -32036.063, # of orders: 39.111                           \n",
            "Episode: 9, Avg. Reward: -29008.939, # of orders: 39.000                           \n",
            "Min. Reward          : -64624.122                                                  \n",
            "Avg. Reward          : -29008.939                                                  \n",
            "Max. Reward          :  25390.346                                                  \n",
            "Min. Orders          :     34.000                                                  \n",
            "Avg. Orders          :     39.000                                                  \n",
            "Max. Orders          :     50.000                                                  \n",
            "Learning rate too high: 0.05292660130989706                                         \n",
            "length of training env time points: 87934,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.03358508876323728, learning rate: 0.012010197758244657                   \n",
            "Episode: 0, Avg. Reward: -21569.870, # of orders: 47.000                            \n",
            "Episode: 1, Avg. Reward: -32529.233, # of orders: 46.000                            \n",
            "Episode: 2, Avg. Reward: -17303.179, # of orders: 51.667                            \n",
            "Episode: 3, Avg. Reward: -19448.069, # of orders: 51.250                            \n",
            "Episode: 4, Avg. Reward: -18748.672, # of orders: 50.400                            \n",
            "Episode: 5, Avg. Reward: -20608.742, # of orders: 49.500                            \n",
            "Episode: 6, Avg. Reward: -23105.797, # of orders: 49.143                            \n",
            "Episode: 7, Avg. Reward: -23535.692, # of orders: 48.625                            \n",
            "Episode: 8, Avg. Reward: -30192.581, # of orders: 48.667                            \n",
            "Episode: 9, Avg. Reward: -28943.242, # of orders: 48.400                            \n",
            "Min. Reward          : -83447.690                                                   \n",
            "Avg. Reward          : -28943.242                                                   \n",
            "Max. Reward          :  13148.930                                                   \n",
            "Min. Orders          :     45.000                                                   \n",
            "Avg. Orders          :     48.400                                                   \n",
            "Max. Orders          :     63.000                                                   \n",
            "Learning rate too high: 0.07601930570031042                                         \n",
            "length of training env time points: 87934,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.009726914355534938, learning rate: 0.0372111292458439                    \n",
            "Episode: 0, Avg. Reward: -47626.349, # of orders: 40.000                            \n",
            "Episode: 1, Avg. Reward: -47747.702, # of orders: 42.000                            \n",
            "Episode: 2, Avg. Reward: -21741.383, # of orders: 45.333                            \n",
            "Episode: 3, Avg. Reward: -30283.259, # of orders: 44.500                            \n",
            "Episode: 4, Avg. Reward: -27857.785, # of orders: 44.600                            \n",
            "Episode: 5, Avg. Reward: -26930.294, # of orders: 44.000                            \n",
            "Episode: 6, Avg. Reward: -23575.879, # of orders: 43.429                            \n",
            "Episode: 7, Avg. Reward: -27161.203, # of orders: 42.500                            \n",
            "Episode: 8, Avg. Reward: -31073.181, # of orders: 42.444                            \n",
            "Episode: 9, Avg. Reward: -26714.719, # of orders: 42.600                            \n",
            "Min. Reward          : -62369.009                                                   \n",
            "Avg. Reward          : -26714.719                                                   \n",
            "Max. Reward          :  30271.255                                                   \n",
            "Min. Orders          :     36.000                                                   \n",
            "Avg. Orders          :     42.600                                                   \n",
            "Max. Orders          :     52.000                                                   \n",
            "length of training env time points: 87934,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.049876876347950266, learning rate: 0.0153791679075107                    \n",
            "Episode: 0, Avg. Reward: -45008.547, # of orders: 36.000                            \n",
            "Episode: 1, Avg. Reward: -44395.071, # of orders: 37.000                            \n",
            "Episode: 2, Avg. Reward: -39925.045, # of orders: 39.333                            \n",
            "Episode: 3, Avg. Reward: -53005.115, # of orders: 37.000                            \n",
            "Episode: 4, Avg. Reward: -50157.620, # of orders: 38.400                            \n",
            "Episode: 5, Avg. Reward: -39733.320, # of orders: 38.333                            \n",
            "Episode: 6, Avg. Reward: -30840.293, # of orders: 38.143                            \n",
            "Episode: 7, Avg. Reward: -35570.465, # of orders: 37.625                            \n",
            "Episode: 8, Avg. Reward: -38708.531, # of orders: 37.667                            \n",
            "Episode: 9, Avg. Reward: -36858.236, # of orders: 37.600                            \n",
            "Min. Reward          : -92245.324                                                   \n",
            "Avg. Reward          : -36858.236                                                   \n",
            "Max. Reward          :  22517.870                                                   \n",
            "Min. Orders          :     30.000                                                   \n",
            "Avg. Orders          :     37.600                                                   \n",
            "Max. Orders          :     44.000                                                   \n",
            "length of training env time points: 87934,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.045646201829425186, learning rate: 0.00826554210128504                   \n",
            "Episode: 0, Avg. Reward: -45770.103, # of orders: 40.000                            \n",
            "Episode: 1, Avg. Reward: -42856.824, # of orders: 42.000                            \n",
            "Episode: 2, Avg. Reward: -22813.582, # of orders: 46.333                            \n",
            "Episode: 3, Avg. Reward: -25701.496, # of orders: 45.750                            \n",
            "Episode: 4, Avg. Reward: -24114.025, # of orders: 45.600                            \n",
            "Episode: 5, Avg. Reward: -24621.988, # of orders: 45.167                            \n",
            "Episode: 6, Avg. Reward: -25327.257, # of orders: 44.714                            \n",
            "Episode: 7, Avg. Reward: -30308.059, # of orders: 43.875                            \n",
            "Episode: 8, Avg. Reward: -34732.884, # of orders: 44.000                            \n",
            "Episode: 9, Avg. Reward: -31254.524, # of orders: 44.000                            \n",
            "Min. Reward          : -70131.484                                                   \n",
            "Avg. Reward          : -31254.524                                                   \n",
            "Max. Reward          :  17272.901                                                   \n",
            "Min. Orders          :     38.000                                                   \n",
            "Avg. Orders          :     44.000                                                   \n",
            "Max. Orders          :     55.000                                                   \n",
            "Learning rate too high: 0.061153632186875605                                        \n",
            "length of training env time points: 87934,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.007656274514471176, learning rate: 0.02403237823033969                   \n",
            "Episode: 0, Avg. Reward: 5924.439, # of orders: 16.000                              \n",
            "Episode: 1, Avg. Reward: -7948.940, # of orders: 15.000                             \n",
            "Episode: 2, Avg. Reward: -4423.462, # of orders: 17.333                             \n",
            "Episode: 3, Avg. Reward: -2952.961, # of orders: 17.500                             \n",
            "Episode: 4, Avg. Reward: -1156.770, # of orders: 17.200                             \n",
            "Episode: 5, Avg. Reward: 4145.852, # of orders: 16.167                              \n",
            "Episode: 6, Avg. Reward: 1547.427, # of orders: 16.714                              \n",
            "Episode: 7, Avg. Reward: -687.081, # of orders: 16.750                              \n",
            "Episode: 8, Avg. Reward: -3358.381, # of orders: 17.111                             \n",
            "Episode: 9, Avg. Reward: -2474.231, # of orders: 17.300                             \n",
            "Min. Reward          : -24728.776                                                   \n",
            "Avg. Reward          :  -2474.231                                                   \n",
            "Max. Reward          :  30658.964                                                   \n",
            "Min. Orders          :     11.000                                                   \n",
            "Avg. Orders          :     17.300                                                   \n",
            "Max. Orders          :     22.000                                                   \n",
            "length of training env time points: 87934,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.009981981879928659, learning rate: 0.024827911654664497                  \n",
            "Episode: 0, Avg. Reward: -46702.865, # of orders: 53.000                            \n",
            "Episode: 1, Avg. Reward: -47907.864, # of orders: 54.500                              \n",
            "Episode: 2, Avg. Reward: -30912.123, # of orders: 59.667                              \n",
            "Episode: 3, Avg. Reward: -27761.959, # of orders: 59.250                              \n",
            "Episode: 4, Avg. Reward: -33389.554, # of orders: 59.400                              \n",
            "Episode: 5, Avg. Reward: -25523.600, # of orders: 59.000                              \n",
            "Episode: 6, Avg. Reward: -21655.550, # of orders: 58.429                              \n",
            "Episode: 7, Avg. Reward: -22298.015, # of orders: 58.000                              \n",
            "Episode: 8, Avg. Reward: -24163.062, # of orders: 58.000                              \n",
            "Episode: 9, Avg. Reward: -21472.514, # of orders: 57.900                              \n",
            "Min. Reward          : -55899.938                                                     \n",
            "Avg. Reward          : -21472.514                                                     \n",
            "Max. Reward          :  13806.172                                                     \n",
            "Min. Orders          :     53.000                                                     \n",
            "Avg. Orders          :     57.900                                                     \n",
            "Max. Orders          :     70.000                                                     \n",
            "length of training env time points: 87934,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------      \n",
            "entropy: 0.007090729161068785, learning rate: 0.02444051706253721                     \n",
            "Episode: 0, Avg. Reward: -53823.972, # of orders: 45.000                              \n",
            "Episode: 1, Avg. Reward: -48740.179, # of orders: 41.500                              \n",
            "Episode: 2, Avg. Reward: -35629.698, # of orders: 47.333                              \n",
            "Episode: 3, Avg. Reward: -26688.159, # of orders: 47.250                              \n",
            "Episode: 4, Avg. Reward: -29359.960, # of orders: 46.800                              \n",
            "Episode: 5, Avg. Reward: -25909.717, # of orders: 46.667                              \n",
            "Episode: 6, Avg. Reward: -26764.546, # of orders: 47.000                              \n",
            "Episode: 7, Avg. Reward: -24422.312, # of orders: 46.875                              \n",
            "Episode: 8, Avg. Reward: -26783.099, # of orders: 47.444                              \n",
            "Episode: 9, Avg. Reward: -25142.535, # of orders: 47.800                              \n",
            "Min. Reward          : -53823.972                                                     \n",
            "Avg. Reward          : -25142.535                                                     \n",
            "Max. Reward          :    136.457                                                     \n",
            "Min. Orders          :     38.000                                                     \n",
            "Avg. Orders          :     47.800                                                     \n",
            "Max. Orders          :     59.000                                                     \n",
            "Entropy too high: 0.13062685881856784                                                 \n",
            "length of training env time points: 87934,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------      \n",
            "entropy: 0.0068703020473257995, learning rate: 0.023136984577776704                   \n",
            "Episode: 0, Avg. Reward: -75426.170, # of orders: 40.000                              \n",
            "Episode: 1, Avg. Reward: -56132.868, # of orders: 38.500                              \n",
            "Episode: 2, Avg. Reward: -53734.384, # of orders: 43.333                              \n",
            "Episode: 3, Avg. Reward: -49506.624, # of orders: 43.750                              \n",
            "Episode: 4, Avg. Reward: -48141.960, # of orders: 43.000                              \n",
            "Episode: 5, Avg. Reward: -41850.268, # of orders: 43.000                              \n",
            "Episode: 6, Avg. Reward: -40296.620, # of orders: 43.143                              \n",
            "Episode: 7, Avg. Reward: -35638.177, # of orders: 42.750                              \n",
            "Episode: 8, Avg. Reward: -36144.147, # of orders: 43.667                              \n",
            "Episode: 9, Avg. Reward: -32721.625, # of orders: 44.000                              \n",
            "Min. Reward          : -75426.170                                                     \n",
            "Avg. Reward          : -32721.625                                                     \n",
            "Max. Reward          :  -1918.928                                                     \n",
            "Min. Orders          :     37.000                                                     \n",
            "Avg. Orders          :     44.000                                                     \n",
            "Max. Orders          :     53.000                                                     \n",
            "length of training env time points: 87934,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------      \n",
            "entropy: 0.014194728228137748, learning rate: 0.04489958582727098                     \n",
            "Episode: 0, Avg. Reward: -51075.369, # of orders: 37.000                              \n",
            "Episode: 1, Avg. Reward: -35368.124, # of orders: 37.500                              \n",
            "Episode: 2, Avg. Reward: -28224.798, # of orders: 39.333                              \n",
            "Episode: 3, Avg. Reward: -41527.397, # of orders: 39.500                              \n",
            "Episode: 4, Avg. Reward: -33347.280, # of orders: 40.800                              \n",
            "Episode: 5, Avg. Reward: -26201.197, # of orders: 40.500                              \n",
            "Episode: 6, Avg. Reward: -19036.492, # of orders: 40.143                              \n",
            "Episode: 7, Avg. Reward: -25063.831, # of orders: 39.375                              \n",
            "Episode: 8, Avg. Reward: -29439.946, # of orders: 39.222                              \n",
            "Episode: 9, Avg. Reward: -28258.610, # of orders: 39.000                              \n",
            "Min. Reward          : -81435.196                                                     \n",
            "Avg. Reward          : -28258.610                                                     \n",
            "Max. Reward          :  23951.734                                                     \n",
            "Min. Orders          :     34.000                                                     \n",
            "Avg. Orders          :     39.000                                                     \n",
            "Max. Orders          :     46.000                                                     \n",
            "Entropy too high: 0.15843101049294384                                                 \n",
            "length of training env time points: 87934,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------      \n",
            "entropy: 0.010636278888983289, learning rate: 0.01180595723118244                     \n",
            "Episode: 0, Avg. Reward: -35301.122, # of orders: 41.000                              \n",
            "Episode: 1, Avg. Reward: -40494.220, # of orders: 39.500                              \n",
            "Episode: 2, Avg. Reward: -31847.530, # of orders: 44.333                              \n",
            "Episode: 3, Avg. Reward: -32410.843, # of orders: 44.000                              \n",
            "Episode: 4, Avg. Reward: -29906.515, # of orders: 43.200                              \n",
            "Episode: 5, Avg. Reward: -25587.875, # of orders: 43.667                              \n",
            "Episode: 6, Avg. Reward: -21203.504, # of orders: 44.143                              \n",
            "Episode: 7, Avg. Reward: -17814.383, # of orders: 43.750                              \n",
            "Episode: 8, Avg. Reward: -17451.098, # of orders: 44.667                              \n",
            "Episode: 9, Avg. Reward: -15113.036, # of orders: 45.100                              \n",
            "Min. Reward          : -45687.318                                                     \n",
            "Avg. Reward          : -15113.036                                                     \n",
            "Max. Reward          :   5929.519                                                     \n",
            "Min. Orders          :     38.000                                                     \n",
            "Avg. Orders          :     45.100                                                     \n",
            "Max. Orders          :     54.000                                                     \n",
            "length of training env time points: 87934,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------      \n",
            "entropy: 0.015437402750310627, learning rate: 0.007141772258884444                    \n",
            "Episode: 0, Avg. Reward: -25973.921, # of orders: 38.000                              \n",
            "Episode: 1, Avg. Reward: -42997.777, # of orders: 36.000                              \n",
            "Episode: 2, Avg. Reward: -32103.318, # of orders: 39.667                              \n",
            "Episode: 3, Avg. Reward: -33521.177, # of orders: 39.750                              \n",
            "Episode: 4, Avg. Reward: -32456.204, # of orders: 39.400                              \n",
            "Episode: 5, Avg. Reward: -35790.402, # of orders: 39.667                              \n",
            "Episode: 6, Avg. Reward: -29536.442, # of orders: 39.714                              \n",
            "Episode: 7, Avg. Reward: -26409.774, # of orders: 39.000                              \n",
            "Episode: 8, Avg. Reward: -21080.906, # of orders: 39.778                              \n",
            "Episode: 9, Avg. Reward: -20356.871, # of orders: 40.300                              \n",
            "Min. Reward          : -60021.633                                                     \n",
            "Avg. Reward          : -20356.871                                                     \n",
            "Max. Reward          :  21550.039                                                     \n",
            "Min. Orders          :     34.000                                                     \n",
            "Avg. Orders          :     40.300                                                     \n",
            "Max. Orders          :     47.000                                                     \n",
            "length of training env time points: 87934,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------      \n",
            "entropy: 0.011238980519007357, learning rate: 0.010518696505863682                    \n",
            "Episode: 0, Avg. Reward: -37214.890, # of orders: 49.000                              \n",
            "Episode: 1, Avg. Reward: -37255.966, # of orders: 48.500                              \n",
            "Episode: 2, Avg. Reward: -27527.658, # of orders: 53.667                              \n",
            "Episode: 3, Avg. Reward: -25183.285, # of orders: 53.250                              \n",
            "Episode: 4, Avg. Reward: -21966.860, # of orders: 53.800                              \n",
            "Episode: 5, Avg. Reward: -22841.675, # of orders: 53.000                              \n",
            "Episode: 6, Avg. Reward: -21279.944, # of orders: 53.143                              \n",
            "Episode: 7, Avg. Reward: -17763.441, # of orders: 52.875                              \n",
            "Episode: 8, Avg. Reward: -18813.469, # of orders: 53.333                              \n",
            "Episode: 9, Avg. Reward: -17990.650, # of orders: 53.200                              \n",
            "Min. Reward          : -37297.042                                                     \n",
            "Avg. Reward          : -17990.650                                                     \n",
            "Max. Reward          :   6852.083                                                     \n",
            "Min. Orders          :     48.000                                                     \n",
            "Avg. Orders          :     53.200                                                     \n",
            "Max. Orders          :     64.000                                                     \n",
            "length of training env time points: 87934,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------      \n",
            "entropy: 0.00691096959728427, learning rate: 0.019103033185392478                     \n",
            "Episode: 0, Avg. Reward: 1439.144, # of orders: 4.000                                 \n",
            "Episode: 1, Avg. Reward: -9320.970, # of orders: 3.000                                \n",
            "Episode: 2, Avg. Reward: 5431.408, # of orders: 4.000                                 \n",
            "Episode: 3, Avg. Reward: 8596.232, # of orders: 3.750                                 \n",
            "Episode: 4, Avg. Reward: 2645.204, # of orders: 3.400                                 \n",
            "Episode: 5, Avg. Reward: 8937.244, # of orders: 3.167                                 \n",
            "Episode: 6, Avg. Reward: 14802.756, # of orders: 3.571                                \n",
            "Episode: 7, Avg. Reward: 10806.605, # of orders: 3.250                                \n",
            "Episode: 8, Avg. Reward: 10593.017, # of orders: 3.333                                \n",
            "Episode: 9, Avg. Reward: 10996.557, # of orders: 3.300                                \n",
            "Min. Reward          : -21158.907                                                     \n",
            "Avg. Reward          :  10996.557                                                     \n",
            "Max. Reward          :  49995.832                                                     \n",
            "Min. Orders          :      1.000                                                     \n",
            "Avg. Orders          :      3.300                                                     \n",
            "Max. Orders          :      6.000                                                     \n",
            "length of training env time points: 87934,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------      \n",
            "entropy: 0.025035719941131487, learning rate: 0.01878316235292663                     \n",
            "Episode: 0, Avg. Reward: -44098.445, # of orders: 36.000                              \n",
            "Episode: 1, Avg. Reward: -44366.605, # of orders: 37.000                              \n",
            "Episode: 2, Avg. Reward: -36614.160, # of orders: 39.667                              \n",
            "Episode: 3, Avg. Reward: -52769.355, # of orders: 37.500                              \n",
            "Episode: 4, Avg. Reward: -50551.193, # of orders: 38.600                              \n",
            "Episode: 5, Avg. Reward: -40357.941, # of orders: 38.500                              \n",
            "Episode: 6, Avg. Reward: -31525.573, # of orders: 38.286                              \n",
            "Episode: 7, Avg. Reward: -36306.046, # of orders: 37.750                              \n",
            "Episode: 8, Avg. Reward: -39494.360, # of orders: 37.778                              \n",
            "Episode: 9, Avg. Reward: -37761.016, # of orders: 37.700                              \n",
            "Min. Reward          : -101234.941                                                    \n",
            "Avg. Reward          : -37761.016                                                     \n",
            "Max. Reward          :  21468.637                                                     \n",
            "Min. Orders          :     31.000                                                     \n",
            "Avg. Orders          :     37.700                                                     \n",
            "Max. Orders          :     45.000                                                     \n",
            "Entropy too high: 0.2260324972685852                                                  \n",
            "length of training env time points: 87934,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------      \n",
            "entropy: 0.006913135460088889, learning rate: 0.014753895312542151                    \n",
            "Episode: 0, Avg. Reward: -69732.651, # of orders: 43.000                              \n",
            "Episode: 1, Avg. Reward: -68530.113, # of orders: 42.000                              \n",
            "Episode: 2, Avg. Reward: -54418.302, # of orders: 47.667                              \n",
            "Episode: 3, Avg. Reward: -53258.097, # of orders: 47.250                              \n",
            "Episode: 4, Avg. Reward: -50779.174, # of orders: 47.200                              \n",
            "Episode: 5, Avg. Reward: -45611.456, # of orders: 47.000                              \n",
            "Episode: 6, Avg. Reward: -39170.700, # of orders: 47.000                              \n",
            "Episode: 7, Avg. Reward: -35728.925, # of orders: 46.500                              \n",
            "Episode: 8, Avg. Reward: -35434.920, # of orders: 47.444                              \n",
            "Episode: 9, Avg. Reward: -32374.755, # of orders: 47.700                              \n",
            "Min. Reward          : -69732.651                                                     \n",
            "Avg. Reward          : -32374.755                                                     \n",
            "Max. Reward          :   -526.163                                                     \n",
            "Min. Orders          :     41.000                                                     \n",
            "Avg. Orders          :     47.700                                                     \n",
            "Max. Orders          :     59.000                                                     \n",
            "length of training env time points: 87934,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------      \n",
            "entropy: 0.01968538225519717, learning rate: 0.031135175207671378                     \n",
            "Episode: 0, Avg. Reward: -28831.169, # of orders: 38.000                              \n",
            "Episode: 1, Avg. Reward: -45662.791, # of orders: 39.000                              \n",
            "Episode: 2, Avg. Reward: -34954.208, # of orders: 41.333                              \n",
            "Episode: 3, Avg. Reward: -42629.120, # of orders: 40.750                              \n",
            "Episode: 4, Avg. Reward: -50510.885, # of orders: 40.200                              \n",
            "Episode: 5, Avg. Reward: -43128.476, # of orders: 40.833                              \n",
            "Episode: 6, Avg. Reward: -41981.555, # of orders: 39.857                              \n",
            "Episode: 7, Avg. Reward: -38010.481, # of orders: 39.250                              \n",
            "Episode: 8, Avg. Reward: -32345.550, # of orders: 40.000                              \n",
            "Episode: 9, Avg. Reward: -29350.082, # of orders: 40.300                              \n",
            "Min. Reward          : -82037.944                                                     \n",
            "Avg. Reward          : -29350.082                                                     \n",
            "Max. Reward          :  12973.898                                                     \n",
            "Min. Orders          :     34.000                                                     \n",
            "Avg. Orders          :     40.300                                                     \n",
            "Max. Orders          :     46.000                                                     \n",
            "Entropy too high: 0.9791484382587303                                                  \n",
            "length of training env time points: 87934,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------      \n",
            "entropy: 0.008140820968856724, learning rate: 0.035353175281769365                    \n",
            "Episode: 0, Avg. Reward: -28782.807, # of orders: 52.000                              \n",
            "Episode: 1, Avg. Reward: -38308.773, # of orders: 53.500                              \n",
            "Episode: 2, Avg. Reward: -29789.181, # of orders: 57.333                              \n",
            "Episode: 3, Avg. Reward: -26652.126, # of orders: 56.500                              \n",
            "Episode: 4, Avg. Reward: -25640.405, # of orders: 57.000                              \n",
            "Episode: 5, Avg. Reward: -20619.818, # of orders: 57.000                              \n",
            "Episode: 6, Avg. Reward: -16794.166, # of orders: 56.143                              \n",
            "Episode: 7, Avg. Reward: -17337.172, # of orders: 55.750                              \n",
            "Episode: 8, Avg. Reward: -17633.558, # of orders: 55.778                              \n",
            "Episode: 9, Avg. Reward: -16274.102, # of orders: 55.600                              \n",
            "Min. Reward          : -47834.739                                                     \n",
            "Avg. Reward          : -16274.102                                                     \n",
            "Max. Reward          :   6159.744                                                     \n",
            "Min. Orders          :     51.000                                                     \n",
            "Avg. Orders          :     55.600                                                     \n",
            "Max. Orders          :     65.000                                                     \n",
            "length of training env time points: 87934,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.018243627256916903, learning rate: 0.02019899114664448                   \n",
            "Episode: 0, Avg. Reward: -90224.741, # of orders: 29.000                            \n",
            "Episode: 1, Avg. Reward: -75823.404, # of orders: 29.500                            \n",
            "Episode: 2, Avg. Reward: -67217.463, # of orders: 33.000                            \n",
            "Episode: 3, Avg. Reward: -56581.087, # of orders: 33.000                            \n",
            "Episode: 4, Avg. Reward: -50575.433, # of orders: 32.600                            \n",
            "Episode: 5, Avg. Reward: -40829.465, # of orders: 33.333                            \n",
            "Episode: 6, Avg. Reward: -38961.088, # of orders: 33.571                            \n",
            "Episode: 7, Avg. Reward: -33136.598, # of orders: 33.500                            \n",
            "Episode: 8, Avg. Reward: -30795.806, # of orders: 34.111                            \n",
            "Episode: 9, Avg. Reward: -30208.664, # of orders: 33.900                            \n",
            "Min. Reward          : -90224.741                                                   \n",
            "Avg. Reward          : -30208.664                                                   \n",
            "Max. Reward          :   7900.377                                                   \n",
            "Min. Orders          :     29.000                                                   \n",
            "Avg. Orders          :     33.900                                                   \n",
            "Max. Orders          :     40.000                                                   \n",
            "length of training env time points: 87934,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.09661923537353989, learning rate: 0.04582655101353427                    \n",
            "there was an error with those parameters: timesteps: 50,                            \n",
            "\n",
            "              ent_coef: 0.09661923537353989, gamma: 0.99, learning_rate: 0.04582655101353427\n",
            "Entropy too high: 0.2774662981754239                                                \n",
            "Learning rate too high: 0.07742613746558182                                         \n",
            "length of training env time points: 87934,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.012252053958602436, learning rate: 0.007031081110951402                  \n",
            "Episode: 0, Avg. Reward: -23618.224, # of orders: 41.000                            \n",
            "Episode: 1, Avg. Reward: -28610.651, # of orders: 41.000                            \n",
            "Episode: 2, Avg. Reward: -19515.920, # of orders: 46.667                            \n",
            "Episode: 3, Avg. Reward: -19425.022, # of orders: 46.250                            \n",
            "Episode: 4, Avg. Reward: -19599.241, # of orders: 46.600                            \n",
            "Episode: 5, Avg. Reward: -17055.846, # of orders: 46.333                            \n",
            "Episode: 6, Avg. Reward: -14859.828, # of orders: 46.286                            \n",
            "Episode: 7, Avg. Reward: -13795.555, # of orders: 46.125                            \n",
            "Episode: 8, Avg. Reward: -12970.987, # of orders: 46.778                            \n",
            "Episode: 9, Avg. Reward: -11711.802, # of orders: 46.900                            \n",
            "Min. Reward          : -33603.078                                                   \n",
            "Avg. Reward          : -11711.802                                                   \n",
            "Max. Reward          :   -379.137                                                   \n",
            "Min. Orders          :     41.000                                                   \n",
            "Avg. Orders          :     46.900                                                   \n",
            "Max. Orders          :     58.000                                                   \n",
            "length of training env time points: 87934,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.01874360382096173, learning rate: 0.027473041412848256                   \n",
            "Episode: 0, Avg. Reward: -44736.651, # of orders: 51.000                            \n",
            "Episode: 1, Avg. Reward: -58139.020, # of orders: 54.000                            \n",
            "Episode: 2, Avg. Reward: -50477.274, # of orders: 58.333                            \n",
            "Episode: 3, Avg. Reward: -40978.500, # of orders: 58.250                            \n",
            "Episode: 4, Avg. Reward: -33543.970, # of orders: 59.200                            \n",
            "Episode: 5, Avg. Reward: -26873.089, # of orders: 58.667                            \n",
            "Episode: 6, Avg. Reward: -21678.681, # of orders: 58.143                            \n",
            "Episode: 7, Avg. Reward: -20358.708, # of orders: 58.000                            \n",
            "Episode: 8, Avg. Reward: -22876.036, # of orders: 57.778                            \n",
            "Episode: 9, Avg. Reward: -17735.194, # of orders: 57.800                            \n",
            "Min. Reward          : -71541.390                                                   \n",
            "Avg. Reward          : -17735.194                                                   \n",
            "Max. Reward          :  28532.380                                                   \n",
            "Min. Orders          :     51.000                                                   \n",
            "Avg. Orders          :     57.800                                                   \n",
            "Max. Orders          :     67.000                                                   \n",
            "length of training env time points: 87934,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.008349524163414685, learning rate: 0.016387414238643507                  \n",
            "Episode: 0, Avg. Reward: -80092.356, # of orders: 44.000                            \n",
            "Episode: 1, Avg. Reward: -69984.479, # of orders: 46.500                            \n",
            "Episode: 2, Avg. Reward: -45460.551, # of orders: 48.333                            \n",
            "Episode: 3, Avg. Reward: -50205.366, # of orders: 48.250                            \n",
            "Episode: 4, Avg. Reward: -41147.615, # of orders: 49.000                            \n",
            "Episode: 5, Avg. Reward: -30143.083, # of orders: 48.333                            \n",
            "Episode: 6, Avg. Reward: -27234.279, # of orders: 47.286                            \n",
            "Episode: 7, Avg. Reward: -28541.000, # of orders: 46.625                            \n",
            "Episode: 8, Avg. Reward: -32504.730, # of orders: 46.111                            \n",
            "Episode: 9, Avg. Reward: -28879.229, # of orders: 45.600                            \n",
            "Min. Reward          : -80092.356                                                   \n",
            "Avg. Reward          : -28879.229                                                   \n",
            "Max. Reward          :  24879.579                                                   \n",
            "Min. Orders          :     41.000                                                   \n",
            "Avg. Orders          :     45.600                                                   \n",
            "Max. Orders          :     52.000                                                   \n",
            "Entropy too high: 0.6897481878509424                                                \n",
            "Learning rate too high: 0.05083001749300672                                         \n",
            "length of training env time points: 87934,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.01342698781433183, learning rate: 0.03337257974305812                    \n",
            "Episode: 0, Avg. Reward: -73656.878, # of orders: 31.000                            \n",
            "Episode: 1, Avg. Reward: -55035.283, # of orders: 31.000                            \n",
            "Episode: 2, Avg. Reward: -34256.467, # of orders: 36.000                            \n",
            "Episode: 3, Avg. Reward: -37458.929, # of orders: 35.500                            \n",
            "Episode: 4, Avg. Reward: -39342.626, # of orders: 35.600                            \n",
            "Episode: 5, Avg. Reward: -32512.264, # of orders: 35.833                            \n",
            "Episode: 6, Avg. Reward: -24036.351, # of orders: 36.143                            \n",
            "Episode: 7, Avg. Reward: -24174.061, # of orders: 35.375                            \n",
            "Episode: 8, Avg. Reward: -28243.510, # of orders: 35.333                            \n",
            "Episode: 9, Avg. Reward: -25767.256, # of orders: 35.700                            \n",
            "Min. Reward          : -73656.878                                                   \n",
            "Avg. Reward          : -25767.256                                                   \n",
            "Max. Reward          :  26819.130                                                   \n",
            "Min. Orders          :     30.000                                                   \n",
            "Avg. Orders          :     35.700                                                   \n",
            "Max. Orders          :     46.000                                                   \n",
            "Learning rate too high: 0.134636263493823                                           \n",
            "Learning rate too high: 0.09395128083662527                                         \n",
            "length of training env time points: 87934,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.0399032096422514, learning rate: 0.008221970409240657                    \n",
            "Episode: 0, Avg. Reward: -36955.155, # of orders: 46.000                            \n",
            "Episode: 1, Avg. Reward: -43866.009, # of orders: 46.500                            \n",
            "Episode: 2, Avg. Reward: -33405.563, # of orders: 51.333                            \n",
            "Episode: 3, Avg. Reward: -24231.432, # of orders: 50.750                            \n",
            "Episode: 4, Avg. Reward: -22713.249, # of orders: 49.800                            \n",
            "Episode: 5, Avg. Reward: -17606.185, # of orders: 49.167                            \n",
            "Episode: 6, Avg. Reward: -15854.772, # of orders: 49.143                            \n",
            "Episode: 7, Avg. Reward: -18647.125, # of orders: 48.875                            \n",
            "Episode: 8, Avg. Reward: -22037.784, # of orders: 49.222                            \n",
            "Episode: 9, Avg. Reward: -17791.955, # of orders: 49.200                            \n",
            "Min. Reward          : -50776.862                                                   \n",
            "Avg. Reward          : -17791.955                                                   \n",
            "Max. Reward          :  20420.501                                                   \n",
            "Min. Orders          :     46.000                                                   \n",
            "Avg. Orders          :     49.200                                                   \n",
            "Max. Orders          :     61.000                                                   \n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [2:44:20<00:00, 197.22s/trial, best loss: -10996.55685254214]\n",
            "Best parameters: {'ent_coef': 0.00691096959728427, 'learning_rate': 0.019103033185392478}\n",
            "length of training env time points: 87815,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------\n",
            "entropy: 0.031865033948128986, learning rate: 0.0183090276323546\n",
            "Episode: 0, Avg. Reward: 42583.125, # of orders: 38.000\n",
            "Episode: 1, Avg. Reward: 27588.959, # of orders: 33.000\n",
            "Episode: 2, Avg. Reward: 9986.948, # of orders: 34.000\n",
            "Episode: 3, Avg. Reward: 14292.880, # of orders: 34.250\n",
            "Episode: 4, Avg. Reward: 27383.331, # of orders: 34.200\n",
            "Episode: 5, Avg. Reward: 16227.692, # of orders: 34.167\n",
            "Episode: 6, Avg. Reward: 9922.108, # of orders: 33.429\n",
            "Episode: 7, Avg. Reward: 332.643, # of orders: 32.750 \n",
            "Episode: 8, Avg. Reward: -3566.048, # of orders: 32.889\n",
            "Episode: 9, Avg. Reward: -12690.731, # of orders: 32.300\n",
            "Min. Reward          : -94812.879                     \n",
            "Avg. Reward          : -12690.731                     \n",
            "Max. Reward          :  79745.137                     \n",
            "Min. Orders          :     27.000                     \n",
            "Avg. Orders          :     32.300                     \n",
            "Max. Orders          :     38.000                     \n",
            "Learning rate too high: 0.061494497744101886                                       \n",
            "Entropy too high: 0.7437130169112782                                               \n",
            "Entropy too high: 0.708263118817324                                                \n",
            "Entropy too high: 0.908243143372008                                                \n",
            "Entropy too high: 0.2725392103630711                                               \n",
            "Entropy too high: 0.5520462612156649                                               \n",
            "length of training env time points: 87815,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------   \n",
            "entropy: 0.010202815341800384, learning rate: 0.04953984586273279                  \n",
            "Episode: 0, Avg. Reward: -43763.276, # of orders: 37.000                           \n",
            "Episode: 1, Avg. Reward: -33236.313, # of orders: 41.000                           \n",
            "Episode: 2, Avg. Reward: -53526.482, # of orders: 35.667                           \n",
            "Episode: 3, Avg. Reward: -38979.119, # of orders: 37.750                           \n",
            "Episode: 4, Avg. Reward: -16068.864, # of orders: 39.800                           \n",
            "Episode: 5, Avg. Reward: -20524.235, # of orders: 40.500                           \n",
            "Episode: 6, Avg. Reward: -32712.625, # of orders: 37.143                           \n",
            "Episode: 7, Avg. Reward: -40181.560, # of orders: 36.625                           \n",
            "Episode: 8, Avg. Reward: -37591.015, # of orders: 36.889                           \n",
            "Episode: 9, Avg. Reward: -43188.708, # of orders: 35.900                           \n",
            "Min. Reward          : -105842.964                                                 \n",
            "Avg. Reward          : -43188.708                                                  \n",
            "Max. Reward          :  75572.158                                                  \n",
            "Min. Orders          :     17.000                                                  \n",
            "Avg. Orders          :     35.900                                                  \n",
            "Max. Orders          :     48.000                                                  \n",
            "Learning rate too high: 0.10034564348020365                                        \n",
            "length of training env time points: 87815,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------\n",
            "entropy: 0.019526340486958792, learning rate: 0.009045998370701816              \n",
            "Episode: 0, Avg. Reward: 10442.255, # of orders: 39.000                         \n",
            "Episode: 1, Avg. Reward: -13829.878, # of orders: 35.500                        \n",
            "Episode: 2, Avg. Reward: -5392.831, # of orders: 41.667                         \n",
            "Episode: 3, Avg. Reward: -2438.303, # of orders: 41.000                         \n",
            "Episode: 4, Avg. Reward: -2764.350, # of orders: 40.800                         \n",
            "Episode: 5, Avg. Reward: -5098.069, # of orders: 41.333                         \n",
            "Episode: 6, Avg. Reward: -9035.762, # of orders: 41.857                         \n",
            "Episode: 7, Avg. Reward: -13000.112, # of orders: 41.625                        \n",
            "Episode: 8, Avg. Reward: -11838.790, # of orders: 42.333                        \n",
            "Episode: 9, Avg. Reward: -15675.462, # of orders: 42.700                        \n",
            "Min. Reward          : -50205.503                                               \n",
            "Avg. Reward          : -15675.462                                               \n",
            "Max. Reward          :  11481.262                                               \n",
            "Min. Orders          :     32.000                                               \n",
            "Avg. Orders          :     42.700                                               \n",
            "Max. Orders          :     54.000                                               \n",
            "Entropy too high: 0.30889297447786845                                               \n",
            "Entropy too high: 0.17662633137930364                                               \n",
            "length of training env time points: 87815,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.09901408594649656, learning rate: 0.012741817049193386                   \n",
            "there was an error with those parameters: timesteps: 50,                            \n",
            "\n",
            "              ent_coef: 0.09901408594649656, gamma: 0.99, learning_rate: 0.012741817049193386\n",
            "Learning rate too high: 0.05016588858472146                                         \n",
            "Entropy too high: 0.10188188643717587                                               \n",
            "Learning rate too high: 0.10197059770671044                                         \n",
            "length of training env time points: 87815,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------  \n",
            "entropy: 0.07354867353786351, learning rate: 0.03255931410025827                  \n",
            "there was an error with those parameters: timesteps: 50,                          \n",
            "\n",
            "              ent_coef: 0.07354867353786351, gamma: 0.99, learning_rate: 0.03255931410025827\n",
            "Learning rate too high: 0.12476616991644512                                       \n",
            "length of training env time points: 87815,               length of validation env time points: 119\n",
            "-------------------------------------------------------------------------------- \n",
            "entropy: 0.02200124466740221, learning rate: 0.009679068714371155                \n",
            "Episode: 0, Avg. Reward: -59082.979, # of orders: 45.000                         \n",
            "Episode: 1, Avg. Reward: -25684.074, # of orders: 47.000                         \n",
            "Episode: 2, Avg. Reward: -28827.233, # of orders: 52.000                         \n",
            "Episode: 3, Avg. Reward: -22821.982, # of orders: 51.500                         \n",
            "Episode: 4, Avg. Reward: -5924.977, # of orders: 51.600                          \n",
            "Episode: 5, Avg. Reward: -4248.196, # of orders: 51.333                          \n",
            "Episode: 6, Avg. Reward: -2145.129, # of orders: 51.286                          \n",
            "Episode: 7, Avg. Reward: -9399.916, # of orders: 50.750                          \n",
            "Episode: 8, Avg. Reward: -7992.301, # of orders: 51.444                          \n",
            "Episode: 9, Avg. Reward: -18362.779, # of orders: 50.800                         \n",
            "Min. Reward          : -111697.089                                               \n",
            "Avg. Reward          : -18362.779                                                \n",
            "Max. Reward          :  61663.046                                                \n",
            "Min. Orders          :     45.000                                                \n",
            "Avg. Orders          :     50.800                                                \n",
            "Max. Orders          :     62.000                                                \n",
            "Entropy too high: 0.10615730668139622                                            \n",
            "length of training env time points: 87815,               length of validation env time points: 119\n",
            "-------------------------------------------------------------------------------- \n",
            "entropy: 0.0368789526698364, learning rate: 0.015017026033296889                 \n",
            "Episode: 0, Avg. Reward: 46999.086, # of orders: 45.000                          \n",
            "Episode: 1, Avg. Reward: 47567.170, # of orders: 41.500                          \n",
            "Episode: 2, Avg. Reward: 29886.695, # of orders: 41.333                          \n",
            "Episode: 3, Avg. Reward: 26761.734, # of orders: 41.500                          \n",
            "Episode: 4, Avg. Reward: 27580.909, # of orders: 43.200                          \n",
            "Episode: 5, Avg. Reward: 30083.256, # of orders: 43.167                          \n",
            "Episode: 6, Avg. Reward: 21653.574, # of orders: 41.429                          \n",
            "Episode: 7, Avg. Reward: 6931.668, # of orders: 39.875                           \n",
            "Episode: 8, Avg. Reward: 4011.818, # of orders: 39.778                           \n",
            "Episode: 9, Avg. Reward: -6676.079, # of orders: 38.100                          \n",
            "Min. Reward          : -102867.154                                               \n",
            "Avg. Reward          :  -6676.079                                                \n",
            "Max. Reward          :  48135.254                                                \n",
            "Min. Orders          :     23.000                                                \n",
            "Avg. Orders          :     38.100                                                \n",
            "Max. Orders          :     50.000                                                \n",
            "length of training env time points: 87815,               length of validation env time points: 119\n",
            "-------------------------------------------------------------------------------- \n",
            "entropy: 0.04005106855588623, learning rate: 0.01629922491736063                 \n",
            "Episode: 0, Avg. Reward: 52263.393, # of orders: 30.000                          \n",
            "Episode: 1, Avg. Reward: 21102.150, # of orders: 27.500                          \n",
            "Episode: 2, Avg. Reward: -5423.306, # of orders: 31.333                          \n",
            "Episode: 3, Avg. Reward: 763.203, # of orders: 31.250                            \n",
            "Episode: 4, Avg. Reward: 13016.443, # of orders: 31.400                          \n",
            "Episode: 5, Avg. Reward: 13655.272, # of orders: 31.500                          \n",
            "Episode: 6, Avg. Reward: 6372.027, # of orders: 31.714                           \n",
            "Episode: 7, Avg. Reward: -1217.736, # of orders: 31.250                          \n",
            "Episode: 8, Avg. Reward: -4853.800, # of orders: 31.444                          \n",
            "Episode: 9, Avg. Reward: -12245.066, # of orders: 31.400                         \n",
            "Min. Reward          : -78766.457                                                \n",
            "Avg. Reward          : -12245.066                                                \n",
            "Max. Reward          :  62029.403                                                \n",
            "Min. Orders          :     25.000                                                \n",
            "Avg. Orders          :     31.400                                                \n",
            "Max. Orders          :     39.000                                                \n",
            "length of training env time points: 87815,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------   \n",
            "entropy: 0.042102777016764445, learning rate: 0.015531615184345857                 \n",
            "Episode: 0, Avg. Reward: -30833.699, # of orders: 35.000                           \n",
            "Episode: 1, Avg. Reward: 6907.591, # of orders: 37.000                             \n",
            "Episode: 2, Avg. Reward: 2323.198, # of orders: 38.333                             \n",
            "Episode: 3, Avg. Reward: 11161.755, # of orders: 39.750                            \n",
            "Episode: 4, Avg. Reward: 11237.079, # of orders: 40.400                            \n",
            "Episode: 5, Avg. Reward: 16049.154, # of orders: 40.833                            \n",
            "Episode: 6, Avg. Reward: 9028.373, # of orders: 39.571                             \n",
            "Episode: 7, Avg. Reward: -3798.266, # of orders: 38.500                            \n",
            "Episode: 8, Avg. Reward: -5538.893, # of orders: 38.556                            \n",
            "Episode: 9, Avg. Reward: -15308.112, # of orders: 37.200                           \n",
            "Min. Reward          : -103231.086                                                 \n",
            "Avg. Reward          : -15308.112                                                  \n",
            "Max. Reward          :  44648.881                                                  \n",
            "Min. Orders          :     25.000                                                  \n",
            "Avg. Orders          :     37.200                                                  \n",
            "Max. Orders          :     44.000                                                  \n",
            "length of training env time points: 87815,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------   \n",
            "entropy: 0.007463444300167134, learning rate: 0.014490123326714156                 \n",
            "Episode: 0, Avg. Reward: 21527.480, # of orders: 86.000                            \n",
            "Episode: 1, Avg. Reward: -641.331, # of orders: 84.500                             \n",
            "Episode: 2, Avg. Reward: -3773.896, # of orders: 85.000                            \n",
            "Episode: 3, Avg. Reward: 3222.350, # of orders: 85.000                             \n",
            "Episode: 4, Avg. Reward: 8401.533, # of orders: 86.000                             \n",
            "Episode: 5, Avg. Reward: 6603.480, # of orders: 86.167                             \n",
            "Episode: 6, Avg. Reward: 5202.254, # of orders: 84.571                             \n",
            "Episode: 7, Avg. Reward: 4207.916, # of orders: 84.875                             \n",
            "Episode: 8, Avg. Reward: 4605.860, # of orders: 85.556                             \n",
            "Episode: 9, Avg. Reward: 676.825, # of orders: 85.700                              \n",
            "Min. Reward          : -34684.493                                                  \n",
            "Avg. Reward          :    676.825                                                  \n",
            "Max. Reward          :  29118.266                                                  \n",
            "Min. Orders          :     75.000                                                  \n",
            "Avg. Orders          :     85.700                                                  \n",
            "Max. Orders          :     91.000                                                  \n",
            "length of training env time points: 87815,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.01175653564365407, learning rate: 0.006860095829038724                   \n",
            "Episode: 0, Avg. Reward: -15479.112, # of orders: 18.000                            \n",
            "Episode: 1, Avg. Reward: -6943.228, # of orders: 16.000                             \n",
            "Episode: 2, Avg. Reward: -97.361, # of orders: 19.000                               \n",
            "Episode: 3, Avg. Reward: 977.280, # of orders: 18.750                               \n",
            "Episode: 4, Avg. Reward: -1452.292, # of orders: 18.600                             \n",
            "Episode: 5, Avg. Reward: 404.275, # of orders: 17.333                               \n",
            "Episode: 6, Avg. Reward: 3457.332, # of orders: 17.714                              \n",
            "Episode: 7, Avg. Reward: 5243.573, # of orders: 18.125                              \n",
            "Episode: 8, Avg. Reward: 4233.734, # of orders: 18.556                              \n",
            "Episode: 9, Avg. Reward: 3010.310, # of orders: 19.000                              \n",
            "Min. Reward          : -15479.112                                                     \n",
            "Avg. Reward          :   3010.310                                                     \n",
            "Max. Reward          :  21775.676                                                     \n",
            "Min. Orders          :     11.000                                                     \n",
            "Avg. Orders          :     19.000                                                     \n",
            "Max. Orders          :     25.000                                                     \n",
            "length of training env time points: 87815,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------       \n",
            "entropy: 0.00691268905803217, learning rate: 0.006925614807196557                      \n",
            "Episode: 0, Avg. Reward: -6570.975, # of orders: 78.000                                \n",
            "Episode: 1, Avg. Reward: -4419.476, # of orders: 79.000                                \n",
            "Episode: 2, Avg. Reward: -4183.375, # of orders: 81.333                                \n",
            "Episode: 3, Avg. Reward: -962.805, # of orders: 81.000                                 \n",
            "Episode: 4, Avg. Reward: -149.475, # of orders: 81.800                                 \n",
            "Episode: 5, Avg. Reward: -422.101, # of orders: 82.000                                 \n",
            "Episode: 6, Avg. Reward: 1229.059, # of orders: 81.286                                 \n",
            "Episode: 7, Avg. Reward: 970.677, # of orders: 81.875                                  \n",
            "Episode: 8, Avg. Reward: 1875.835, # of orders: 82.444                                 \n",
            "Episode: 9, Avg. Reward: 2050.738, # of orders: 82.500                                 \n",
            "Min. Reward          :  -6570.975                                                      \n",
            "Avg. Reward          :   2050.738                                                      \n",
            "Max. Reward          :  11136.023                                                      \n",
            "Min. Orders          :     77.000                                                      \n",
            "Avg. Orders          :     82.500                                                      \n",
            "Max. Orders          :     87.000                                                      \n",
            "length of training env time points: 87815,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------       \n",
            "entropy: 0.008538562921968374, learning rate: 0.006830072675288301                     \n",
            "Episode: 0, Avg. Reward: -25248.769, # of orders: 36.000                               \n",
            "Episode: 1, Avg. Reward: -14109.245, # of orders: 34.000                               \n",
            "Episode: 2, Avg. Reward: -8944.097, # of orders: 38.667                                \n",
            "Episode: 3, Avg. Reward: -3107.748, # of orders: 38.000                                \n",
            "Episode: 4, Avg. Reward: -6474.886, # of orders: 37.600                                \n",
            "Episode: 5, Avg. Reward: -5671.045, # of orders: 38.167                                \n",
            "Episode: 6, Avg. Reward: -3366.122, # of orders: 38.857                                \n",
            "Episode: 7, Avg. Reward: -1921.197, # of orders: 38.500                                \n",
            "Episode: 8, Avg. Reward: -2595.630, # of orders: 38.889                                \n",
            "Episode: 9, Avg. Reward: -2722.212, # of orders: 39.400                                \n",
            "Min. Reward          : -25248.769                                                      \n",
            "Avg. Reward          :  -2722.212                                                      \n",
            "Max. Reward          :  14401.299                                                      \n",
            "Min. Orders          :     32.000                                                      \n",
            "Avg. Orders          :     39.400                                                      \n",
            "Max. Orders          :     48.000                                                      \n",
            "length of training env time points: 87815,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------       \n",
            "entropy: 0.012129900289723437, learning rate: 0.0069921312799254174                    \n",
            "Episode: 0, Avg. Reward: -49887.060, # of orders: 61.000                               \n",
            "Episode: 1, Avg. Reward: -25690.814, # of orders: 62.500                               \n",
            "Episode: 2, Avg. Reward: -24254.266, # of orders: 66.667                               \n",
            "Episode: 3, Avg. Reward: -3899.990, # of orders: 66.250                                \n",
            "Episode: 4, Avg. Reward: 407.684, # of orders: 66.600                                  \n",
            "Episode: 5, Avg. Reward: -2478.612, # of orders: 66.000                                \n",
            "Episode: 6, Avg. Reward: -1699.658, # of orders: 65.571                                \n",
            "Episode: 7, Avg. Reward: -7846.745, # of orders: 65.500                                \n",
            "Episode: 8, Avg. Reward: -8097.766, # of orders: 66.111                                \n",
            "Episode: 9, Avg. Reward: -21768.848, # of orders: 65.600                               \n",
            "Min. Reward          : -144808.588                                                     \n",
            "Avg. Reward          : -21768.848                                                      \n",
            "Max. Reward          :  57162.838                                                      \n",
            "Min. Orders          :     61.000                                                      \n",
            "Avg. Orders          :     65.600                                                      \n",
            "Max. Orders          :     75.000                                                      \n",
            "length of training env time points: 87815,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------       \n",
            "entropy: 0.006875024716201391, learning rate: 0.007000216738060244                     \n",
            "Episode: 0, Avg. Reward: 1909.290, # of orders: 40.000                                 \n",
            "Episode: 1, Avg. Reward: -2388.867, # of orders: 40.000                                \n",
            "Episode: 2, Avg. Reward: -2875.031, # of orders: 43.333                                \n",
            "Episode: 3, Avg. Reward: -937.861, # of orders: 43.000                                 \n",
            "Episode: 4, Avg. Reward: -771.348, # of orders: 43.600                                 \n",
            "Episode: 5, Avg. Reward: 471.221, # of orders: 44.000                                  \n",
            "Episode: 6, Avg. Reward: 1398.182, # of orders: 43.286                                 \n",
            "Episode: 7, Avg. Reward: 3138.566, # of orders: 43.625                                 \n",
            "Episode: 8, Avg. Reward: 3763.409, # of orders: 44.222                                 \n",
            "Episode: 9, Avg. Reward: 2745.417, # of orders: 44.100                                 \n",
            "Min. Reward          :  -6687.025                                                      \n",
            "Avg. Reward          :   2745.417                                                      \n",
            "Max. Reward          :  15321.253                                                      \n",
            "Min. Orders          :     39.000                                                      \n",
            "Avg. Orders          :     44.100                                                      \n",
            "Max. Orders          :     50.000                                                      \n",
            "length of training env time points: 87815,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------       \n",
            "entropy: 0.013214848111460606, learning rate: 0.01039547597847782                      \n",
            "Episode: 0, Avg. Reward: -35554.068, # of orders: 37.000                               \n",
            "Episode: 1, Avg. Reward: 5168.791, # of orders: 38.500                                 \n",
            "Episode: 2, Avg. Reward: 2366.937, # of orders: 39.667                                 \n",
            "Episode: 3, Avg. Reward: 10997.593, # of orders: 40.750                                \n",
            "Episode: 4, Avg. Reward: 25833.780, # of orders: 42.600                                \n",
            "Episode: 5, Avg. Reward: 28637.016, # of orders: 42.667                                \n",
            "Episode: 6, Avg. Reward: 19500.886, # of orders: 41.143                                \n",
            "Episode: 7, Avg. Reward: 5450.028, # of orders: 39.750                                 \n",
            "Episode: 8, Avg. Reward: 2517.181, # of orders: 39.667                                 \n",
            "Episode: 9, Avg. Reward: -7100.914, # of orders: 38.200                                \n",
            "Min. Reward          : -93663.769                                                      \n",
            "Avg. Reward          :  -7100.914                                                      \n",
            "Max. Reward          :  85178.530                                                      \n",
            "Min. Orders          :     25.000                                                      \n",
            "Avg. Orders          :     38.200                                                      \n",
            "Max. Orders          :     50.000                                                      \n",
            "length of training env time points: 87815,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------       \n",
            "entropy: 0.028928713610903028, learning rate: 0.007972121534094479                     \n",
            "Episode: 0, Avg. Reward: -30978.489, # of orders: 18.000                               \n",
            "Episode: 1, Avg. Reward: -16348.022, # of orders: 18.000                               \n",
            "Episode: 2, Avg. Reward: -24585.691, # of orders: 21.000                               \n",
            "Episode: 3, Avg. Reward: -10333.535, # of orders: 20.250                               \n",
            "Episode: 4, Avg. Reward: -6879.180, # of orders: 20.000                                \n",
            "Episode: 5, Avg. Reward: 928.420, # of orders: 18.667                                  \n",
            "Episode: 6, Avg. Reward: 2348.598, # of orders: 19.143                                 \n",
            "Episode: 7, Avg. Reward: 6113.004, # of orders: 19.750                                 \n",
            "Episode: 8, Avg. Reward: 8254.940, # of orders: 20.000                                 \n",
            "Episode: 9, Avg. Reward: -241.226, # of orders: 20.300                                 \n",
            "Min. Reward          : -76706.724                                                      \n",
            "Avg. Reward          :   -241.226                                                      \n",
            "Max. Reward          :  39966.423                                                      \n",
            "Min. Orders          :     12.000                                                      \n",
            "Avg. Orders          :     20.300                                                      \n",
            "Max. Orders          :     27.000                                                      \n",
            "Learning rate too high: 0.06960952257879557                                            \n",
            "length of training env time points: 87815,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------       \n",
            "entropy: 0.027178445663728044, learning rate: 0.019916855188500827                     \n",
            "Episode: 0, Avg. Reward: -32061.169, # of orders: 34.000                               \n",
            "Episode: 1, Avg. Reward: 6604.969, # of orders: 36.500                                 \n",
            "Episode: 2, Avg. Reward: -26438.936, # of orders: 32.000                               \n",
            "Episode: 3, Avg. Reward: -21083.531, # of orders: 34.000                               \n",
            "Episode: 4, Avg. Reward: -8351.139, # of orders: 36.800                                \n",
            "Episode: 5, Avg. Reward: -14085.141, # of orders: 37.000                               \n",
            "Episode: 6, Avg. Reward: -16495.458, # of orders: 36.143                               \n",
            "Episode: 7, Avg. Reward: -26655.185, # of orders: 35.375                               \n",
            "Episode: 8, Avg. Reward: -25686.671, # of orders: 35.778                               \n",
            "Episode: 9, Avg. Reward: -33405.112, # of orders: 34.600                               \n",
            "Min. Reward          : -102871.081                                                     \n",
            "Avg. Reward          : -33405.112                                                      \n",
            "Max. Reward          :  45271.108                                                      \n",
            "Min. Orders          :     23.000                                                      \n",
            "Avg. Orders          :     34.600                                                      \n",
            "Max. Orders          :     48.000                                                      \n",
            "length of training env time points: 87815,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------       \n",
            "entropy: 0.012665377702854154, learning rate: 0.025483830620553236                     \n",
            "Episode: 0, Avg. Reward: -7242.998, # of orders: 32.000                                \n",
            "Episode: 1, Avg. Reward: -7899.944, # of orders: 31.000                                \n",
            "Episode: 2, Avg. Reward: -19355.056, # of orders: 33.000                               \n",
            "Episode: 3, Avg. Reward: -16761.432, # of orders: 33.750                               \n",
            "Episode: 4, Avg. Reward: -8326.838, # of orders: 34.600                                \n",
            "Episode: 5, Avg. Reward: -8049.484, # of orders: 34.667                                \n",
            "Episode: 6, Avg. Reward: -12234.394, # of orders: 34.000                               \n",
            "Episode: 7, Avg. Reward: -20991.459, # of orders: 33.500                               \n",
            "Episode: 8, Avg. Reward: -18316.950, # of orders: 34.333                               \n",
            "Episode: 9, Avg. Reward: -24269.478, # of orders: 34.500                               \n",
            "Min. Reward          : -82290.915                                                      \n",
            "Avg. Reward          : -24269.478                                                      \n",
            "Max. Reward          :  25411.538                                                      \n",
            "Min. Orders          :     30.000                                                      \n",
            "Avg. Orders          :     34.500                                                      \n",
            "Max. Orders          :     41.000                                                      \n",
            "length of training env time points: 87815,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------       \n",
            "entropy: 0.057274427405753885, learning rate: 0.008221142636044164                     \n",
            "Episode: 0, Avg. Reward: -4999.818, # of orders: 43.000                                \n",
            "Episode: 1, Avg. Reward: -1086.744, # of orders: 43.000                                \n",
            "Episode: 2, Avg. Reward: -3083.035, # of orders: 47.333                                \n",
            "Episode: 3, Avg. Reward: 7120.235, # of orders: 47.500                                 \n",
            "Episode: 4, Avg. Reward: 14533.694, # of orders: 47.000                                \n",
            "Episode: 5, Avg. Reward: 18308.434, # of orders: 46.500                                \n",
            "Episode: 6, Avg. Reward: 16370.802, # of orders: 46.429                                \n",
            "Episode: 7, Avg. Reward: 8312.597, # of orders: 45.750                                 \n",
            "Episode: 8, Avg. Reward: 4314.701, # of orders: 46.667                                 \n",
            "Episode: 9, Avg. Reward: -7954.681, # of orders: 45.900                                \n",
            "Min. Reward          : -118379.113                                                     \n",
            "Avg. Reward          :  -7954.681                                                      \n",
            "Max. Reward          :  44187.531                                                      \n",
            "Min. Orders          :     39.000                                                      \n",
            "Avg. Orders          :     45.900                                                      \n",
            "Max. Orders          :     56.000                                                      \n",
            "length of training env time points: 87815,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------       \n",
            "entropy: 0.00898069040044002, learning rate: 0.010978809207382407                      \n",
            "Episode: 0, Avg. Reward: 3634.398, # of orders: 18.000                                 \n",
            "Episode: 1, Avg. Reward: -3899.950, # of orders: 16.000                                \n",
            "Episode: 2, Avg. Reward: -15804.268, # of orders: 18.000                               \n",
            "Episode: 3, Avg. Reward: -9688.913, # of orders: 17.500                                \n",
            "Episode: 4, Avg. Reward: -12448.510, # of orders: 17.600                               \n",
            "Episode: 5, Avg. Reward: -8858.371, # of orders: 16.500                                \n",
            "Episode: 6, Avg. Reward: -12572.215, # of orders: 16.714                               \n",
            "Episode: 7, Avg. Reward: -19322.300, # of orders: 17.250                               \n",
            "Episode: 8, Avg. Reward: -15969.311, # of orders: 17.667                               \n",
            "Episode: 9, Avg. Reward: -19576.561, # of orders: 18.000                               \n",
            "Min. Reward          : -66572.896                                                      \n",
            "Avg. Reward          : -19576.561                                                      \n",
            "Max. Reward          :  10854.599                                                      \n",
            "Min. Orders          :     11.000                                                      \n",
            "Avg. Orders          :     18.000                                                      \n",
            "Max. Orders          :     22.000                                                      \n",
            "length of training env time points: 87815,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------       \n",
            "entropy: 0.006995810587969539, learning rate: 0.017613063332745475                     \n",
            "Episode: 0, Avg. Reward: -40884.708, # of orders: 36.000                               \n",
            "Episode: 1, Avg. Reward: 1390.185, # of orders: 37.500                                 \n",
            "Episode: 2, Avg. Reward: -8978.568, # of orders: 40.000                                \n",
            "Episode: 3, Avg. Reward: -8540.648, # of orders: 40.750                                \n",
            "Episode: 4, Avg. Reward: 1072.288, # of orders: 42.200                                 \n",
            "Episode: 5, Avg. Reward: -2758.679, # of orders: 41.667                                \n",
            "Episode: 6, Avg. Reward: -6385.212, # of orders: 40.714                                \n",
            "Episode: 7, Avg. Reward: -13147.340, # of orders: 40.000                               \n",
            "Episode: 8, Avg. Reward: -12993.576, # of orders: 40.556                               \n",
            "Episode: 9, Avg. Reward: -22074.768, # of orders: 39.100                               \n",
            "Min. Reward          : -103805.488                                                     \n",
            "Avg. Reward          : -22074.768                                                      \n",
            "Max. Reward          :  43665.078                                                      \n",
            "Min. Orders          :     26.000                                                      \n",
            "Avg. Orders          :     39.100                                                      \n",
            "Max. Orders          :     48.000                                                      \n",
            "Learning rate too high: 0.06681221103594108                                            \n",
            "length of training env time points: 87815,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------       \n",
            "entropy: 0.02256413043821513, learning rate: 0.04129298401416588                       \n",
            "Episode: 0, Avg. Reward: 129610.969, # of orders: 41.000                               \n",
            "Episode: 1, Avg. Reward: 26940.368, # of orders: 35.500                                \n",
            "Episode: 2, Avg. Reward: -13658.002, # of orders: 29.333                               \n",
            "Episode: 3, Avg. Reward: -10361.992, # of orders: 30.500                               \n",
            "Episode: 4, Avg. Reward: 13553.417, # of orders: 33.400                                \n",
            "Episode: 5, Avg. Reward: -4543.278, # of orders: 31.000                                \n",
            "Episode: 6, Avg. Reward: -14909.978, # of orders: 30.286                               \n",
            "Episode: 7, Avg. Reward: -19562.249, # of orders: 30.125                               \n",
            "Episode: 8, Avg. Reward: -23795.988, # of orders: 30.444                               \n",
            "Episode: 9, Avg. Reward: -33118.927, # of orders: 29.700                               \n",
            "Min. Reward          : -117025.375                                                     \n",
            "Avg. Reward          : -33118.927                                                      \n",
            "Max. Reward          : 129610.969                                                      \n",
            "Min. Orders          :     17.000                                                      \n",
            "Avg. Orders          :     29.700                                                      \n",
            "Max. Orders          :     45.000                                                      \n",
            "Entropy too high: 0.5303402845875482                                                   \n",
            "length of training env time points: 87815,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------     \n",
            "entropy: 0.010747101420293486, learning rate: 0.012915574862861242                   \n",
            "Episode: 0, Avg. Reward: 0.000, # of orders: 0.000                                   \n",
            "Episode: 1, Avg. Reward: 0.000, # of orders: 0.000                                   \n",
            "Episode: 2, Avg. Reward: 35.126, # of orders: 0.333                                  \n",
            "Episode: 3, Avg. Reward: 325.052, # of orders: 0.500                                 \n",
            "Episode: 4, Avg. Reward: 260.042, # of orders: 0.400                                 \n",
            "Episode: 5, Avg. Reward: 216.702, # of orders: 0.333                                 \n",
            "Episode: 6, Avg. Reward: -582.366, # of orders: 0.571                                \n",
            "Episode: 7, Avg. Reward: -509.570, # of orders: 0.500                                \n",
            "Episode: 8, Avg. Reward: -452.951, # of orders: 0.444                                \n",
            "Episode: 9, Avg. Reward: 173.247, # of orders: 0.600                                 \n",
            "Min. Reward          :  -5376.769                                                    \n",
            "Avg. Reward          :    173.247                                                    \n",
            "Max. Reward          :   5809.028                                                    \n",
            "Min. Orders          :      0.000                                                    \n",
            "Avg. Orders          :      0.600                                                    \n",
            "Max. Orders          :      2.000                                                    \n",
            "Entropy too high: 0.16960291593278937                                                \n",
            "length of training env time points: 87815,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------     \n",
            "entropy: 0.058506831823968826, learning rate: 0.006811184932657923                   \n",
            "Episode: 0, Avg. Reward: -36323.543, # of orders: 37.000                             \n",
            "Episode: 1, Avg. Reward: -30972.365, # of orders: 39.000                             \n",
            "Episode: 2, Avg. Reward: -20512.826, # of orders: 40.333                             \n",
            "Episode: 3, Avg. Reward: -6665.045, # of orders: 41.500                              \n",
            "Episode: 4, Avg. Reward: 10210.336, # of orders: 43.200                              \n",
            "Episode: 5, Avg. Reward: 15339.892, # of orders: 43.333                              \n",
            "Episode: 6, Avg. Reward: 8444.531, # of orders: 41.714                               \n",
            "Episode: 7, Avg. Reward: -4895.569, # of orders: 40.500                              \n",
            "Episode: 8, Avg. Reward: -6428.929, # of orders: 40.333                              \n",
            "Episode: 9, Avg. Reward: -15636.450, # of orders: 38.900                             \n",
            "Min. Reward          : -98504.134                                                    \n",
            "Avg. Reward          : -15636.450                                                    \n",
            "Max. Reward          :  77711.863                                                    \n",
            "Min. Orders          :     26.000                                                    \n",
            "Avg. Orders          :     38.900                                                    \n",
            "Max. Orders          :     50.000                                                    \n",
            "length of training env time points: 87815,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------     \n",
            "entropy: 0.015595175414363163, learning rate: 0.036033079132137866                   \n",
            "Episode: 0, Avg. Reward: 87866.947, # of orders: 40.000                              \n",
            "Episode: 1, Avg. Reward: 20598.948, # of orders: 36.500                              \n",
            "Episode: 2, Avg. Reward: 9789.581, # of orders: 39.000                               \n",
            "Episode: 3, Avg. Reward: 18438.167, # of orders: 39.500                              \n",
            "Episode: 4, Avg. Reward: 28038.395, # of orders: 40.200                              \n",
            "Episode: 5, Avg. Reward: 16160.657, # of orders: 39.833                              \n",
            "Episode: 6, Avg. Reward: 12242.847, # of orders: 39.429                              \n",
            "Episode: 7, Avg. Reward: 5698.283, # of orders: 38.500                               \n",
            "Episode: 8, Avg. Reward: 1482.248, # of orders: 39.000                               \n",
            "Episode: 9, Avg. Reward: -12788.821, # of orders: 37.900                             \n",
            "Min. Reward          : -141228.434                                                   \n",
            "Avg. Reward          : -12788.821                                                    \n",
            "Max. Reward          :  87866.947                                                    \n",
            "Min. Orders          :     28.000                                                    \n",
            "Avg. Orders          :     37.900                                                    \n",
            "Max. Orders          :     44.000                                                    \n",
            "length of training env time points: 87815,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------     \n",
            "entropy: 0.009651564536579093, learning rate: 0.010947084820387719                   \n",
            "Episode: 0, Avg. Reward: 20871.097, # of orders: 57.000                              \n",
            "Episode: 1, Avg. Reward: -30714.438, # of orders: 56.500                             \n",
            "Episode: 2, Avg. Reward: -27266.926, # of orders: 57.667                             \n",
            "Episode: 3, Avg. Reward: -11071.504, # of orders: 58.750                             \n",
            "Episode: 4, Avg. Reward: -5305.464, # of orders: 58.800                              \n",
            "Episode: 5, Avg. Reward: -16689.384, # of orders: 57.833                             \n",
            "Episode: 6, Avg. Reward: -17802.927, # of orders: 56.714                             \n",
            "Episode: 7, Avg. Reward: -27617.215, # of orders: 55.375                             \n",
            "Episode: 8, Avg. Reward: -27723.083, # of orders: 55.889                             \n",
            "Episode: 9, Avg. Reward: -35251.771, # of orders: 54.900                             \n",
            "Min. Reward          : -103009.961                                                   \n",
            "Avg. Reward          : -35251.771                                                    \n",
            "Max. Reward          :  37514.761                                                    \n",
            "Min. Orders          :     46.000                                                    \n",
            "Avg. Orders          :     54.900                                                    \n",
            "Max. Orders          :     62.000                                                    \n",
            "Learning rate too high: 0.0792902694611552                                           \n",
            "length of training env time points: 87815,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------     \n",
            "entropy: 0.0068111614684125904, learning rate: 0.009000133947499621                  \n",
            "Episode: 0, Avg. Reward: -11526.161, # of orders: 35.000                             \n",
            "Episode: 1, Avg. Reward: -8192.884, # of orders: 33.500                              \n",
            "Episode: 2, Avg. Reward: -11243.555, # of orders: 37.333                             \n",
            "Episode: 3, Avg. Reward: -8169.994, # of orders: 37.000                              \n",
            "Episode: 4, Avg. Reward: -4911.514, # of orders: 36.800                              \n",
            "Episode: 5, Avg. Reward: -5363.456, # of orders: 37.167                              \n",
            "Episode: 6, Avg. Reward: -5944.671, # of orders: 38.000                              \n",
            "Episode: 7, Avg. Reward: -6623.075, # of orders: 37.625                              \n",
            "Episode: 8, Avg. Reward: -6112.475, # of orders: 37.778                              \n",
            "Episode: 9, Avg. Reward: -5440.163, # of orders: 38.200                              \n",
            "Min. Reward          : -17344.898                                                    \n",
            "Avg. Reward          :  -5440.163                                                    \n",
            "Max. Reward          :   8122.405                                                    \n",
            "Min. Orders          :     32.000                                                    \n",
            "Avg. Orders          :     38.200                                                    \n",
            "Max. Orders          :     45.000                                                    \n",
            "Entropy too high: 0.3779889518796741                                                 \n",
            "Entropy too high: 0.13004429968350278                                                \n",
            "length of training env time points: 87815,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------     \n",
            "entropy: 0.019172738415603498, learning rate: 0.007595553302772887                   \n",
            "Episode: 0, Avg. Reward: -408.915, # of orders: 69.000                               \n",
            "Episode: 1, Avg. Reward: -24028.909, # of orders: 68.500                             \n",
            "Episode: 2, Avg. Reward: -21108.930, # of orders: 71.000                             \n",
            "Episode: 3, Avg. Reward: -17896.124, # of orders: 70.000                             \n",
            "Episode: 4, Avg. Reward: -15221.470, # of orders: 70.200                             \n",
            "Episode: 5, Avg. Reward: -20711.543, # of orders: 69.167                             \n",
            "Episode: 6, Avg. Reward: -22751.823, # of orders: 67.571                             \n",
            "Episode: 7, Avg. Reward: -23496.135, # of orders: 67.375                             \n",
            "Episode: 8, Avg. Reward: -23286.832, # of orders: 67.778                             \n",
            "Episode: 9, Avg. Reward: -28199.679, # of orders: 67.400                             \n",
            "Min. Reward          : -72415.300                                                    \n",
            "Avg. Reward          : -28199.679                                                    \n",
            "Max. Reward          :   -408.915                                                    \n",
            "Min. Orders          :     58.000                                                    \n",
            "Avg. Orders          :     67.400                                                    \n",
            "Max. Orders          :     76.000                                                    \n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [2:42:53<00:00, 195.47s/trial, best loss: -3010.3098764769616]\n",
            "Best parameters: {'ent_coef': 0.01175653564365407, 'learning_rate': 0.006860095829038724}\n",
            "Entropy too high: 0.4601615305720313                  \n",
            "length of training env time points: 87696,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------\n",
            "entropy: 0.01077318913997561, learning rate: 0.01922707236440688\n",
            "Episode: 0, Avg. Reward: -50169.644, # of orders: 35.000      \n",
            "Episode: 1, Avg. Reward: -71999.410, # of orders: 34.000         \n",
            "Episode: 2, Avg. Reward: -48697.014, # of orders: 39.333         \n",
            "Episode: 3, Avg. Reward: -37277.841, # of orders: 39.750         \n",
            "Episode: 4, Avg. Reward: -33587.594, # of orders: 40.000         \n",
            "Episode: 5, Avg. Reward: -36607.761, # of orders: 39.667         \n",
            "Episode: 6, Avg. Reward: -38249.718, # of orders: 38.429         \n",
            "Episode: 7, Avg. Reward: -41020.597, # of orders: 37.875         \n",
            "Episode: 8, Avg. Reward: -44229.523, # of orders: 38.000         \n",
            "Episode: 9, Avg. Reward: -45223.254, # of orders: 37.700         \n",
            "Min. Reward          : -93829.176                                \n",
            "Avg. Reward          : -45223.254                                \n",
            "Max. Reward          :  -2092.221                                \n",
            "Min. Orders          :     31.000                                \n",
            "Avg. Orders          :     37.700                                \n",
            "Max. Orders          :     50.000                                \n",
            "Learning rate too high: 0.11268735560344026                                       \n",
            "Entropy too high: 0.11509425902209378                                             \n",
            "Learning rate too high: 0.09168093493786816                                       \n",
            "length of training env time points: 87696,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------  \n",
            "entropy: 0.006940991324988598, learning rate: 0.027513600361444096                \n",
            "Episode: 0, Avg. Reward: -93689.634, # of orders: 46.000                          \n",
            "Episode: 1, Avg. Reward: -93842.170, # of orders: 47.000                          \n",
            "Episode: 2, Avg. Reward: -76945.688, # of orders: 51.333                          \n",
            "Episode: 3, Avg. Reward: -66127.077, # of orders: 51.000                          \n",
            "Episode: 4, Avg. Reward: -53652.707, # of orders: 51.600                          \n",
            "Episode: 5, Avg. Reward: -57313.612, # of orders: 51.167                          \n",
            "Episode: 6, Avg. Reward: -49449.418, # of orders: 50.571                          \n",
            "Episode: 7, Avg. Reward: -52411.146, # of orders: 50.875                          \n",
            "Episode: 8, Avg. Reward: -53962.133, # of orders: 51.556                          \n",
            "Episode: 9, Avg. Reward: -53509.856, # of orders: 51.400                          \n",
            "Min. Reward          : -93994.706                                                 \n",
            "Avg. Reward          : -53509.856                                                 \n",
            "Max. Reward          :  -2264.252                                                 \n",
            "Min. Orders          :     46.000                                                 \n",
            "Avg. Orders          :     51.400                                                 \n",
            "Max. Orders          :     60.000                                                 \n",
            "length of training env time points: 87696,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------  \n",
            "entropy: 0.007585127624307432, learning rate: 0.008676246636913706                \n",
            "Episode: 0, Avg. Reward: -5243.674, # of orders: 33.000                           \n",
            "Episode: 1, Avg. Reward: -4254.768, # of orders: 32.000                           \n",
            "Episode: 2, Avg. Reward: -3140.250, # of orders: 36.333                           \n",
            "Episode: 3, Avg. Reward: -869.230, # of orders: 35.750                            \n",
            "Episode: 4, Avg. Reward: -288.053, # of orders: 35.600                            \n",
            "Episode: 5, Avg. Reward: -800.261, # of orders: 36.000                            \n",
            "Episode: 6, Avg. Reward: -1243.590, # of orders: 36.714                           \n",
            "Episode: 7, Avg. Reward: -1613.927, # of orders: 36.250                           \n",
            "Episode: 8, Avg. Reward: -2317.332, # of orders: 36.222                           \n",
            "Episode: 9, Avg. Reward: -2536.635, # of orders: 36.600                           \n",
            "Min. Reward          :  -7944.571                                                 \n",
            "Avg. Reward          :  -2536.635                                                 \n",
            "Max. Reward          :   5943.828                                                 \n",
            "Min. Orders          :     31.000                                                 \n",
            "Avg. Orders          :     36.600                                                 \n",
            "Max. Orders          :     45.000                                                 \n",
            "Entropy too high: 0.6356089311546175                                               \n",
            "Entropy too high: 0.567743242296536                                                \n",
            "Learning rate too high: 0.09997451908190859                                        \n",
            "length of training env time points: 87696,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.010774268748262006, learning rate: 0.025329844387620423                  \n",
            "Episode: 0, Avg. Reward: -50323.959, # of orders: 33.000                            \n",
            "Episode: 1, Avg. Reward: -61179.194, # of orders: 34.000                            \n",
            "Episode: 2, Avg. Reward: -52650.211, # of orders: 38.000                            \n",
            "Episode: 3, Avg. Reward: -36342.420, # of orders: 38.000                            \n",
            "Episode: 4, Avg. Reward: -28472.660, # of orders: 37.600                            \n",
            "Episode: 5, Avg. Reward: -28324.484, # of orders: 37.667                            \n",
            "Episode: 6, Avg. Reward: -32097.048, # of orders: 36.714                            \n",
            "Episode: 7, Avg. Reward: -36727.568, # of orders: 35.875                            \n",
            "Episode: 8, Avg. Reward: -40940.713, # of orders: 36.111                            \n",
            "Episode: 9, Avg. Reward: -41964.208, # of orders: 35.900                            \n",
            "Min. Reward          : -74645.871                                                   \n",
            "Avg. Reward          : -41964.208                                                   \n",
            "Max. Reward          :  12580.952                                                   \n",
            "Min. Orders          :     30.000                                                   \n",
            "Avg. Orders          :     35.900                                                   \n",
            "Max. Orders          :     46.000                                                   \n",
            "length of training env time points: 87696,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.013702494390782749, learning rate: 0.014848906904526993                  \n",
            "Episode: 0, Avg. Reward: -46070.099, # of orders: 34.000                            \n",
            "Episode: 1, Avg. Reward: -72450.078, # of orders: 34.500                            \n",
            "Episode: 2, Avg. Reward: -47521.481, # of orders: 38.000                            \n",
            "Episode: 3, Avg. Reward: -37398.784, # of orders: 38.500                            \n",
            "Episode: 4, Avg. Reward: -33511.602, # of orders: 38.800                            \n",
            "Episode: 5, Avg. Reward: -36361.860, # of orders: 38.500                            \n",
            "Episode: 6, Avg. Reward: -37816.969, # of orders: 37.429                            \n",
            "Episode: 7, Avg. Reward: -40459.360, # of orders: 36.875                            \n",
            "Episode: 8, Avg. Reward: -43712.009, # of orders: 37.222                            \n",
            "Episode: 9, Avg. Reward: -43439.188, # of orders: 37.000                            \n",
            "Min. Reward          : -98830.058                                                   \n",
            "Avg. Reward          : -43439.188                                                   \n",
            "Max. Reward          :   2335.713                                                   \n",
            "Min. Orders          :     31.000                                                   \n",
            "Avg. Orders          :     37.000                                                   \n",
            "Max. Orders          :     45.000                                                   \n",
            "Learning rate too high: 0.10716536623371264                                         \n",
            "length of training env time points: 87696,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.016782656221482964, learning rate: 0.029825300318514353                  \n",
            "Episode: 0, Avg. Reward: -82991.543, # of orders: 36.000                            \n",
            "Episode: 1, Avg. Reward: -92543.702, # of orders: 35.500                            \n",
            "Episode: 2, Avg. Reward: -61937.319, # of orders: 40.333                            \n",
            "Episode: 3, Avg. Reward: -46018.392, # of orders: 40.750                            \n",
            "Episode: 4, Avg. Reward: -35861.394, # of orders: 42.000                            \n",
            "Episode: 5, Avg. Reward: -38093.654, # of orders: 41.833                            \n",
            "Episode: 6, Avg. Reward: -38492.870, # of orders: 40.571                            \n",
            "Episode: 7, Avg. Reward: -41329.496, # of orders: 39.875                            \n",
            "Episode: 8, Avg. Reward: -44081.921, # of orders: 39.778                            \n",
            "Episode: 9, Avg. Reward: -45389.921, # of orders: 39.300                            \n",
            "Min. Reward          : -102095.861                                                  \n",
            "Avg. Reward          : -45389.921                                                   \n",
            "Max. Reward          :   4766.598                                                   \n",
            "Min. Orders          :     33.000                                                   \n",
            "Avg. Orders          :     39.300                                                   \n",
            "Max. Orders          :     50.000                                                   \n",
            "Learning rate too high: 0.06557760425927084                                         \n",
            "Entropy too high: 0.2611236147866991                                                \n",
            "length of training env time points: 87696,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.09889547511417368, learning rate: 0.01989104448275035                    \n",
            "there was an error with those parameters: timesteps: 50,                            \n",
            "\n",
            "              ent_coef: 0.09889547511417368, gamma: 0.99, learning_rate: 0.01989104448275035\n",
            "Learning rate too high: 0.06995306292090335                                         \n",
            "Learning rate too high: 0.11153167044393596                                         \n",
            "Entropy too high: 0.18295465288306842                                               \n",
            "length of training env time points: 87696,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.02813974324427213, learning rate: 0.04409867372922471                    \n",
            "Episode: 0, Avg. Reward: -52504.676, # of orders: 35.000                            \n",
            "Episode: 1, Avg. Reward: -74534.449, # of orders: 34.000                              \n",
            "Episode: 2, Avg. Reward: -51300.932, # of orders: 39.333                              \n",
            "Episode: 3, Avg. Reward: -39807.866, # of orders: 39.750                              \n",
            "Episode: 4, Avg. Reward: -35038.712, # of orders: 40.000                              \n",
            "Episode: 5, Avg. Reward: -37752.716, # of orders: 39.667                              \n",
            "Episode: 6, Avg. Reward: -38962.482, # of orders: 38.429                              \n",
            "Episode: 7, Avg. Reward: -41222.085, # of orders: 37.875                              \n",
            "Episode: 8, Avg. Reward: -44357.786, # of orders: 38.000                              \n",
            "Episode: 9, Avg. Reward: -45098.095, # of orders: 37.700                              \n",
            "Min. Reward          : -96564.222                                                     \n",
            "Avg. Reward          : -45098.095                                                     \n",
            "Max. Reward          :  -4833.898                                                     \n",
            "Min. Orders          :     31.000                                                     \n",
            "Avg. Orders          :     37.700                                                     \n",
            "Max. Orders          :     50.000                                                     \n",
            "length of training env time points: 87696,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------      \n",
            "entropy: 0.031135390720831678, learning rate: 0.011097534530597312                    \n",
            "Episode: 0, Avg. Reward: -6954.025, # of orders: 37.000                               \n",
            "Episode: 1, Avg. Reward: -13555.111, # of orders: 34.500                              \n",
            "Episode: 2, Avg. Reward: -14931.570, # of orders: 40.333                              \n",
            "Episode: 3, Avg. Reward: -11279.326, # of orders: 39.500                              \n",
            "Episode: 4, Avg. Reward: -13674.448, # of orders: 39.400                              \n",
            "Episode: 5, Avg. Reward: -14032.844, # of orders: 39.833                              \n",
            "Episode: 6, Avg. Reward: -17548.918, # of orders: 40.286                              \n",
            "Episode: 7, Avg. Reward: -15864.023, # of orders: 40.250                              \n",
            "Episode: 8, Avg. Reward: -16379.595, # of orders: 41.000                              \n",
            "Episode: 9, Avg. Reward: -15746.469, # of orders: 41.500                              \n",
            "Min. Reward          : -38645.361                                                     \n",
            "Avg. Reward          : -15746.469                                                     \n",
            "Max. Reward          :   -322.594                                                     \n",
            "Min. Orders          :     32.000                                                     \n",
            "Avg. Orders          :     41.500                                                     \n",
            "Max. Orders          :     52.000                                                     \n",
            "length of training env time points: 87696,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------      \n",
            "entropy: 0.033892546991338694, learning rate: 0.006880453177944406                    \n",
            "Episode: 0, Avg. Reward: -18351.355, # of orders: 48.000                              \n",
            "Episode: 1, Avg. Reward: -28360.609, # of orders: 50.500                              \n",
            "Episode: 2, Avg. Reward: -32012.330, # of orders: 54.000                              \n",
            "Episode: 3, Avg. Reward: -31765.640, # of orders: 53.500                              \n",
            "Episode: 4, Avg. Reward: -17694.067, # of orders: 53.600                              \n",
            "Episode: 5, Avg. Reward: -20777.573, # of orders: 53.167                              \n",
            "Episode: 6, Avg. Reward: -20477.173, # of orders: 52.714                              \n",
            "Episode: 7, Avg. Reward: -21826.437, # of orders: 52.375                              \n",
            "Episode: 8, Avg. Reward: -21654.706, # of orders: 52.556                              \n",
            "Episode: 9, Avg. Reward: -22344.608, # of orders: 52.600                              \n",
            "Min. Reward          : -39315.770                                                     \n",
            "Avg. Reward          : -22344.608                                                     \n",
            "Max. Reward          :  38592.225                                                     \n",
            "Min. Orders          :     48.000                                                     \n",
            "Avg. Orders          :     52.600                                                     \n",
            "Max. Orders          :     61.000                                                     \n",
            "length of training env time points: 87696,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------      \n",
            "entropy: 0.007037805733334204, learning rate: 0.011304253012903182                    \n",
            "Episode: 0, Avg. Reward: -14595.006, # of orders: 108.000                             \n",
            "Episode: 1, Avg. Reward: -18836.327, # of orders: 108.500                             \n",
            "Episode: 2, Avg. Reward: -23565.880, # of orders: 108.667                             \n",
            "Episode: 3, Avg. Reward: -22361.812, # of orders: 108.500                             \n",
            "Episode: 4, Avg. Reward: -17829.638, # of orders: 108.600                             \n",
            "Episode: 5, Avg. Reward: -16220.590, # of orders: 108.333                             \n",
            "Episode: 6, Avg. Reward: -16045.180, # of orders: 108.429                             \n",
            "Episode: 7, Avg. Reward: -16290.478, # of orders: 108.500                             \n",
            "Episode: 8, Avg. Reward: -15397.568, # of orders: 108.333                             \n",
            "Episode: 9, Avg. Reward: -16034.679, # of orders: 108.400                             \n",
            "Min. Reward          : -33024.988                                                     \n",
            "Avg. Reward          : -16034.679                                                     \n",
            "Max. Reward          :    299.060                                                     \n",
            "Min. Orders          :    107.000                                                     \n",
            "Avg. Orders          :    108.400                                                     \n",
            "Max. Orders          :    109.000                                                     \n",
            "length of training env time points: 87696,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------      \n",
            "entropy: 0.025816085067532316, learning rate: 0.007275737090237874                    \n",
            "Episode: 0, Avg. Reward: -8487.442, # of orders: 50.000                               \n",
            "Episode: 1, Avg. Reward: -13292.290, # of orders: 49.500                              \n",
            "Episode: 2, Avg. Reward: -15922.342, # of orders: 54.333                              \n",
            "Episode: 3, Avg. Reward: -14818.337, # of orders: 54.000                              \n",
            "Episode: 4, Avg. Reward: -10385.914, # of orders: 53.600                              \n",
            "Episode: 5, Avg. Reward: -9163.491, # of orders: 53.000                               \n",
            "Episode: 6, Avg. Reward: -8644.981, # of orders: 53.143                               \n",
            "Episode: 7, Avg. Reward: -9453.155, # of orders: 53.000                               \n",
            "Episode: 8, Avg. Reward: -8832.672, # of orders: 53.444                               \n",
            "Episode: 9, Avg. Reward: -8512.980, # of orders: 53.200                               \n",
            "Min. Reward          : -21182.446                                                     \n",
            "Avg. Reward          :  -8512.980                                                     \n",
            "Max. Reward          :   7343.779                                                     \n",
            "Min. Orders          :     49.000                                                     \n",
            "Avg. Orders          :     53.200                                                     \n",
            "Max. Orders          :     64.000                                                     \n",
            "length of training env time points: 87696,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------      \n",
            "entropy: 0.022020698556396226, learning rate: 0.006875934634221374                    \n",
            "Episode: 0, Avg. Reward: 2362.793, # of orders: 27.000                                \n",
            "Episode: 1, Avg. Reward: -4011.953, # of orders: 24.500                               \n",
            "Episode: 2, Avg. Reward: -6256.688, # of orders: 29.333                               \n",
            "Episode: 3, Avg. Reward: -4775.222, # of orders: 28.250                               \n",
            "Episode: 4, Avg. Reward: -5447.255, # of orders: 27.600                               \n",
            "Episode: 5, Avg. Reward: -5764.022, # of orders: 27.500                               \n",
            "Episode: 6, Avg. Reward: -5492.113, # of orders: 28.286                               \n",
            "Episode: 7, Avg. Reward: -4715.147, # of orders: 28.250                               \n",
            "Episode: 8, Avg. Reward: -4851.506, # of orders: 28.111                               \n",
            "Episode: 9, Avg. Reward: -5227.311, # of orders: 28.500                               \n",
            "Min. Reward          : -10746.158                                                     \n",
            "Avg. Reward          :  -5227.311                                                     \n",
            "Max. Reward          :   2362.793                                                     \n",
            "Min. Orders          :     22.000                                                     \n",
            "Avg. Orders          :     28.500                                                     \n",
            "Max. Orders          :     39.000                                                     \n",
            "length of training env time points: 87696,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------      \n",
            "entropy: 0.020556778750636575, learning rate: 0.04147753834561417                     \n",
            "Episode: 0, Avg. Reward: -49857.844, # of orders: 35.000                              \n",
            "Episode: 1, Avg. Reward: -72382.744, # of orders: 34.000                              \n",
            "Episode: 2, Avg. Reward: -48874.205, # of orders: 39.333                              \n",
            "Episode: 3, Avg. Reward: -38094.183, # of orders: 39.750                              \n",
            "Episode: 4, Avg. Reward: -33959.773, # of orders: 40.000                              \n",
            "Episode: 5, Avg. Reward: -36882.036, # of orders: 39.667                              \n",
            "Episode: 6, Avg. Reward: -38583.476, # of orders: 38.429                              \n",
            "Episode: 7, Avg. Reward: -41221.002, # of orders: 37.875                              \n",
            "Episode: 8, Avg. Reward: -44682.293, # of orders: 38.000                              \n",
            "Episode: 9, Avg. Reward: -45214.686, # of orders: 37.700                              \n",
            "Min. Reward          : -94907.644                                                     \n",
            "Avg. Reward          : -45214.686                                                     \n",
            "Max. Reward          :  -1857.128                                                     \n",
            "Min. Orders          :     31.000                                                     \n",
            "Avg. Orders          :     37.700                                                     \n",
            "Max. Orders          :     50.000                                                     \n",
            "length of training env time points: 87696,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------      \n",
            "entropy: 0.04199291429655386, learning rate: 0.008407963714782928                     \n",
            "Episode: 0, Avg. Reward: -51624.986, # of orders: 35.000                              \n",
            "Episode: 1, Avg. Reward: -73715.825, # of orders: 34.000                              \n",
            "Episode: 2, Avg. Reward: -49179.508, # of orders: 39.333                              \n",
            "Episode: 3, Avg. Reward: -38524.959, # of orders: 39.750                              \n",
            "Episode: 4, Avg. Reward: -34768.102, # of orders: 40.000                              \n",
            "Episode: 5, Avg. Reward: -36779.665, # of orders: 39.667                              \n",
            "Episode: 6, Avg. Reward: -38394.277, # of orders: 38.429                              \n",
            "Episode: 7, Avg. Reward: -41204.942, # of orders: 37.875                              \n",
            "Episode: 8, Avg. Reward: -44088.617, # of orders: 38.000                              \n",
            "Episode: 9, Avg. Reward: -44977.928, # of orders: 37.700                              \n",
            "Min. Reward          : -95806.663                                                     \n",
            "Avg. Reward          : -44977.928                                                     \n",
            "Max. Reward          :   -106.876                                                     \n",
            "Min. Orders          :     31.000                                                     \n",
            "Avg. Orders          :     37.700                                                     \n",
            "Max. Orders          :     50.000                                                     \n",
            "length of training env time points: 87696,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------      \n",
            "entropy: 0.008233834107424294, learning rate: 0.012607807888424001                    \n",
            "Episode: 0, Avg. Reward: 470.796, # of orders: 4.000                                  \n",
            "Episode: 1, Avg. Reward: 235.398, # of orders: 2.000                                  \n",
            "Episode: 2, Avg. Reward: -2742.893, # of orders: 2.000                                \n",
            "Episode: 3, Avg. Reward: -1942.073, # of orders: 1.750                                \n",
            "Episode: 4, Avg. Reward: -2809.960, # of orders: 1.800                                \n",
            "Episode: 5, Avg. Reward: -3626.978, # of orders: 1.667                                \n",
            "Episode: 6, Avg. Reward: -4973.476, # of orders: 1.714                                \n",
            "Episode: 7, Avg. Reward: -4756.222, # of orders: 1.625                                \n",
            "Episode: 8, Avg. Reward: -4227.753, # of orders: 1.444                                \n",
            "Episode: 9, Avg. Reward: -3730.568, # of orders: 1.500                                \n",
            "Min. Reward          : -13052.464                                                     \n",
            "Avg. Reward          :  -3730.568                                                     \n",
            "Max. Reward          :    744.092                                                     \n",
            "Min. Orders          :      0.000                                                     \n",
            "Avg. Orders          :      1.500                                                     \n",
            "Max. Orders          :      4.000                                                     \n",
            "length of training env time points: 87696,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------      \n",
            "entropy: 0.006762764559887291, learning rate: 0.013154394661164455                    \n",
            "Episode: 0, Avg. Reward: 2852.105, # of orders: 7.000                                 \n",
            "Episode: 1, Avg. Reward: -2596.217, # of orders: 7.500                                \n",
            "Episode: 2, Avg. Reward: -2001.003, # of orders: 8.333                                \n",
            "Episode: 3, Avg. Reward: -799.685, # of orders: 8.500                                 \n",
            "Episode: 4, Avg. Reward: -451.691, # of orders: 8.200                                 \n",
            "Episode: 5, Avg. Reward: -2015.175, # of orders: 7.333                                \n",
            "Episode: 6, Avg. Reward: -2334.027, # of orders: 7.714                                \n",
            "Episode: 7, Avg. Reward: -2091.544, # of orders: 8.000                                \n",
            "Episode: 8, Avg. Reward: -2173.093, # of orders: 8.556                                \n",
            "Episode: 9, Avg. Reward: -1042.885, # of orders: 8.600                                \n",
            "Min. Reward          :  -9832.596                                                     \n",
            "Avg. Reward          :  -1042.885                                                     \n",
            "Max. Reward          :   9128.981                                                     \n",
            "Min. Orders          :      3.000                                                     \n",
            "Avg. Orders          :      8.600                                                     \n",
            "Max. Orders          :     13.000                                                     \n",
            "length of training env time points: 87696,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------      \n",
            "entropy: 0.00880414879658209, learning rate: 0.021352296962772584                     \n",
            "Episode: 0, Avg. Reward: 11101.595, # of orders: 12.000                               \n",
            "Episode: 1, Avg. Reward: -18513.376, # of orders: 11.500                              \n",
            "Episode: 2, Avg. Reward: -22751.539, # of orders: 13.000                              \n",
            "Episode: 3, Avg. Reward: -13618.582, # of orders: 13.750                              \n",
            "Episode: 4, Avg. Reward: -10089.577, # of orders: 14.200                              \n",
            "Episode: 5, Avg. Reward: -8937.414, # of orders: 13.500                               \n",
            "Episode: 6, Avg. Reward: -4836.775, # of orders: 13.571                               \n",
            "Episode: 7, Avg. Reward: -5131.095, # of orders: 14.000                               \n",
            "Episode: 8, Avg. Reward: -7353.218, # of orders: 14.444                               \n",
            "Episode: 9, Avg. Reward: -9700.944, # of orders: 14.500                               \n",
            "Min. Reward          : -48128.347                                                     \n",
            "Avg. Reward          :  -9700.944                                                     \n",
            "Max. Reward          :  19767.059                                                     \n",
            "Min. Orders          :     10.000                                                     \n",
            "Avg. Orders          :     14.500                                                     \n",
            "Max. Orders          :     18.000                                                     \n",
            "length of training env time points: 87696,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------      \n",
            "entropy: 0.048505707583764164, learning rate: 0.01393497035544242                     \n",
            "Episode: 0, Avg. Reward: -49119.462, # of orders: 35.000                              \n",
            "Episode: 1, Avg. Reward: -71466.109, # of orders: 34.000                              \n",
            "Episode: 2, Avg. Reward: -48574.861, # of orders: 39.333                              \n",
            "Episode: 3, Avg. Reward: -38445.760, # of orders: 39.750                              \n",
            "Episode: 4, Avg. Reward: -34380.780, # of orders: 40.000                              \n",
            "Episode: 5, Avg. Reward: -36529.172, # of orders: 39.667                              \n",
            "Episode: 6, Avg. Reward: -37611.054, # of orders: 38.429                              \n",
            "Episode: 7, Avg. Reward: -40025.391, # of orders: 37.875                              \n",
            "Episode: 8, Avg. Reward: -43120.997, # of orders: 38.000                              \n",
            "Episode: 9, Avg. Reward: -44176.578, # of orders: 37.700                              \n",
            "Min. Reward          : -93812.755                                                     \n",
            "Avg. Reward          : -44176.578                                                     \n",
            "Max. Reward          :  -2792.366                                                     \n",
            "Min. Orders          :     31.000                                                     \n",
            "Avg. Orders          :     37.700                                                     \n",
            "Max. Orders          :     50.000                                                     \n",
            "Entropy too high: 0.35643224845618077                                                 \n",
            "Entropy too high: 0.14957565245619564                                                 \n",
            "length of training env time points: 87696,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------      \n",
            "entropy: 0.010364094158132272, learning rate: 0.016635768123426965                    \n",
            "Episode: 0, Avg. Reward: 0.000, # of orders: 0.000                                    \n",
            "Episode: 1, Avg. Reward: 0.000, # of orders: 0.000                                    \n",
            "Episode: 2, Avg. Reward: -381.665, # of orders: 0.333                                 \n",
            "Episode: 3, Avg. Reward: -286.249, # of orders: 0.250                                 \n",
            "Episode: 4, Avg. Reward: -228.999, # of orders: 0.200                                 \n",
            "Episode: 5, Avg. Reward: -190.833, # of orders: 0.167                                 \n",
            "Episode: 6, Avg. Reward: -2053.097, # of orders: 0.286                                \n",
            "Episode: 7, Avg. Reward: -1796.460, # of orders: 0.250                                \n",
            "Episode: 8, Avg. Reward: -1596.853, # of orders: 0.222                                \n",
            "Episode: 9, Avg. Reward: -1040.051, # of orders: 0.300                                \n",
            "Min. Reward          : -13226.684                                                     \n",
            "Avg. Reward          :  -1040.051                                                     \n",
            "Max. Reward          :   3971.172                                                     \n",
            "Min. Orders          :      0.000                                                     \n",
            "Avg. Orders          :      0.300                                                     \n",
            "Max. Orders          :      1.000                                                     \n",
            "length of training env time points: 87696,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------      \n",
            "entropy: 0.011309859182387487, learning rate: 0.03534517446911043                     \n",
            "Episode: 0, Avg. Reward: -45152.705, # of orders: 65.000                              \n",
            "Episode: 1, Avg. Reward: -58858.908, # of orders: 65.000                              \n",
            "Episode: 2, Avg. Reward: -53311.334, # of orders: 65.000                              \n",
            "Episode: 3, Avg. Reward: -43650.409, # of orders: 64.250                              \n",
            "Episode: 4, Avg. Reward: -22811.350, # of orders: 67.000                              \n",
            "Episode: 5, Avg. Reward: -15589.614, # of orders: 67.000                              \n",
            "Episode: 6, Avg. Reward: -2905.512, # of orders: 66.714                               \n",
            "Episode: 7, Avg. Reward: -6710.859, # of orders: 66.625                               \n",
            "Episode: 8, Avg. Reward: -12922.343, # of orders: 66.111                              \n",
            "Episode: 9, Avg. Reward: -15165.890, # of orders: 65.600                              \n",
            "Min. Reward          : -72565.111                                                     \n",
            "Avg. Reward          : -15165.890                                                     \n",
            "Max. Reward          :  73199.098                                                     \n",
            "Min. Orders          :     61.000                                                     \n",
            "Avg. Orders          :     65.600                                                     \n",
            "Max. Orders          :     78.000                                                     \n",
            "length of training env time points: 87696,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------      \n",
            "entropy: 0.020822623800981117, learning rate: 0.016364193088740656                    \n",
            "Episode: 0, Avg. Reward: -53433.578, # of orders: 35.000                              \n",
            "Episode: 1, Avg. Reward: -75902.687, # of orders: 34.000                              \n",
            "Episode: 2, Avg. Reward: -50893.336, # of orders: 39.333                              \n",
            "Episode: 3, Avg. Reward: -40875.861, # of orders: 39.750                              \n",
            "Episode: 4, Avg. Reward: -36296.601, # of orders: 40.000                              \n",
            "Episode: 5, Avg. Reward: -38534.269, # of orders: 39.667                              \n",
            "Episode: 6, Avg. Reward: -39430.003, # of orders: 38.429                              \n",
            "Episode: 7, Avg. Reward: -41620.634, # of orders: 37.875                              \n",
            "Episode: 8, Avg. Reward: -44665.928, # of orders: 38.000                              \n",
            "Episode: 9, Avg. Reward: -45562.152, # of orders: 37.700                              \n",
            "Min. Reward          : -98371.796                                                     \n",
            "Avg. Reward          : -45562.152                                                     \n",
            "Max. Reward          :   -874.635                                                     \n",
            "Min. Orders          :     31.000                                                     \n",
            "Avg. Orders          :     37.700                                                     \n",
            "Max. Orders          :     50.000                                                     \n",
            "Entropy too high: 0.9740946519453233                                                  \n",
            "length of training env time points: 87696,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------      \n",
            "entropy: 0.01640968366738473, learning rate: 0.021300590801800575                     \n",
            "Episode: 0, Avg. Reward: -26559.815, # of orders: 47.000                              \n",
            "Episode: 1, Avg. Reward: -41976.488, # of orders: 47.500                              \n",
            "Episode: 2, Avg. Reward: -51364.573, # of orders: 51.333                              \n",
            "Episode: 3, Avg. Reward: -53261.957, # of orders: 51.000                              \n",
            "Episode: 4, Avg. Reward: -53947.329, # of orders: 50.600                              \n",
            "Episode: 5, Avg. Reward: -52047.043, # of orders: 50.000                              \n",
            "Episode: 6, Avg. Reward: -52044.579, # of orders: 49.286                              \n",
            "Episode: 7, Avg. Reward: -48760.353, # of orders: 48.875                              \n",
            "Episode: 8, Avg. Reward: -47960.988, # of orders: 49.556                              \n",
            "Episode: 9, Avg. Reward: -44788.655, # of orders: 49.600                              \n",
            "Min. Reward          : -70140.743                                                     \n",
            "Avg. Reward          : -44788.655                                                     \n",
            "Max. Reward          : -16237.655                                                     \n",
            "Min. Orders          :     45.000                                                     \n",
            "Avg. Orders          :     49.600                                                     \n",
            "Max. Orders          :     59.000                                                     \n",
            "length of training env time points: 87696,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.039909347165911865, learning rate: 0.025302951648730188                  \n",
            "Episode: 0, Avg. Reward: -49597.533, # of orders: 35.000                            \n",
            "Episode: 1, Avg. Reward: -74545.404, # of orders: 34.000                            \n",
            "Episode: 2, Avg. Reward: -50250.075, # of orders: 39.333                            \n",
            "Episode: 3, Avg. Reward: -39696.725, # of orders: 39.750                            \n",
            "Episode: 4, Avg. Reward: -36251.073, # of orders: 40.000                            \n",
            "Episode: 5, Avg. Reward: -38422.852, # of orders: 39.667                            \n",
            "Episode: 6, Avg. Reward: -39556.666, # of orders: 38.429                            \n",
            "Episode: 7, Avg. Reward: -41744.664, # of orders: 37.875                            \n",
            "Episode: 8, Avg. Reward: -44492.044, # of orders: 38.000                            \n",
            "Episode: 9, Avg. Reward: -44789.713, # of orders: 37.700                            \n",
            "Min. Reward          : -99493.275                                                   \n",
            "Avg. Reward          : -44789.713                                                   \n",
            "Max. Reward          :  -1659.417                                                   \n",
            "Min. Orders          :     31.000                                                   \n",
            "Avg. Orders          :     37.700                                                   \n",
            "Max. Orders          :     50.000                                                   \n",
            "length of training env time points: 87696,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.006855223748088962, learning rate: 0.017881289539344494                  \n",
            "Episode: 0, Avg. Reward: -47608.512, # of orders: 30.000                            \n",
            "Episode: 1, Avg. Reward: -59550.277, # of orders: 30.000                            \n",
            "Episode: 2, Avg. Reward: -55176.610, # of orders: 34.333                            \n",
            "Episode: 3, Avg. Reward: -33526.669, # of orders: 35.250                            \n",
            "Episode: 4, Avg. Reward: -29337.777, # of orders: 35.000                            \n",
            "Episode: 5, Avg. Reward: -27992.953, # of orders: 35.000                            \n",
            "Episode: 6, Avg. Reward: -32201.958, # of orders: 34.286                            \n",
            "Episode: 7, Avg. Reward: -34199.990, # of orders: 33.875                            \n",
            "Episode: 8, Avg. Reward: -37900.308, # of orders: 33.889                            \n",
            "Episode: 9, Avg. Reward: -37679.888, # of orders: 34.000                            \n",
            "Min. Reward          : -71492.043                                                   \n",
            "Avg. Reward          : -37679.888                                                   \n",
            "Max. Reward          :  31423.157                                                   \n",
            "Min. Orders          :     30.000                                                   \n",
            "Avg. Orders          :     34.000                                                   \n",
            "Max. Orders          :     43.000                                                   \n",
            "length of training env time points: 87696,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.01538371110542255, learning rate: 0.0330178600622879                     \n",
            "Episode: 0, Avg. Reward: -46508.588, # of orders: 38.000                            \n",
            "Episode: 1, Avg. Reward: -71130.201, # of orders: 39.000                            \n",
            "Episode: 2, Avg. Reward: -60149.991, # of orders: 44.667                            \n",
            "Episode: 3, Avg. Reward: -61618.260, # of orders: 45.500                            \n",
            "Episode: 4, Avg. Reward: -53272.244, # of orders: 44.800                            \n",
            "Episode: 5, Avg. Reward: -52553.140, # of orders: 44.500                            \n",
            "Episode: 6, Avg. Reward: -55000.119, # of orders: 43.857                            \n",
            "Episode: 7, Avg. Reward: -54071.464, # of orders: 43.375                            \n",
            "Episode: 8, Avg. Reward: -54567.351, # of orders: 44.000                            \n",
            "Episode: 9, Avg. Reward: -51988.403, # of orders: 43.300                            \n",
            "Min. Reward          : -95751.815                                                   \n",
            "Avg. Reward          : -51988.403                                                   \n",
            "Max. Reward          : -19888.177                                                   \n",
            "Min. Orders          :     37.000                                                   \n",
            "Avg. Orders          :     43.300                                                   \n",
            "Max. Orders          :     56.000                                                   \n",
            "length of training env time points: 87696,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.009672334415707693, learning rate: 0.012903243722493279                  \n",
            "Episode: 0, Avg. Reward: -4792.952, # of orders: 48.000                             \n",
            "Episode: 1, Avg. Reward: -8486.878, # of orders: 49.000                             \n",
            "Episode: 2, Avg. Reward: -13861.557, # of orders: 53.000                            \n",
            "Episode: 3, Avg. Reward: -12604.265, # of orders: 53.000                            \n",
            "Episode: 4, Avg. Reward: -9524.305, # of orders: 53.400                             \n",
            "Episode: 5, Avg. Reward: -10780.478, # of orders: 52.667                            \n",
            "Episode: 6, Avg. Reward: -11487.602, # of orders: 51.857                            \n",
            "Episode: 7, Avg. Reward: -11022.477, # of orders: 51.625                            \n",
            "Episode: 8, Avg. Reward: -10872.455, # of orders: 51.889                            \n",
            "Episode: 9, Avg. Reward: -10678.173, # of orders: 52.000                            \n",
            "Min. Reward          : -24610.915                                                   \n",
            "Avg. Reward          : -10678.173                                                   \n",
            "Max. Reward          :   2795.538                                                   \n",
            "Min. Orders          :     47.000                                                   \n",
            "Avg. Orders          :     52.000                                                   \n",
            "Max. Orders          :     61.000                                                   \n",
            "length of training env time points: 87696,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.05633323247661363, learning rate: 0.024965495048346147                   \n",
            "there was an error with those parameters: timesteps: 50,                            \n",
            "\n",
            "              ent_coef: 0.05633323247661363, gamma: 0.99, learning_rate: 0.024965495048346147\n",
            "length of training env time points: 87696,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.012215824598430278, learning rate: 0.010704670578517036                  \n",
            "Episode: 0, Avg. Reward: -19745.258, # of orders: 42.000                            \n",
            "Episode: 1, Avg. Reward: -31888.079, # of orders: 40.000                            \n",
            "Episode: 2, Avg. Reward: -36427.468, # of orders: 44.000                            \n",
            "Episode: 3, Avg. Reward: -23594.787, # of orders: 44.250                            \n",
            "Episode: 4, Avg. Reward: -19956.971, # of orders: 43.400                            \n",
            "Episode: 5, Avg. Reward: -19198.397, # of orders: 43.833                            \n",
            "Episode: 6, Avg. Reward: -21598.208, # of orders: 44.143                            \n",
            "Episode: 7, Avg. Reward: -23862.563, # of orders: 43.875                            \n",
            "Episode: 8, Avg. Reward: -22627.088, # of orders: 44.556                            \n",
            "Episode: 9, Avg. Reward: -22747.952, # of orders: 45.000                            \n",
            "Min. Reward          : -45506.246                                                   \n",
            "Avg. Reward          : -22747.952                                                   \n",
            "Max. Reward          :  14903.255                                                   \n",
            "Min. Orders          :     38.000                                                   \n",
            "Avg. Orders          :     45.000                                                   \n",
            "Max. Orders          :     52.000                                                   \n",
            "Learning rate too high: 0.05659850101322883                                         \n",
            "Entropy too high: 0.9337861588566321                                                \n",
            "length of training env time points: 87696,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.07000778910115504, learning rate: 0.015998242955211656                   \n",
            "there was an error with those parameters: timesteps: 50,                            \n",
            "\n",
            "              ent_coef: 0.07000778910115504, gamma: 0.99, learning_rate: 0.015998242955211656\n",
            "Entropy too high: 0.28872923689721713                                               \n",
            "length of training env time points: 87696,               length of validation env time points: 119\n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.006846062561454449, learning rate: 0.012709375075782516                  \n",
            "Episode: 0, Avg. Reward: 0.000, # of orders: 0.000                                  \n",
            "Episode: 1, Avg. Reward: 0.000, # of orders: 0.000                                  \n",
            "Episode: 2, Avg. Reward: 0.000, # of orders: 0.000                                  \n",
            "Episode: 3, Avg. Reward: 0.000, # of orders: 0.000                                  \n",
            "Episode: 4, Avg. Reward: 0.000, # of orders: 0.000                                  \n",
            "Episode: 5, Avg. Reward: 0.000, # of orders: 0.000                                  \n",
            "Episode: 6, Avg. Reward: 527.505, # of orders: 0.143                                \n",
            "Episode: 7, Avg. Reward: 461.567, # of orders: 0.125                                \n",
            "Episode: 8, Avg. Reward: 410.282, # of orders: 0.111                                \n",
            "Episode: 9, Avg. Reward: 369.253, # of orders: 0.100                                \n",
            "Min. Reward          :      0.000                                                   \n",
            "Avg. Reward          :    369.253                                                   \n",
            "Max. Reward          :   3692.534                                                   \n",
            "Min. Orders          :      0.000                                                   \n",
            "Avg. Orders          :      0.100                                                   \n",
            "Max. Orders          :      1.000                                                   \n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [4:01:37<00:00, 289.95s/trial, best loss: -369.253381053466] \n",
            "Best parameters: {'ent_coef': 0.006846062561454449, 'learning_rate': 0.012709375075782516}\n"
          ]
        }
      ],
      "source": [
        "for i in range(0, 35, 7):\n",
        "    training_index_slice = symbols[1]['EURUSD'].loc[:(max_friday - pd.DateOffset(days=i+7)), :].index\n",
        "    validation_index_slice = symbols[1]['EURUSD'].loc[(max_friday - pd.DateOffset(days=i+7)):(max_friday - pd.DateOffset(days=i)), :].index\n",
        "    env_train.time_points = list(training_index_slice)\n",
        "    env_validation.time_points = list(validation_index_slice)\n",
        "    trials = Trials()\n",
        "    best = fmin(fn=objective,\n",
        "                space=space,\n",
        "                algo=tpe.suggest,\n",
        "                max_evals=50, # Number of evaluations of the objective function\n",
        "                trials=trials,\n",
        "                trials_save_file=f'hyperopt/trials_4_22_iter_{i}.pkl')\n",
        "\n",
        "    print(\"Best parameters:\", best)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testing Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>status</th>\n",
              "      <th>eval_time</th>\n",
              "      <th>parameters</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>fail</td>\n",
              "      <td>1.713532e+09</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>fail</td>\n",
              "      <td>1.713532e+09</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>108189.442904</td>\n",
              "      <td>ok</td>\n",
              "      <td>1.713533e+09</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>112597.585936</td>\n",
              "      <td>ok</td>\n",
              "      <td>1.713533e+09</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>fail</td>\n",
              "      <td>1.713533e+09</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>fail</td>\n",
              "      <td>1.713562e+09</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>fail</td>\n",
              "      <td>1.713562e+09</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>192103.142642</td>\n",
              "      <td>ok</td>\n",
              "      <td>1.713563e+09</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>189639.526575</td>\n",
              "      <td>ok</td>\n",
              "      <td>1.713563e+09</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>fail</td>\n",
              "      <td>1.713563e+09</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows √ó 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             loss status     eval_time  parameters\n",
              "0             NaN   fail  1.713532e+09         NaN\n",
              "0             NaN   fail  1.713532e+09         NaN\n",
              "0   108189.442904     ok  1.713533e+09         NaN\n",
              "0   112597.585936     ok  1.713533e+09         NaN\n",
              "0             NaN   fail  1.713533e+09         NaN\n",
              "..            ...    ...           ...         ...\n",
              "0             NaN   fail  1.713562e+09         NaN\n",
              "0             NaN   fail  1.713562e+09         NaN\n",
              "0   192103.142642     ok  1.713563e+09         NaN\n",
              "0   189639.526575     ok  1.713563e+09         NaN\n",
              "0             NaN   fail  1.713563e+09         NaN\n",
              "\n",
              "[100 rows x 4 columns]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load in the saved trials data\n",
        "# trials = pickle.load(open('hyperopt/trials.pkl', 'rb'))\n",
        "# trials_4_19 = pickle.load(open('hyperopt/trials_4_19.pkl', 'rb'))\n",
        "# trials_all = trials.extend(trials_4_19)\n",
        "# trials_all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_df = pd.DataFrame()\n",
        "for result in trials.results:\n",
        "    result['window_size'] = result['parameters']['window_size']\n",
        "    result['learning_rate'] = result['parameters']['learning_rate']\n",
        "    result['ent_coef'] = result['parameters']['ent_coef']\n",
        "    # del result['parameters']\n",
        "    new_row = pd.DataFrame(result)\n",
        "    results_df = pd.concat([results_df, new_row], axis=0)\n",
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# visualize the parameters that cause failures in the objective function\n",
        "\n",
        "# create a graph that has learning rate on the x-axis and ent_coef on the y-axis, then the color of the points is whether the status is ok or fail, green for ok and red for fail\n",
        "fig, ax = plt.subplots()\n",
        "scatter = ax.scatter(results_df['learning_rate'], results_df['ent_coef'], c=results_df['status'].apply(lambda x: 'green' if x == 'ok' else 'red'))\n",
        "ax.set_xlabel('Learning Rate')\n",
        "ax.set_ylabel('Entropy Coefficient')\n",
        "ax.set_title('Hyperparameter Optimization')\n",
        "plt.legend(handles=scatter.legend_elements()[0], labels=['OK', 'Fail'])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # create a dataframe of the rewards\n",
        "# rewards_df = pd.DataFrame({'rewards': rewards})\n",
        "# # plot the rewards\n",
        "# plt.figure(figsize=(10, 5))\n",
        "# sns.lineplot(data=rewards_df)\n",
        "# plt.title('Rewards')\n",
        "# plt.xlabel('Episode')\n",
        "# plt.ylabel('Reward')\n",
        "# plt.legend()\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # import the models from /models folder\n",
        "# import os\n",
        "# import glob\n",
        "# # get the list of models\n",
        "# model_list = glob.glob('models_4_17_24/*.pkl')\n",
        "# # separate the strings of each model name on _ and get the last element of the string if the string of the model doesn't include 'initial' or 'updated'\n",
        "# model_list_episode_nbr = [model.split('_')[-1] for model in model_list if 'initial' not in model and 'updated' not in model]\n",
        "# model_list_episode_nbr = [int(model_name.split('.')[0]) for model_name in model_list_episode_nbr]\n",
        "# max_episode = max(model_list_episode_nbr)\n",
        "# # test the last set of 10 episodes\n",
        "# init_episode = ((int(max_episode)/10) - 10)*10\n",
        "# # print(max_episode, init_episode)\n",
        "# models = []\n",
        "# # test the last set of 10 episodes from init_episode to max_episode\n",
        "# for nbr in range(int(init_episode), int(max_episode)+10, 10):\n",
        "#     # set up the appropriate time_points for each of the models in the list\n",
        "#     env_train.time_points = list(symbols[1]['EURUSD'].iloc[-int(training_length):-(int(testing_length)-int(nbr)), :].index)# make this -nbr not +nbr next time\n",
        "#     obs_train, info_train = env_train.reset(seed=2024)\n",
        "#     # find the model name that contains the nbr\n",
        "#     model_name = [model for model in model_list if str(nbr) in model][0]\n",
        "#     print(model_name)\n",
        "#     # load the models into a list\n",
        "#     models.append(PPO.load(model_name, env=env_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# sim_testing = gym_mtsim.MtSimulator(\n",
        "#     unit='USD',\n",
        "#     balance=200000.,\n",
        "#     leverage=100.,\n",
        "#     stop_out_level=0.2,\n",
        "#     hedge=True,\n",
        "#     symbols_filename=FOREX_DATA_PATH\n",
        "# )\n",
        "\n",
        "# env_testing = MtEnv(\n",
        "#     original_simulator=sim_testing,\n",
        "#     trading_symbols=['EURUSD'],\n",
        "#     window_size = window_size_param,\n",
        "#     time_points=list(testing_index_slice),\n",
        "#     hold_threshold=0.1,\n",
        "#     close_threshold=0.1,\n",
        "#     fee=lambda symbol: {\n",
        "#         # 'GBPCAD': max(0., np.random.normal(0.0007, 0.00005)),\n",
        "#         'EURUSD': max(0., np.random.normal(0.0001, 0.00003))\n",
        "#         # 'USDJPY': max(0., np.random.normal(0.02, 0.003)),\n",
        "#     }[symbol],\n",
        "#     symbol_max_orders=2,\n",
        "#     multiprocessing_processes=2\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model_ppo = PPO.load(f'models_4_17_24\\model_25K_5.pkl', env=env_train)\n",
        "\n",
        "# obs_test, info_test = env_testing.reset(seed=2024)\n",
        "# done_test = False\n",
        "# while not done_test:\n",
        "#     action, _states = model_ppo.predict(obs_test)\n",
        "#     obs_test, reward_test, terminated_test, truncated_test, info_test = env_testing.step(action)\n",
        "#     done_test = terminated_test or truncated_test\n",
        "#     # total_reward += reward_test\n",
        "#     if done_test:\n",
        "#         break\n",
        "# try:\n",
        "#     order_len = len(env_testing.render()['orders'])\n",
        "# except:\n",
        "#     order_len = 0\n",
        "# # print(f\"Episode: {episode}, Reward: {total_reward:.3f}, # orders: {order_len}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # if model_dict is still a thing\n",
        "# for timestep in timesteps_models_dict.keys():\n",
        "#     models_dict = timesteps_models_dict[timestep]\n",
        "\n",
        "#     for nbr in range(0, 10):\n",
        "#         msg = f\"{'-'*8} Testing Model {nbr} with {timestep} training timesteps {'-'*8}\"\n",
        "#         print(f\"\"\"{msg}\\n{'-'*len(msg)}\"\"\")\n",
        "#         reward_across_episodes = []\n",
        "#         rewards_dict = {}\n",
        "#         model_results_dict = {}\n",
        "#         for episode in range(0, 10):   \n",
        "#             total_reward = 0\n",
        "#             done_test = False\n",
        "#             model_ppo = models_dict[f'model_{nbr}']\n",
        "\n",
        "#             obs_test, info_test = env_train.reset(seed=2024)\n",
        "#             while not done_test:\n",
        "#                 action, _states = model_ppo.predict(obs_test)\n",
        "#                 obs_test, reward_test, terminated_test, truncated_test, info_test = env_train.step(action)\n",
        "#                 done_test = terminated_test or truncated_test\n",
        "#                 total_reward += reward_test\n",
        "#                 if done_test:\n",
        "#                     break\n",
        "#             reward_across_episodes.append(total_reward)\n",
        "#             try:\n",
        "#                 order_len = len(env_train.render()['orders'])\n",
        "#             except:\n",
        "#                 order_len = 0\n",
        "#             print(f\"Episode: {episode}, Reward: {total_reward:.3f}, # orders: {order_len}\")\n",
        "#         print_stats(reward_across_episodes)\n",
        "#         model_results_dict[f'model_{nbr}_{timestep}'] = reward_across_episodes\n",
        "# model_results_df = pd.DataFrame(model_results_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # plot the rewards for each model over episodes\n",
        "# plt.figure(figsize=(10, 5))\n",
        "# sns.lineplot(data=model_results_df)\n",
        "# plt.title('Rewards')\n",
        "# plt.xlabel('Episode')\n",
        "# plt.ylabel('Reward')\n",
        "# plt.legend()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # if model_dict is still a thing\n",
        "# for timestep in ['25K']:\n",
        "#     for nbr in tqdm(range(1, 10)):\n",
        "#         msg = f\"{'-'*8} Testing Model {nbr} with {timestep} training timesteps {'-'*8}\"\n",
        "#         print(f\"\"\"{msg}\\n{'-'*len(msg)}\"\"\")\n",
        "#         reward_across_episodes = []\n",
        "#         number_of_orders_across_episodes = []\n",
        "#         rewards_dict = {}\n",
        "#         model_results_dict = {}\n",
        "#         for episode in tqdm(range(0, 10)):   \n",
        "#             total_reward = 0\n",
        "#             done_test = False\n",
        "#             model_ppo = PPO.load(f'models_4_17_24\\model_{timestep}_{nbr}.pkl', env=env_train)\n",
        "\n",
        "#             obs_test, info_test = env_testing.reset(seed=2024)\n",
        "#             while not done_test:\n",
        "#                 action, _states = model_ppo.predict(obs_test)\n",
        "#                 obs_test, reward_test, terminated_test, truncated_test, info_test = env_testing.step(action)\n",
        "#                 done_test = terminated_test or truncated_test\n",
        "#                 total_reward += reward_test\n",
        "#                 if done_test:\n",
        "#                     break\n",
        "#             reward_across_episodes.append(total_reward)\n",
        "#             try:\n",
        "#                 order_len = len(env_testing.render()['orders'])\n",
        "#             except:\n",
        "#                 order_len = 0\n",
        "#             number_of_orders_across_episodes.append(order_len)\n",
        "#             print(f\"Episode: {episode}, Reward: {total_reward:.3f}, # orders: {order_len}\")\n",
        "#         print_stats(reward_across_episodes, 'Reward')\n",
        "#         print_stats(number_of_orders_across_episodes, 'Orders')\n",
        "#         model_results_dict[f'model_{nbr}_{timestep}'] = reward_across_episodes\n",
        "# model_results_df = pd.DataFrame(model_results_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # plot the rewards for each model over episodes\n",
        "# plt.figure(figsize=(10, 5))\n",
        "# sns.lineplot(data=model_results_df)\n",
        "# plt.title('Rewards')\n",
        "# plt.xlabel('Episode')\n",
        "# plt.ylabel('Reward')\n",
        "# plt.legend()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # if the cluster has been restarted\n",
        "# for nbr, time_points_idx in zip(range(0, 10), range(0, 500, 50)):\n",
        "#     # model_ppo.learn(total_timesteps=25000, callback=ProgressBarCallback(100))\n",
        "#     env_train = MtEnv(\n",
        "#         original_simulator=sim_train,\n",
        "#         trading_symbols=['EURUSD'],\n",
        "#         window_size = window_size_param,\n",
        "#         time_points=list(symbols[1]['EURUSD'].iloc[-int(training_length):-(int(testing_length)-int(time_points_idx)), :].index),\n",
        "#         hold_threshold=0.5,\n",
        "#         close_threshold=0.5,\n",
        "#         fee=lambda symbol: {\n",
        "#             # 'GBPCAD': max(0., np.random.normal(0.0007, 0.00005)),\n",
        "#             'EURUSD': max(0., np.random.normal(0.0001, 0.00003))\n",
        "#             # 'USDJPY': max(0., np.random.normal(0.02, 0.003)),\n",
        "#         }[symbol],\n",
        "#         symbol_max_orders=2,\n",
        "#         multiprocessing_processes=2\n",
        "#     )\n",
        "#     # obs_train, info_train = env_train.reset(seed=2024)\n",
        "#     total_reward = 0\n",
        "#     done_test = False\n",
        "#     model_ppo = PPO.load(f'models\\model_{nbr}.pkl', env=env_train)\n",
        "\n",
        "#     env_testing = MtEnv(\n",
        "#         original_simulator=sim_testing,\n",
        "#         trading_symbols=['EURUSD'],\n",
        "#         window_size = window_size_param,\n",
        "#         # time_points=list(testing_index_slice),\n",
        "#         hold_threshold=0.5,\n",
        "#         close_threshold=0.5,\n",
        "#         fee=lambda symbol: {\n",
        "#             # 'GBPCAD': max(0., np.random.normal(0.0007, 0.00005)),\n",
        "#             'EURUSD': max(0., np.random.normal(0.0001, 0.00003))\n",
        "#             # 'USDJPY': max(0., np.random.normal(0.02, 0.003)),\n",
        "#         }[symbol],\n",
        "#         symbol_max_orders=2,\n",
        "#         multiprocessing_processes=2\n",
        "#     )\n",
        "#     obs_test, info_test = env_testing.reset(seed=2024)\n",
        "#     while not done_test:\n",
        "#         action, _states = model_ppo.predict(obs_test)\n",
        "#         obs_test, reward_test, terminated_test, truncated_test, info_test = env_testing.step(action)\n",
        "#         done_test = terminated_test or truncated_test\n",
        "#         total_reward += reward_test\n",
        "#         if done_test:\n",
        "#             break\n",
        "#     state = env_testing.render()\n",
        "\n",
        "#     print(\n",
        "#         f\"balance: {state['balance']}, equity: {state['equity']}, margin: {state['margin']}\\n\"\n",
        "#         f\"free_margin: {state['free_margin']}, margin_level: {state['margin_level']}\\n\"\n",
        "\n",
        "#     )\n",
        "#     # print(state['orders'].Profit.sum())\n",
        "#     if len(state['orders']) > 0:\n",
        "#         print(state['orders'].Profit.sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# max_episode = 120\n",
        "# for model_nbr in range(0, int(max_episode)+10, 10):\n",
        "#     print(f'Model: {model_nbr}')\n",
        "#     over_episodes_rewards = []\n",
        "#     over_episodes_balance = []\n",
        "#     obs_training, info_training = env_train.reset(seed=2024)\n",
        "#     for episode in range(0, 10):\n",
        "#         obs_test, info_test = env_testing.reset(seed=2024)\n",
        "        \n",
        "#         # model_ppo.learn(total_timesteps=25000, callback=ProgressBarCallback(100))\n",
        "\n",
        "#         total_reward = 0\n",
        "#         done_test = False\n",
        "#         env_train.time_points = list(symbols[1]['EURUSD'].iloc[-int(training_length):-(int(testing_length)-int(model_nbr)), :].index)\n",
        "#         obs_training, info_training = env_train.reset(seed=2024)\n",
        "#         model_ppo = PPO.load(f'models\\model_{model_nbr}.pkl', env=env_train)\n",
        "\n",
        "#         while not done_test:\n",
        "#             action, _states = model_ppo.predict(obs_test)\n",
        "#             obs_test, reward_test, terminated_test, truncated_test, info_test = env_testing.step(action)\n",
        "#             done_test = terminated_test or truncated_test\n",
        "\n",
        "#             total_reward += reward_test\n",
        "#             if done_test:\n",
        "#                 break\n",
        "#         over_episodes_balance.append(info_test['balance'])\n",
        "#         over_episodes_rewards.append(total_reward)\n",
        "#         print(f'Episode: {episode}, Reward: {total_reward:.3f}, Balance: {info_test[\"balance\"]:.3f}')\n",
        "#     print_stats(over_episodes_rewards)\n",
        "#     print_stats(over_episodes_balance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# data = pd.DataFrame(plot_data)\n",
        "\n",
        "# sns.set_style('whitegrid')\n",
        "# plt.figure(figsize=(8, 6))\n",
        "\n",
        "# for key in plot_data:\n",
        "#     if key == 'x':\n",
        "#         continue\n",
        "#     label = plot_settings[key]['label']\n",
        "#     line = plt.plot('x', key, data=data, linewidth=1, label=label)\n",
        "\n",
        "# plt.xlabel('episode')\n",
        "# plt.ylabel('reward')\n",
        "# plt.title('Random vs. SB3 Agents')\n",
        "# plt.legend()\n",
        "# plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "p3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
