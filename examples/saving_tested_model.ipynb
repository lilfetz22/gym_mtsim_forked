{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import gymnasium as gym\n",
        "import gym_mtsim\n",
        "sys.path.append(\"C:/Users/WilliamFetzner/Documents/Trading/\")\n",
        "from gym_mtsim_forked.gym_mtsim.data import FOREX_DATA_PATH_TRAIN, FOREX_DATA_PATH_TEST, FOREX_DATA_PATH\n",
        "from gym_mtsim import OrderType, Timeframe, MtEnv, MtSimulator\n",
        "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials, STATUS_FAIL\n",
        "from stable_baselines3 import A2C, PPO\n",
        "from stable_baselines3.common.callbacks import BaseCallback, EvalCallback\n",
        "import time\n",
        "import torch\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# unpack the pickle file and load the data that is in symbols_forex.pkl\n",
        "with open('C:/Users/WilliamFetzner/Documents/Trading/gym_mtsim_forked/gym_mtsim/data/symbols_forex.pkl', 'rb') as f:\n",
        "    symbols = pickle.load(f)\n",
        "# convert symbols to a pd.dataframe\n",
        "# symbols[1]['EURUSD']\n",
        "split = int(len(symbols[1]['EURUSD']) * 0.80)\n",
        "validation_split = int(len(symbols[1]['EURUSD']) * 0.90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get the 2 weeks of the symbols[1]['EURUSD'] dataframe by first finding the max date\n",
        "# then subtracting 14 days from that date\n",
        "symbols[1]['EURUSD'].index = pd.to_datetime(symbols[1]['EURUSD'].index)\n",
        "max_date = symbols[1]['EURUSD'].index.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# find the previous friday before max_date\n",
        "# what is the day of the week of the max_date\n",
        "max_day_of_week = max_date.dayofweek\n",
        "# subtract the day of the week from the max_date to get the previous friday\n",
        "max_friday = max_date - pd.DateOffset(days=max_day_of_week+2)\n",
        "two_weeks = max_friday - pd.DateOffset(days=14)\n",
        "one_week = max_friday - pd.DateOffset(days=7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "training_index_slice = symbols[1]['EURUSD'].loc[:one_week, :].index\n",
        "validation_index_slice = symbols[1]['EURUSD'].loc[one_week:max_friday, :].index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatetimeIndex(['2024-04-08 00:00:00+00:00', '2024-04-08 01:00:00+00:00',\n",
              "               '2024-04-08 02:00:00+00:00', '2024-04-08 03:00:00+00:00',\n",
              "               '2024-04-08 04:00:00+00:00', '2024-04-08 05:00:00+00:00',\n",
              "               '2024-04-08 06:00:00+00:00', '2024-04-08 07:00:00+00:00',\n",
              "               '2024-04-08 08:00:00+00:00', '2024-04-08 09:00:00+00:00',\n",
              "               ...\n",
              "               '2024-04-12 14:00:00+00:00', '2024-04-12 15:00:00+00:00',\n",
              "               '2024-04-12 16:00:00+00:00', '2024-04-12 17:00:00+00:00',\n",
              "               '2024-04-12 18:00:00+00:00', '2024-04-12 19:00:00+00:00',\n",
              "               '2024-04-12 20:00:00+00:00', '2024-04-12 21:00:00+00:00',\n",
              "               '2024-04-12 22:00:00+00:00', '2024-04-12 23:00:00+00:00'],\n",
              "              dtype='datetime64[ns, UTC]', name='Time', length=120, freq=None)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "validation_index_slice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create Env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "sim_train = gym_mtsim.MtSimulator(\n",
        "    unit='USD',\n",
        "    balance=200000.,\n",
        "    leverage=100.,\n",
        "    stop_out_level=0.2,\n",
        "    hedge=True,\n",
        "    symbols_filename=FOREX_DATA_PATH\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "env_train = MtEnv(\n",
        "    original_simulator=sim_train,\n",
        "    trading_symbols=['EURUSD'],\n",
        "    window_size = 10,\n",
        "    time_points=list(training_index_slice),\n",
        "    hold_threshold=0.5,\n",
        "    close_threshold=0.5,\n",
        "    fee=lambda symbol: {\n",
        "        # 'GBPCAD': max(0., np.random.normal(0.0007, 0.00005)),\n",
        "        'EURUSD': max(0., np.random.normal(0.0001, 0.00003))\n",
        "        # 'USDJPY': max(0., np.random.normal(0.02, 0.003)),\n",
        "    }[symbol],\n",
        "    symbol_max_orders=2,\n",
        "    multiprocessing_processes=2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "sim_validation = gym_mtsim.MtSimulator(\n",
        "    unit='USD',\n",
        "    balance=200000.,\n",
        "    leverage=100.,\n",
        "    stop_out_level=0.2,\n",
        "    hedge=True,\n",
        "    symbols_filename=FOREX_DATA_PATH\n",
        ")\n",
        "\n",
        "env_validation = MtEnv(\n",
        "    original_simulator=sim_validation,\n",
        "    trading_symbols=['EURUSD'],\n",
        "    window_size = 10,\n",
        "    time_points=list(validation_index_slice),\n",
        "    hold_threshold=0.5,\n",
        "    close_threshold=0.5,\n",
        "    fee=lambda symbol: {\n",
        "        # 'GBPCAD': max(0., np.random.normal(0.0007, 0.00005)),\n",
        "        'EURUSD': max(0., np.random.normal(0.0001, 0.00003))\n",
        "        # 'USDJPY': max(0., np.random.normal(0.02, 0.003)),\n",
        "    }[symbol],\n",
        "    symbol_max_orders=2,\n",
        "    multiprocessing_processes=2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_stats(reward_over_episodes, printing_name):\n",
        "    \"\"\"  Print Reward  \"\"\"\n",
        "\n",
        "    avg_rewards = np.mean(reward_over_episodes)\n",
        "    min_rewards = np.min(reward_over_episodes)\n",
        "    max_rewards = np.max(reward_over_episodes)\n",
        "\n",
        "    print (f'Min. {printing_name}          : {min_rewards:>10.3f}')\n",
        "    print (f'Avg. {printing_name}          : {avg_rewards:>10.3f}')\n",
        "    print (f'Max. {printing_name}          : {max_rewards:>10.3f}')\n",
        "\n",
        "    return min_rewards, avg_rewards, max_rewards\n",
        "\n",
        "def my_profit_calculation(env_orders, stop_loss):\n",
        "        # env_orders = env_testing.render()['orders']\n",
        "        # stop_loss = 0.001\n",
        "\n",
        "        # normalize the Volume with to have a mean of 1\n",
        "        mean_value = env_orders['Volume'].mean()\n",
        "\n",
        "        # Normalize the column to have a mean of 1\n",
        "        env_orders.loc[:, 'Volume_normalized'] = round((env_orders['Volume'] / mean_value), 2)\n",
        "        # add a column for when the difference between the Entry Price and the Exit Price is greater than stop_loss\n",
        "        env_orders.loc[:, 'stoploss_hit'] = np.where((env_orders['Type'].str.strip() == 'Buy') &\n",
        "                                                        ((env_orders['Entry Price'] - env_orders['Exit Price']) > stop_loss),\n",
        "                                                        1, np.where((env_orders['Type'].str.strip() == 'Sell') &\n",
        "                                                                        ((env_orders['Exit Price'] - env_orders['Entry Price']) > stop_loss),\n",
        "                                                                        1, 0))\n",
        "        env_orders.loc[:, 'Exit Price'] = np.where((env_orders['Type'].str.strip() == 'Buy') & (env_orders['stoploss_hit'] == 1),\n",
        "                                                        env_orders['Entry Price'] - stop_loss,\n",
        "                                                        np.where((env_orders['Type'].str.strip() == 'Sell') & (env_orders['stoploss_hit'] == 1),\n",
        "                                                                env_orders['Entry Price'] + stop_loss, env_orders['Exit Price']))\n",
        "        env_orders.loc[:, 'Profit'] = np.where((env_orders['Type'].str.strip() == 'Buy'),\n",
        "                                                        ((env_orders['Exit Price'] - (env_orders['Fee']/2)) - \n",
        "                                                        (env_orders['Entry Price'] + (env_orders['Fee']/2)))\n",
        "                                                                * 100_000 * env_orders['Volume_normalized'], \n",
        "                                                        np.where((env_orders['Type'].str.strip() == 'Sell'),\n",
        "                                                                ((env_orders['Entry Price'] - (env_orders['Fee']/2)) - \n",
        "                                                                (env_orders['Exit Price'] + (env_orders['Fee']/2)))\n",
        "                                                                * 100_000 * env_orders['Volume_normalized'], np.nan))\n",
        "        total_reward = env_orders.loc[:, 'Profit'].sum()\n",
        "        # Calculate Gross Profit\n",
        "        gross_profit = env_orders.loc[env_orders['Profit'] > 0, 'Profit'].sum()\n",
        "\n",
        "        # Calculate Gross Loss\n",
        "        gross_loss = env_orders.loc[env_orders['Profit'] < 0, 'Profit'].abs().sum()\n",
        "\n",
        "        # Calculate Profit Factor\n",
        "        profit_factor = gross_profit / gross_loss if gross_loss != 0 else 0\n",
        "\n",
        "        profit_factor = profit_factor - 1\n",
        "\n",
        "        return profit_factor, total_reward, env_orders\n",
        "\n",
        "# ProgressBarCallback for model.learn()\n",
        "class ProgressBarCallback(BaseCallback):\n",
        "\n",
        "    def __init__(self, check_freq: int, verbose: int = 1):\n",
        "        super().__init__(verbose)\n",
        "        self.check_freq = check_freq\n",
        "\n",
        "    def _on_training_start(self) -> None:\n",
        "        \"\"\"\n",
        "        This method is called before the first rollout starts.\n",
        "        \"\"\"\n",
        "        self.progress_bar = tqdm(total=self.model._total_timesteps, desc=\"model.learn()\")\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        if self.n_calls % self.check_freq == 0:\n",
        "            self.progress_bar.update(self.check_freq)\n",
        "        return True\n",
        "    \n",
        "    def _on_training_end(self) -> None:\n",
        "        \"\"\"\n",
        "        This event is triggered before exiting the `learn()` method.\n",
        "        \"\"\"\n",
        "        self.progress_bar.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TRAINING + TEST\n",
        "def train_val_model(model, model_policy, env_tr, env_val, seed, steps_str, lr, gamma_param, entropy, total_learning_timesteps=10_000):\n",
        "    \"\"\"\n",
        "    Trains and validates a model using the Proximal Policy Optimization (PPO) algorithm.\n",
        "\n",
        "    Args:\n",
        "        model (object): The model to be trained.\n",
        "        model_policy (object): The policy used by the model.\n",
        "        env_tr (object): The training environment.\n",
        "        env_val (object): The validation environment.\n",
        "        seed (int): The random seed for reproducibility.\n",
        "        steps_str (str): A string representing the number of steps.\n",
        "        window_size_param (int): The window size parameter.\n",
        "        lr (float): The learning rate.\n",
        "        gamma_param (float): The gamma parameter.\n",
        "        entropy (float): The entropy coefficient.\n",
        "        total_learning_timesteps (int, optional): The total number of learning timesteps. Defaults to 10,000.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the reward over validations, orders over validations, and the model dictionary.\n",
        "    \"\"\"\n",
        "    # reproduce training and test\n",
        "    print('-' * 80)\n",
        "    torch.manual_seed(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    #model_dict = {}\n",
        "    # env_tr.window_size = window_size_param\n",
        "    print(f'entropy: {entropy}, learning rate: {lr}, gamma: {gamma_param}')\n",
        "    # eval_callback = EvalCallback(env_tr, log_path='./logs/', eval_freq=1000)\n",
        "    model = PPO(model_policy, env_tr, verbose=0, ent_coef=entropy, learning_rate=lr)#, gamma=gamma_param, \n",
        "    obs_tr, info_tr = env_tr.reset(seed=seed)\n",
        "    # custom callback for 'progress_bar'\n",
        "    model.learn(total_timesteps=total_learning_timesteps)#, callback=ProgressBarCallback(100))\n",
        "\n",
        "    reward_over_validations = []\n",
        "    orders_over_validations = []\n",
        "    orders_over_validations_dfs = {}\n",
        "    profit_over_validations = []\n",
        "\n",
        "    for episode in range(0, 10):\n",
        "        obs_val, info_val = env_val.reset(seed=seed)\n",
        "\n",
        "        total_reward = 0\n",
        "        done_val = False\n",
        "\n",
        "        while not done_val:\n",
        "            action, _states = model.predict(obs_val)\n",
        "            obs_val, reward_val, terminated_val, truncated_val, info_val = env_val.step(action)\n",
        "            done_val = terminated_val or truncated_val\n",
        "\n",
        "            total_reward += reward_val\n",
        "            if done_val:\n",
        "                break\n",
        "        try:\n",
        "            orders_made_in_episode = env_val.render()['orders']\n",
        "            order_len = len(orders_made_in_episode)\n",
        "            total_reward, total_profit, orders_df = my_profit_calculation(orders_made_in_episode, 0.001)\n",
        "            orders_over_validations_dfs[f'{episode}'] = orders_df\n",
        "            \n",
        "        except:\n",
        "            print('There were not any orders produced by the model')\n",
        "            order_len = 0        \n",
        "\n",
        "        reward_over_validations.append(total_reward) \n",
        "        profit_over_validations.append(total_profit)   \n",
        "        orders_over_validations.append(order_len)  \n",
        "\n",
        "\n",
        "        # if episode % 1 == 0:\n",
        "        avg_reward = np.mean(reward_over_validations)\n",
        "        avg_orders = np.mean(orders_over_validations)\n",
        "        avg_profit = np.mean(profit_over_validations)\n",
        "        print(f'Episode: {episode}, Avg. Reward: {avg_reward:.3f}, # of orders: {avg_orders:.3f}, avg Profit: {avg_profit:.3f}')\n",
        "    model.save(f'best_hyperparameters/models_4_27_24/model_{steps_str}.pkl')\n",
        "    return reward_over_validations, orders_over_validations, orders_over_validations_dfs#, model_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Objective Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "seed                     : 2024\n"
          ]
        }
      ],
      "source": [
        "seed = 2024  # random seed\n",
        "total_num_episodes = 10\n",
        "\n",
        "# print (\"env_name                 :\", env_name)\n",
        "print (\"seed                     :\", seed)\n",
        "\n",
        "# INIT matplotlib\n",
        "plot_settings = {}\n",
        "plot_data = {'x': [i for i in range(1, total_num_episodes + 1)]}\n",
        "\n",
        "# learning_timesteps_list_in_K = [25]#, 50, 100]\n",
        "# learning_timesteps_list_in_K = [50, 250, 500]\n",
        "# learning_timesteps_list_in_K = [500, 1000, 3000, 5000]\n",
        "\n",
        "# RL Algorithms: https://stable-baselines3.readthedocs.io/en/master/guide/algos.html\n",
        "\n",
        "timesteps_models_dict = {}\n",
        "def objective(params):\n",
        "    learning_timesteps = 100 #params['learning_timesteps']\n",
        "    ent_coef = params['ent_coef']\n",
        "    gamma = params['gamma'] #0.99 #\n",
        "    learning_rate = params['learning_rate']#0.0003#\n",
        "\n",
        "    if learning_rate > 0.08:\n",
        "        print(f'Learning rate too high: {learning_rate}')\n",
        "        return {'loss': None, 'status': STATUS_FAIL, 'eval_time': time.time(), 'parameters': params}\n",
        "    if ent_coef > 0.1:\n",
        "        print(f'Entropy too high: {ent_coef}')\n",
        "        return {'loss': None, 'status': STATUS_FAIL, 'eval_time': time.time(), 'parameters': params}\n",
        "\n",
        "    total_learning_timesteps = learning_timesteps * 1000\n",
        "    step_key = f'{learning_timesteps}K'\n",
        "    policy_dict = PPO.policy_aliases\n",
        "    policy = policy_dict.get('MultiInputPolicy')\n",
        "    class_name = type(PPO).__qualname__\n",
        "    plot_key = f'{class_name}_rewards_'+step_key\n",
        "    try:\n",
        "        rewards, orders = train_val_model(PPO, policy, env_train, env_validation, seed, step_key,  \n",
        "                                                    learning_rate, gamma, ent_coef, total_learning_timesteps)\n",
        "    except:\n",
        "        print(f'''there was an error with those parameters: timesteps: {learning_timesteps}, \\n\n",
        "              ent_coef: {ent_coef}, gamma: {gamma}, learning_rate: {learning_rate}''')\n",
        "        return {'loss': None, 'status': STATUS_FAIL, 'eval_time': time.time(), 'parameters': params}\n",
        "    # timesteps_models_dict[step_key] = models_dict\n",
        "    min_rewards, avg_rewards, max_rewards, = print_stats(rewards, 'Reward')\n",
        "    print_stats(orders, 'Orders')\n",
        "    label = f'Avg. {avg_rewards:>7.2f} : {class_name} - {step_key}'\n",
        "    plot_data[plot_key] = rewards\n",
        "    plot_settings[plot_key] = {'label': label}\n",
        "    params['avg_orders'] = np.mean(orders)       \n",
        "\n",
        "    return {'loss': -avg_rewards, 'status': STATUS_OK, 'eval_time': time.time(), 'parameters': params} "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.01683527363887545"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_hyperparameters_current_week = pd.read_excel('best_hyperparameter_search_results.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "entropy: 0.01879460162445175, learning rate: 0.01683527363887545, gamma: 0.99\n",
            "Episode: 0, Avg. Reward: -0.166, # of orders: 42.000, avg Profit: -224.783\n",
            "Episode: 1, Avg. Reward: 0.745, # of orders: 41.000, avg Profit: 790.657\n",
            "Episode: 2, Avg. Reward: 0.264, # of orders: 33.667, avg Profit: 270.732\n",
            "Episode: 3, Avg. Reward: 0.072, # of orders: 29.250, avg Profit: 141.611\n",
            "Episode: 4, Avg. Reward: 0.038, # of orders: 29.000, avg Profit: 96.550\n",
            "Episode: 5, Avg. Reward: 0.283, # of orders: 31.500, avg Profit: 242.613\n",
            "Episode: 6, Avg. Reward: 0.408, # of orders: 32.714, avg Profit: 394.583\n",
            "Episode: 7, Avg. Reward: 0.308, # of orders: 31.250, avg Profit: 310.829\n",
            "Episode: 8, Avg. Reward: 0.220, # of orders: 31.444, avg Profit: 198.966\n",
            "Episode: 9, Avg. Reward: 0.233, # of orders: 31.700, avg Profit: 212.372\n"
          ]
        }
      ],
      "source": [
        "# # # check if it is working:\n",
        "parameters = {\n",
        "    # 'window_size': 10,\n",
        "    # 'learning_timesteps': 25,\n",
        "    'ent_coef': best_hyperparameters_current_week.loc[0,'ent_coef'],\n",
        "    'gamma': best_hyperparameters_current_week.loc[0,'gamma'],\n",
        "    'learning_rate': best_hyperparameters_current_week.loc[0,'learning_rate']\n",
        "}\n",
        "rewards_250, orders_250, orders_df_dict_250 = train_val_model(PPO, 'MultiInputPolicy', env_train, env_validation, seed, '250K',  \n",
        "                                            parameters['learning_rate'], parameters['gamma'], parameters['ent_coef'], 250_000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "entropy: 0.01879460162445175, learning rate: 0.01683527363887545, gamma: 0.99\n",
            "Episode: 0, Avg. Reward: 1.530, # of orders: 60.000, avg Profit: 2588.582\n",
            "Episode: 1, Avg. Reward: 0.709, # of orders: 38.500, avg Profit: 1255.176\n",
            "Episode: 2, Avg. Reward: 0.578, # of orders: 38.667, avg Profit: 1014.547\n",
            "Episode: 3, Avg. Reward: 0.714, # of orders: 48.250, avg Profit: 1357.107\n",
            "Episode: 4, Avg. Reward: 0.390, # of orders: 40.600, avg Profit: 991.873\n",
            "Episode: 5, Avg. Reward: 0.219, # of orders: 36.500, avg Profit: 739.308\n",
            "Episode: 6, Avg. Reward: 0.047, # of orders: 32.429, avg Profit: 553.190\n",
            "Episode: 7, Avg. Reward: -0.027, # of orders: 30.750, avg Profit: 430.696\n",
            "Episode: 8, Avg. Reward: 0.120, # of orders: 30.333, avg Profit: 549.282\n",
            "Episode: 9, Avg. Reward: 0.156, # of orders: 32.800, avg Profit: 593.882\n"
          ]
        }
      ],
      "source": [
        "rewards_50, orders_50, orders_df_dict_50 = train_val_model(PPO, 'MultiInputPolicy', env_train, env_validation, seed, '250K',  \n",
        "                                            parameters['learning_rate'], parameters['gamma'], parameters['ent_coef'], 50_000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2588.5820506547198"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "orders_df_dict['0'].Profit.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test which version of the model to take, does it make a difference whether I use model_0 or model_9\n",
        "obs_tr, info_tr = env_train.reset(seed=seed)\n",
        "obs_test, info_test = env_validation.reset(seed=seed)\n",
        "\n",
        "total_reward = 0\n",
        "done_test = False\n",
        "reward_over_tests = {}\n",
        "for training in ['', '250K_']:\n",
        "    rewards = []\n",
        "    for episode in range(500):\n",
        "        obs_test, info_test = env_validation.reset(seed=seed)\n",
        "        model_ppo = PPO.load(f'best_hyperparameters/models_4_27_24/model_{training}0.pkl', env_train)\n",
        "        done_test = False\n",
        "        while not done_test:\n",
        "            action, _states = model_ppo.predict(obs_test)\n",
        "            obs_test, reward_test, terminated_test, truncated_test, info_test = env_validation.step(action)\n",
        "            done_test = terminated_test or truncated_test\n",
        "            \n",
        "            total_reward += reward_test\n",
        "            if done_test:\n",
        "                break\n",
        "        try:\n",
        "            orders_made_in_episode_test = env_validation.render()['orders']\n",
        "            # orders_over_validations_dfs[f'{episode}'] = orders_made_in_episode_test\n",
        "            order_len = len(orders_made_in_episode_test)\n",
        "            total_reward, total_profit, orders_df = my_profit_calculation(orders_made_in_episode_test, 0.001)\n",
        "            rewards.append(total_profit)\n",
        "        except:\n",
        "            print('There were not any orders produced by the model')\n",
        "            order_len = 0\n",
        "    reward_over_tests[f'{training}_1'] = rewards\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>50K</th>\n",
              "      <th>250K</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.107907</td>\n",
              "      <td>-0.821472</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        50K      250K\n",
              "0  0.107907 -0.821472"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "timesteps_test_df = pd.DataFrame(reward_over_tests, columns=['_1', '250K__1'])\n",
        "timesteps_test_df = timesteps_test_df.rename(columns={'_1': '50K', '250K__1': '250K'})\n",
        "timesteps_test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timesteps</th>\n",
              "      <th>values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50K</td>\n",
              "      <td>0.107907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>250K</td>\n",
              "      <td>-0.821472</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  timesteps    values\n",
              "0       50K  0.107907\n",
              "1      250K -0.821472"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# transform the dataframe to be a long dataframe where the columns 50K and 250K are in a column called timesteps and the values are in a second column called values\n",
        "timesteps_test_df_long = pd.melt(timesteps_test_df, var_name='timesteps', value_name='values')\n",
        "timesteps_test_df_long\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# plot the timesteps_test_df results with the index on the x axis and the values for the columns as the y axis and the column names as the color of the dots\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.figure(figsize=(12, 6)) \n",
        "sns.boxplot(x='timesteps', y='values', data=timesteps_test_df_long)\n",
        "plt.title('Profit of the model for 500 episodes')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "p3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
